{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pedestrian class cityscape_Group 15.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AY_q-qHj6szJ",
        "AYSQb2bl7QPI",
        "c7u8EKO4Rq5v",
        "4I24zkUtiC2z",
        "PVQNAWAzuAcg",
        "uO9XD-PmvnZN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashradhakrish/Segmentation-using-UNet-Architecture/blob/master/Pedestrian_class_cityscape_Group_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V2YEsTO4M4m_"
      },
      "source": [
        "# **Unet in Cityscape**#\n",
        "\n",
        "---\n",
        "#![alt text](https://drive.google.com/uc?id=1gesaCGGIDJFhpKmejb7tFyv-vAj_aIDf)\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY_q-qHj6szJ",
        "colab_type": "text"
      },
      "source": [
        "# **Initialisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j317gTuj3-ft",
        "colab": {}
      },
      "source": [
        "# initialising \n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as func\n",
        "from torch import Tensor\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from IPython.display import HTML, display\n",
        "from torchvision import transforms,datasets,utils\n",
        "%matplotlib inline\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AYSQb2bl7QPI"
      },
      "source": [
        "# **Dataset creation for pedestrian segmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr2rcXCW7ifP",
        "colab_type": "text"
      },
      "source": [
        "**List of steps for creating dataset**\n",
        "\n",
        "*   Liniking the Cityscape train and test image from Google drive\n",
        "*   Resizing and storing the images as 400x400 done seperately in another code\n",
        "*   Adding the images directly to dataloader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh3nJZ8e9Pfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "dde307b3-8952-4f28-a5b4-87dbdb506b24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7y0agLPLNS8",
        "colab": {}
      },
      "source": [
        "# Dataset creation based on new data image\n",
        "transform = transforms.Compose([transforms.ToTensor()]) # Converting to tensor dataset\n",
        "\n",
        "train_set = torchvision.datasets.Cityscapes(root = \"/content/drive/My Drive/Dataset/cityscape_400x400/\", split='train', mode='fine', target_type='semantic', transform=transform , target_transform=transform , transforms=None)\n",
        "test_set = torchvision.datasets.Cityscapes(root = \"/content/drive/My Drive/Dataset/cityscape_400x400/\", split='val', mode='fine', target_type='semantic', transform=transform , target_transform=transform , transforms=None)\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "# creating data loader for train and test\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2),\n",
        "    'test': DataLoader(test_set, batch_size=1, shuffle=True, num_workers=2)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8G-TmvfQABI",
        "colab_type": "text"
      },
      "source": [
        "# **Model creation**#\n",
        "\n",
        "**Input size of image** : (3, 400, 400)\n",
        "\n",
        "**Input type** : Tensor\n",
        "\n",
        "**Output size of image** : (2, 400, 400) -> **Channel information:** pedestrian and background\n",
        "\n",
        "**List of Unet models created for studies. Categorised based on parameters**\n",
        "\n",
        "*   unet_5k - 5,938 parameters\n",
        "*   unet_50k - 48,018 parameters \n",
        "*   unet_100k - 138000 parameters \n",
        "*   unet_3M - 3,873,986 parameters\n",
        "*   unet_7M - 7,782,978 parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-_6GHueWagy",
        "colab_type": "text"
      },
      "source": [
        "**5000 Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WknWTViHWZWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "2e14a5c4-850c-43b7-80f9-a13e65681731"
      },
      "source": [
        "class unet_5k(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(unet_5k,self).__init__()\n",
        "\n",
        "    #Encoder\n",
        "    self.contractinglayer1 = nn.Sequential(nn.Conv2d(3, 8, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.contractinglayer2 = nn.Sequential(nn.Conv2d(8, 16, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.downsampling = nn.MaxPool2d(2)\n",
        "\n",
        "    #Decoder\n",
        "    self.upsampling_2to1 = nn.ConvTranspose2d(16, 16, 2,stride=2, padding=0)\n",
        "    self.explayer5 = nn.Sequential(nn.Conv2d(16+8, 16, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.output_conv = nn.Conv2d(16, 2, 1, stride=1)\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "      #x = x.view(-1, 128 * 128)\n",
        "      x1 = self.contractinglayer1(x)\n",
        "      x2 = self.downsampling(x1)\n",
        "      x3 = self.contractinglayer2(x2)\n",
        "      x4 = torch.cat([self.upsampling_2to1(x3,output_size=x1.size()), x1], dim=1)\n",
        "      x5 = self.explayer5(x4)\n",
        "      x6 = self.output_conv(x5)\n",
        "      return x6   \n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = unet_5k()\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, input_size=(3, 400, 400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 400, 400]             224\n",
            "              ReLU-2          [-1, 8, 400, 400]               0\n",
            "         MaxPool2d-3          [-1, 8, 200, 200]               0\n",
            "            Conv2d-4         [-1, 16, 200, 200]           1,168\n",
            "              ReLU-5         [-1, 16, 200, 200]               0\n",
            "   ConvTranspose2d-6         [-1, 16, 400, 400]           1,040\n",
            "            Conv2d-7         [-1, 16, 400, 400]           3,472\n",
            "              ReLU-8         [-1, 16, 400, 400]               0\n",
            "            Conv2d-9          [-1, 2, 400, 400]              34\n",
            "================================================================\n",
            "Total params: 5,938\n",
            "Trainable params: 5,938\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.83\n",
            "Forward/backward pass size (MB): 92.77\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 94.63\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzSw0ZBAXWl_",
        "colab_type": "text"
      },
      "source": [
        "**50kParameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB8Woo4iPxEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "60aa4201-9c77-4e15-abde-792bcbf5cc34"
      },
      "source": [
        "class unet_50k(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(unet_50k,self).__init__()\n",
        "\n",
        "    #Encoder\n",
        "    self.contractinglayer1 = nn.Sequential(nn.Conv2d(3, 16, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.contractinglayer2 = nn.Sequential(nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.contractinglayer3 = nn.Sequential(nn.Conv2d(32, 32, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.downsampling = nn.MaxPool2d(2)\n",
        "\n",
        "    #Decoder\n",
        "    self.upsampling_3to2 = nn.ConvTranspose2d(32, 32, 2,stride=2, padding=0)\n",
        "    self.explayer4 = nn.Sequential(nn.Conv2d(32+32, 32, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.upsampling_2to1 = nn.ConvTranspose2d(32, 32, 2,stride=2, padding=0)\n",
        "    self.explayer5 = nn.Sequential(nn.Conv2d(32+16, 16, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.output_conv = nn.Conv2d(16, 2, 1, stride=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x1 = self.contractinglayer1(x)\n",
        "      x2 = self.downsampling(x1)\n",
        "      x3 = self.contractinglayer2(x2)\n",
        "      x4 = self.downsampling(x3)\n",
        "      x5 = self.contractinglayer3(x4)\n",
        "      x6 = torch.cat([self.upsampling_3to2(x5,output_size=x3.size()), x3], dim=1)\n",
        "      x7 = self.explayer4(x6)\n",
        "      x8 = torch.cat([self.upsampling_2to1(x7,output_size=x1.size()), x1], dim=1)\n",
        "      x9 = self.explayer5(x8)\n",
        "      x10 = self.output_conv(x9)\n",
        "      return x10   \n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = unet_50k()\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, input_size=(3, 400, 400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 400, 400]             448\n",
            "              ReLU-2         [-1, 16, 400, 400]               0\n",
            "         MaxPool2d-3         [-1, 16, 200, 200]               0\n",
            "            Conv2d-4         [-1, 32, 200, 200]           4,640\n",
            "              ReLU-5         [-1, 32, 200, 200]               0\n",
            "         MaxPool2d-6         [-1, 32, 100, 100]               0\n",
            "            Conv2d-7         [-1, 32, 100, 100]           9,248\n",
            "              ReLU-8         [-1, 32, 100, 100]               0\n",
            "   ConvTranspose2d-9         [-1, 32, 200, 200]           4,128\n",
            "           Conv2d-10         [-1, 32, 200, 200]          18,464\n",
            "             ReLU-11         [-1, 32, 200, 200]               0\n",
            "  ConvTranspose2d-12         [-1, 32, 400, 400]           4,128\n",
            "           Conv2d-13         [-1, 16, 400, 400]           6,928\n",
            "             ReLU-14         [-1, 16, 400, 400]               0\n",
            "           Conv2d-15          [-1, 2, 400, 400]              34\n",
            "================================================================\n",
            "Total params: 48,018\n",
            "Trainable params: 48,018\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.83\n",
            "Forward/backward pass size (MB): 180.66\n",
            "Params size (MB): 0.18\n",
            "Estimated Total Size (MB): 182.68\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un1pLjyAYIWh",
        "colab_type": "text"
      },
      "source": [
        "**100kParameters** - 0.01M"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2n0TyADw9dV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "7639a1fe-7435-44ae-e482-ed68e67aead1"
      },
      "source": [
        "class unet_100k(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(unet_100k,self).__init__()\n",
        "\n",
        "    #Encoder\n",
        "    self.contractinglayer1 = nn.Sequential(nn.Conv2d(3, 16, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(16, 16, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.contractinglayer2 = nn.Sequential(nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(32, 32, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.contractinglayer3 = nn.Sequential(nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.downsampling = nn.MaxPool2d(2)\n",
        "\n",
        "    #Decoder\n",
        "    self.upsampling_3to2 = nn.ConvTranspose2d(64, 64, 2,stride=2, padding=0)\n",
        "    self.explayer4 = nn.Sequential(nn.Conv2d(64+32, 32, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(32, 32, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.upsampling_2to1 = nn.ConvTranspose2d(32, 32, 2,stride=2, padding=0)\n",
        "    self.explayer5 = nn.Sequential(nn.Conv2d(32+16, 16, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(16, 16, 3, stride=1, padding=1), nn.ReLU())\n",
        "    self.output_conv = nn.Conv2d(16, 2, 1, stride=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x1 = self.contractinglayer1(x)\n",
        "      x2 = self.downsampling(x1)\n",
        "      x3 = self.contractinglayer2(x2)\n",
        "      x4 = self.downsampling(x3)\n",
        "      x5 = self.contractinglayer3(x4)\n",
        "      x6 = torch.cat([self.upsampling_3to2(x5,output_size=x3.size()), x3], dim=1)\n",
        "      x7 = self.explayer4(x6)\n",
        "      x8 = torch.cat([self.upsampling_2to1(x7,output_size=x1.size()), x1], dim=1)\n",
        "      x9 = self.explayer5(x8)\n",
        "      x10 = self.output_conv(x9)\n",
        "      return x10   \n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = unet_100k()\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, input_size=(3, 400, 400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 400, 400]             448\n",
            "              ReLU-2         [-1, 16, 400, 400]               0\n",
            "            Conv2d-3         [-1, 16, 400, 400]           2,320\n",
            "              ReLU-4         [-1, 16, 400, 400]               0\n",
            "         MaxPool2d-5         [-1, 16, 200, 200]               0\n",
            "            Conv2d-6         [-1, 32, 200, 200]           4,640\n",
            "              ReLU-7         [-1, 32, 200, 200]               0\n",
            "            Conv2d-8         [-1, 32, 200, 200]           9,248\n",
            "              ReLU-9         [-1, 32, 200, 200]               0\n",
            "        MaxPool2d-10         [-1, 32, 100, 100]               0\n",
            "           Conv2d-11         [-1, 64, 100, 100]          18,496\n",
            "             ReLU-12         [-1, 64, 100, 100]               0\n",
            "           Conv2d-13         [-1, 64, 100, 100]          36,928\n",
            "             ReLU-14         [-1, 64, 100, 100]               0\n",
            "  ConvTranspose2d-15         [-1, 64, 200, 200]          16,448\n",
            "           Conv2d-16         [-1, 32, 200, 200]          27,680\n",
            "             ReLU-17         [-1, 32, 200, 200]               0\n",
            "           Conv2d-18         [-1, 32, 200, 200]           9,248\n",
            "             ReLU-19         [-1, 32, 200, 200]               0\n",
            "  ConvTranspose2d-20         [-1, 32, 400, 400]           4,128\n",
            "           Conv2d-21         [-1, 16, 400, 400]           6,928\n",
            "             ReLU-22         [-1, 16, 400, 400]               0\n",
            "           Conv2d-23         [-1, 16, 400, 400]           2,320\n",
            "             ReLU-24         [-1, 16, 400, 400]               0\n",
            "           Conv2d-25          [-1, 2, 400, 400]              34\n",
            "================================================================\n",
            "Total params: 138,866\n",
            "Trainable params: 138,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.83\n",
            "Forward/backward pass size (MB): 322.27\n",
            "Params size (MB): 0.53\n",
            "Estimated Total Size (MB): 324.63\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_CudyHjYzDr",
        "colab_type": "text"
      },
      "source": [
        "**3 Million parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lttnXaXYzQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "1a7fb0f3-9061-48ae-9b43-fd5d6bc89b48"
      },
      "source": [
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )   \n",
        "\n",
        "\n",
        "class UNet_3M(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512)        \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2,stride=2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(64, 2, 1,stride=1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "        \n",
        "        x = self.dconv_down4(x)\n",
        "        \n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        \n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)       \n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1)   \n",
        "        \n",
        "        x = self.dconv_up1(x)\n",
        "        \n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet_3M()\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, input_size=(3, 400, 400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 400, 400]           1,792\n",
            "              ReLU-2         [-1, 64, 400, 400]               0\n",
            "         MaxPool2d-3         [-1, 64, 200, 200]               0\n",
            "            Conv2d-4        [-1, 128, 200, 200]          73,856\n",
            "              ReLU-5        [-1, 128, 200, 200]               0\n",
            "         MaxPool2d-6        [-1, 128, 100, 100]               0\n",
            "            Conv2d-7        [-1, 256, 100, 100]         295,168\n",
            "              ReLU-8        [-1, 256, 100, 100]               0\n",
            "         MaxPool2d-9          [-1, 256, 50, 50]               0\n",
            "           Conv2d-10          [-1, 512, 50, 50]       1,180,160\n",
            "             ReLU-11          [-1, 512, 50, 50]               0\n",
            "         Upsample-12        [-1, 512, 100, 100]               0\n",
            "           Conv2d-13        [-1, 256, 100, 100]       1,769,728\n",
            "             ReLU-14        [-1, 256, 100, 100]               0\n",
            "         Upsample-15        [-1, 256, 200, 200]               0\n",
            "           Conv2d-16        [-1, 128, 200, 200]         442,496\n",
            "             ReLU-17        [-1, 128, 200, 200]               0\n",
            "         Upsample-18        [-1, 128, 400, 400]               0\n",
            "           Conv2d-19         [-1, 64, 400, 400]         110,656\n",
            "             ReLU-20         [-1, 64, 400, 400]               0\n",
            "           Conv2d-21          [-1, 2, 400, 400]             130\n",
            "================================================================\n",
            "Total params: 3,873,986\n",
            "Trainable params: 3,873,986\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.83\n",
            "Forward/backward pass size (MB): 876.46\n",
            "Params size (MB): 14.78\n",
            "Estimated Total Size (MB): 893.07\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ_ufIS0bGoN",
        "colab_type": "text"
      },
      "source": [
        "**7 Million parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y71BdxMLGRmB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "41459887-c1f9-418e-ec24-d811ea322bea"
      },
      "source": [
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )   \n",
        "\n",
        "\n",
        "class UNet_7M(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512)        \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2,stride=2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(64, 2, 1,stride=1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "        \n",
        "        x = self.dconv_down4(x)\n",
        "        \n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        \n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)       \n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1)   \n",
        "        \n",
        "        x = self.dconv_up1(x)\n",
        "        \n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet_7M()\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, input_size=(3, 400, 400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 400, 400]           1,792\n",
            "              ReLU-2         [-1, 64, 400, 400]               0\n",
            "            Conv2d-3         [-1, 64, 400, 400]          36,928\n",
            "              ReLU-4         [-1, 64, 400, 400]               0\n",
            "         MaxPool2d-5         [-1, 64, 200, 200]               0\n",
            "            Conv2d-6        [-1, 128, 200, 200]          73,856\n",
            "              ReLU-7        [-1, 128, 200, 200]               0\n",
            "            Conv2d-8        [-1, 128, 200, 200]         147,584\n",
            "              ReLU-9        [-1, 128, 200, 200]               0\n",
            "        MaxPool2d-10        [-1, 128, 100, 100]               0\n",
            "           Conv2d-11        [-1, 256, 100, 100]         295,168\n",
            "             ReLU-12        [-1, 256, 100, 100]               0\n",
            "           Conv2d-13        [-1, 256, 100, 100]         590,080\n",
            "             ReLU-14        [-1, 256, 100, 100]               0\n",
            "        MaxPool2d-15          [-1, 256, 50, 50]               0\n",
            "           Conv2d-16          [-1, 512, 50, 50]       1,180,160\n",
            "             ReLU-17          [-1, 512, 50, 50]               0\n",
            "           Conv2d-18          [-1, 512, 50, 50]       2,359,808\n",
            "             ReLU-19          [-1, 512, 50, 50]               0\n",
            "         Upsample-20        [-1, 512, 100, 100]               0\n",
            "           Conv2d-21        [-1, 256, 100, 100]       1,769,728\n",
            "             ReLU-22        [-1, 256, 100, 100]               0\n",
            "           Conv2d-23        [-1, 256, 100, 100]         590,080\n",
            "             ReLU-24        [-1, 256, 100, 100]               0\n",
            "         Upsample-25        [-1, 256, 200, 200]               0\n",
            "           Conv2d-26        [-1, 128, 200, 200]         442,496\n",
            "             ReLU-27        [-1, 128, 200, 200]               0\n",
            "           Conv2d-28        [-1, 128, 200, 200]         147,584\n",
            "             ReLU-29        [-1, 128, 200, 200]               0\n",
            "         Upsample-30        [-1, 128, 400, 400]               0\n",
            "           Conv2d-31         [-1, 64, 400, 400]         110,656\n",
            "             ReLU-32         [-1, 64, 400, 400]               0\n",
            "           Conv2d-33         [-1, 64, 400, 400]          36,928\n",
            "             ReLU-34         [-1, 64, 400, 400]               0\n",
            "           Conv2d-35          [-1, 2, 400, 400]             130\n",
            "================================================================\n",
            "Total params: 7,782,978\n",
            "Trainable params: 7,782,978\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.83\n",
            "Forward/backward pass size (MB): 1442.87\n",
            "Params size (MB): 29.69\n",
            "Estimated Total Size (MB): 1474.39\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7u8EKO4Rq5v",
        "colab_type": "text"
      },
      "source": [
        "# **Information to be set**\n",
        "\n",
        "Requires input from the user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfMgSTnNcA_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "picking_architecture = 4 #required user input to choose architecture from 0 to 4\n",
        "n_class =2 # enter the number of class here\n",
        "num_epochs =50 # enter number of epochs\n",
        "\n",
        "unetslist = [unet_5k(),unet_50k(),unet_100k(),UNet_3M(),UNet_7M()] # to select the model to train\n",
        "unetsavelist = [\"unet_5k_city.pth\",\"unet_50k_city.pth\",\"unet_100k_city.pth\",\"UNet_3M_city.pth\",\"UNet_7M_city.pth\"] # to save the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCaHcT5FGJ2A",
        "colab_type": "text"
      },
      "source": [
        "**Load the pretrained dataset here if available**\n",
        "\n",
        "**Note:**\n",
        "\n",
        "* Ensure the directory is correct to search the .pth file\n",
        "* Ensure correct name for .pth file matching the choosen model architecture\n",
        "* If architecture matched we will see: **All keys matched successfully**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DWLQzhP6R6-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a26e2b9f-b361-4ca2-a737-a3256f1d7774"
      },
      "source": [
        "unet.load_state_dict(torch.load(os.path.join(\"/content/drive/My Drive/Dataset/PennFudanPed/\",\"UNet_7M.pth\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EFpcYBjDR-Cj"
      },
      "source": [
        "**Function for splitting the masking labels to channel required for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFRko-M7SBQN",
        "colab": {}
      },
      "source": [
        "def label_split(labels,targetimage,n_class):\n",
        "  for i in range(n_class):\n",
        "    if i==0:\n",
        "      labels[:,0,:,:] = (targetimage== 0)==1\n",
        "    else:\n",
        "        labels[:,i,:,:] = (targetimage!= i)==0\n",
        "  return labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4I24zkUtiC2z"
      },
      "source": [
        "# **Loss function**\n",
        "\n",
        "**Using Dice loss with BCE loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPDjEYWyFqGk",
        "colab_type": "text"
      },
      "source": [
        "**Dice loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE55kSZOdy4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_loss(pred, target, smooth = 1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    \n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_PF1ZYU9Skx0"
      },
      "source": [
        "**Dice loss function with BCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Li3KfDCO7Hj0",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "\n",
        "def calc_loss(pred, target, bce_weight=0.5):\n",
        "    bce = func.binary_cross_entropy_with_logits(pred, target).type(dtype)\n",
        "\n",
        "    pred = torch.sigmoid(pred).type(dtype)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PVQNAWAzuAcg"
      },
      "source": [
        "# **Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2yPl3bd5unlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "128bd1ff-8dee-41cd-91b1-d48c6214728d"
      },
      "source": [
        "unet = unetslist[picking_architecture]\n",
        "print(\"Architecture choosen with parameters: \" + str(sum(p.numel() for p in unet.parameters())))\n",
        "gpu_available = torch.cuda.is_available() \n",
        "if gpu_available:\n",
        "    unet = unet.cuda()\n",
        "    \n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, unet.parameters()), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture choosen with parameters: 7782978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uO9XD-PmvnZN"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qc_y4T9mvqPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9f89e3c-715d-441f-c725-fd26a86be4e4"
      },
      "source": [
        "loss_values =[]\n",
        "running_loss = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "\n",
        "    scheduler.step()\n",
        "    for param_group in optimizer.param_groups:\n",
        "      print(\"LR\", param_group['lr'])\n",
        "\n",
        "    for i, data in enumerate(dataloaders['train']):\n",
        "        inputimage, targetimage = data\n",
        "        if gpu_available:\n",
        "            inputimage = inputimage.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = unet(inputimage)\n",
        "      \n",
        "\n",
        "        labels = torch.empty_like(outputs)\n",
        "        lab_channel = (label_split(labels,targetimage.squeeze(1),n_class)).cuda()\n",
        "\n",
        "\n",
        "        loss = calc_loss(outputs,lab_channel)\n",
        "\n",
        "        #loss += lmbd * reg_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % 10 == 9:\n",
        "            print('[%d, %5d] loss: %.10f' %(epoch + 1, i + 1, running_loss / 100))\n",
        "            loss_values.append(running_loss / 170)\n",
        "            running_loss = 0.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "LR 0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.0579832333\n",
            "[1,    20] loss: 0.0319376069\n",
            "[1,    30] loss: 0.0302089819\n",
            "[1,    40] loss: 0.0288808119\n",
            "[1,    50] loss: 0.0283103862\n",
            "[1,    60] loss: 0.0301215154\n",
            "[1,    70] loss: 0.0301306060\n",
            "[1,    80] loss: 0.0291834939\n",
            "[1,    90] loss: 0.0311216304\n",
            "[1,   100] loss: 0.0297596332\n",
            "[1,   110] loss: 0.0286186182\n",
            "[1,   120] loss: 0.0299234685\n",
            "[1,   130] loss: 0.0297481647\n",
            "[1,   140] loss: 0.0307950711\n",
            "[1,   150] loss: 0.0280389518\n",
            "[1,   160] loss: 0.0288383475\n",
            "[1,   170] loss: 0.0284469438\n",
            "[1,   180] loss: 0.0281965259\n",
            "[1,   190] loss: 0.0283464131\n",
            "[1,   200] loss: 0.0270741469\n",
            "[1,   210] loss: 0.0294692191\n",
            "[1,   220] loss: 0.0304292738\n",
            "[1,   230] loss: 0.0280255347\n",
            "[1,   240] loss: 0.0278291601\n",
            "[1,   250] loss: 0.0288405958\n",
            "[1,   260] loss: 0.0268846560\n",
            "[1,   270] loss: 0.0276133734\n",
            "[1,   280] loss: 0.0278756407\n",
            "[1,   290] loss: 0.0283010018\n",
            "Epoch 1/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[2,    10] loss: 0.0487054385\n",
            "[2,    20] loss: 0.0261500880\n",
            "[2,    30] loss: 0.0259626059\n",
            "[2,    40] loss: 0.0256830245\n",
            "[2,    50] loss: 0.0251865272\n",
            "[2,    60] loss: 0.0295842968\n",
            "[2,    70] loss: 0.0280623083\n",
            "[2,    80] loss: 0.0268779284\n",
            "[2,    90] loss: 0.0274150681\n",
            "[2,   100] loss: 0.0264930633\n",
            "[2,   110] loss: 0.0256795450\n",
            "[2,   120] loss: 0.0260249119\n",
            "[2,   130] loss: 0.0264474034\n",
            "[2,   140] loss: 0.0258304760\n",
            "[2,   150] loss: 0.0259446445\n",
            "[2,   160] loss: 0.0265978436\n",
            "[2,   170] loss: 0.0251047006\n",
            "[2,   180] loss: 0.0253916302\n",
            "[2,   190] loss: 0.0234376030\n",
            "[2,   200] loss: 0.0242863987\n",
            "[2,   210] loss: 0.0239079151\n",
            "[2,   220] loss: 0.0260527863\n",
            "[2,   230] loss: 0.0260734746\n",
            "[2,   240] loss: 0.0233619739\n",
            "[2,   250] loss: 0.0254814045\n",
            "[2,   260] loss: 0.0251049745\n",
            "[2,   270] loss: 0.0244281030\n",
            "[2,   280] loss: 0.0242667158\n",
            "[2,   290] loss: 0.0246358088\n",
            "Epoch 2/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[3,    10] loss: 0.0441862014\n",
            "[3,    20] loss: 0.0237729776\n",
            "[3,    30] loss: 0.0239794999\n",
            "[3,    40] loss: 0.0241993675\n",
            "[3,    50] loss: 0.0239933862\n",
            "[3,    60] loss: 0.0235735130\n",
            "[3,    70] loss: 0.0243957728\n",
            "[3,    80] loss: 0.0230176263\n",
            "[3,    90] loss: 0.0227153608\n",
            "[3,   100] loss: 0.0237951209\n",
            "[3,   110] loss: 0.0227840750\n",
            "[3,   120] loss: 0.0256773010\n",
            "[3,   130] loss: 0.0242108950\n",
            "[3,   140] loss: 0.0220910186\n",
            "[3,   150] loss: 0.0241737787\n",
            "[3,   160] loss: 0.0232671134\n",
            "[3,   170] loss: 0.0231498130\n",
            "[3,   180] loss: 0.0260387920\n",
            "[3,   190] loss: 0.0224873851\n",
            "[3,   200] loss: 0.0226335754\n",
            "[3,   210] loss: 0.0227655526\n",
            "[3,   220] loss: 0.0241990249\n",
            "[3,   230] loss: 0.0234352912\n",
            "[3,   240] loss: 0.0234434173\n",
            "[3,   250] loss: 0.0229871178\n",
            "[3,   260] loss: 0.0227843142\n",
            "[3,   270] loss: 0.0226333639\n",
            "[3,   280] loss: 0.0227068427\n",
            "[3,   290] loss: 0.0220161624\n",
            "Epoch 3/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[4,    10] loss: 0.0410096735\n",
            "[4,    20] loss: 0.0219340108\n",
            "[4,    30] loss: 0.0203880945\n",
            "[4,    40] loss: 0.0220828809\n",
            "[4,    50] loss: 0.0218944450\n",
            "[4,    60] loss: 0.0236381114\n",
            "[4,    70] loss: 0.0219459571\n",
            "[4,    80] loss: 0.0217008288\n",
            "[4,    90] loss: 0.0228951147\n",
            "[4,   100] loss: 0.0240468548\n",
            "[4,   110] loss: 0.0206321882\n",
            "[4,   120] loss: 0.0217621227\n",
            "[4,   130] loss: 0.0213871227\n",
            "[4,   140] loss: 0.0225091496\n",
            "[4,   150] loss: 0.0203367791\n",
            "[4,   160] loss: 0.0228159370\n",
            "[4,   170] loss: 0.0207549140\n",
            "[4,   180] loss: 0.0213095267\n",
            "[4,   190] loss: 0.0203498618\n",
            "[4,   200] loss: 0.0200714223\n",
            "[4,   210] loss: 0.0205507900\n",
            "[4,   220] loss: 0.0218028444\n",
            "[4,   230] loss: 0.0212462349\n",
            "[4,   240] loss: 0.0201522732\n",
            "[4,   250] loss: 0.0216181849\n",
            "[4,   260] loss: 0.0209510328\n",
            "[4,   270] loss: 0.0197283266\n",
            "[4,   280] loss: 0.0229891707\n",
            "[4,   290] loss: 0.0207333188\n",
            "Epoch 4/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[5,    10] loss: 0.0389591299\n",
            "[5,    20] loss: 0.0218978857\n",
            "[5,    30] loss: 0.0212575884\n",
            "[5,    40] loss: 0.0188941254\n",
            "[5,    50] loss: 0.0201613772\n",
            "[5,    60] loss: 0.0199482681\n",
            "[5,    70] loss: 0.0192795743\n",
            "[5,    80] loss: 0.0209189677\n",
            "[5,    90] loss: 0.0194922166\n",
            "[5,   100] loss: 0.0193708493\n",
            "[5,   110] loss: 0.0201136211\n",
            "[5,   120] loss: 0.0197094147\n",
            "[5,   130] loss: 0.0188332534\n",
            "[5,   140] loss: 0.0206692633\n",
            "[5,   150] loss: 0.0183878833\n",
            "[5,   160] loss: 0.0199111111\n",
            "[5,   170] loss: 0.0203221488\n",
            "[5,   180] loss: 0.0240006135\n",
            "[5,   190] loss: 0.0224000221\n",
            "[5,   200] loss: 0.0196670489\n",
            "[5,   210] loss: 0.0191211082\n",
            "[5,   220] loss: 0.0217078617\n",
            "[5,   230] loss: 0.0204432172\n",
            "[5,   240] loss: 0.0196562809\n",
            "[5,   250] loss: 0.0207693334\n",
            "[5,   260] loss: 0.0205036484\n",
            "[5,   270] loss: 0.0196693546\n",
            "[5,   280] loss: 0.0188838427\n",
            "[5,   290] loss: 0.0186047031\n",
            "Epoch 5/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[6,    10] loss: 0.0347914402\n",
            "[6,    20] loss: 0.0198603319\n",
            "[6,    30] loss: 0.0197479887\n",
            "[6,    40] loss: 0.0190856948\n",
            "[6,    50] loss: 0.0182153399\n",
            "[6,    60] loss: 0.0200643998\n",
            "[6,    70] loss: 0.0189423344\n",
            "[6,    80] loss: 0.0193324110\n",
            "[6,    90] loss: 0.0197546978\n",
            "[6,   100] loss: 0.0194028366\n",
            "[6,   110] loss: 0.0187837712\n",
            "[6,   120] loss: 0.0203985269\n",
            "[6,   130] loss: 0.0203141388\n",
            "[6,   140] loss: 0.0206555876\n",
            "[6,   150] loss: 0.0206486148\n",
            "[6,   160] loss: 0.0197074959\n",
            "[6,   170] loss: 0.0200754200\n",
            "[6,   180] loss: 0.0192354125\n",
            "[6,   190] loss: 0.0206259842\n",
            "[6,   200] loss: 0.0181820433\n",
            "[6,   210] loss: 0.0187009898\n",
            "[6,   220] loss: 0.0191099159\n",
            "[6,   230] loss: 0.0184256063\n",
            "[6,   240] loss: 0.0181290814\n",
            "[6,   250] loss: 0.0178248887\n",
            "[6,   260] loss: 0.0192571366\n",
            "[6,   270] loss: 0.0174674848\n",
            "[6,   280] loss: 0.0184676746\n",
            "[6,   290] loss: 0.0184918228\n",
            "Epoch 6/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[7,    10] loss: 0.0327109002\n",
            "[7,    20] loss: 0.0191407135\n",
            "[7,    30] loss: 0.0184691921\n",
            "[7,    40] loss: 0.0179453623\n",
            "[7,    50] loss: 0.0184481549\n",
            "[7,    60] loss: 0.0195543066\n",
            "[7,    70] loss: 0.0192960222\n",
            "[7,    80] loss: 0.0173686695\n",
            "[7,    90] loss: 0.0174050069\n",
            "[7,   100] loss: 0.0171559432\n",
            "[7,   110] loss: 0.0173178187\n",
            "[7,   120] loss: 0.0170447174\n",
            "[7,   130] loss: 0.0186794186\n",
            "[7,   140] loss: 0.0176110655\n",
            "[7,   150] loss: 0.0179186272\n",
            "[7,   160] loss: 0.0181131007\n",
            "[7,   170] loss: 0.0166041864\n",
            "[7,   180] loss: 0.0187428741\n",
            "[7,   190] loss: 0.0181435572\n",
            "[7,   200] loss: 0.0195857397\n",
            "[7,   210] loss: 0.0199899068\n",
            "[7,   220] loss: 0.0189283364\n",
            "[7,   230] loss: 0.0193163234\n",
            "[7,   240] loss: 0.0170034158\n",
            "[7,   250] loss: 0.0206355195\n",
            "[7,   260] loss: 0.0203985088\n",
            "[7,   270] loss: 0.0185756430\n",
            "[7,   280] loss: 0.0203274773\n",
            "[7,   290] loss: 0.0200726533\n",
            "Epoch 7/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[8,    10] loss: 0.0301083592\n",
            "[8,    20] loss: 0.0188557008\n",
            "[8,    30] loss: 0.0202294508\n",
            "[8,    40] loss: 0.0180643432\n",
            "[8,    50] loss: 0.0187619124\n",
            "[8,    60] loss: 0.0169030985\n",
            "[8,    70] loss: 0.0169060902\n",
            "[8,    80] loss: 0.0174350688\n",
            "[8,    90] loss: 0.0162402547\n",
            "[8,   100] loss: 0.0166446121\n",
            "[8,   110] loss: 0.0180961806\n",
            "[8,   120] loss: 0.0189413345\n",
            "[8,   130] loss: 0.0169369911\n",
            "[8,   140] loss: 0.0186681017\n",
            "[8,   150] loss: 0.0163212204\n",
            "[8,   160] loss: 0.0163990584\n",
            "[8,   170] loss: 0.0190469892\n",
            "[8,   180] loss: 0.0177910408\n",
            "[8,   190] loss: 0.0171813887\n",
            "[8,   200] loss: 0.0176396679\n",
            "[8,   210] loss: 0.0167692143\n",
            "[8,   220] loss: 0.0162075816\n",
            "[8,   230] loss: 0.0164197165\n",
            "[8,   240] loss: 0.0160325647\n",
            "[8,   250] loss: 0.0149820130\n",
            "[8,   260] loss: 0.0173511901\n",
            "[8,   270] loss: 0.0186428827\n",
            "[8,   280] loss: 0.0176150735\n",
            "[8,   290] loss: 0.0154632378\n",
            "Epoch 8/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[9,    10] loss: 0.0283947451\n",
            "[9,    20] loss: 0.0209120585\n",
            "[9,    30] loss: 0.0172610323\n",
            "[9,    40] loss: 0.0156305870\n",
            "[9,    50] loss: 0.0158509041\n",
            "[9,    60] loss: 0.0165656963\n",
            "[9,    70] loss: 0.0171357422\n",
            "[9,    80] loss: 0.0175062987\n",
            "[9,    90] loss: 0.0177049858\n",
            "[9,   100] loss: 0.0180277069\n",
            "[9,   110] loss: 0.0178717431\n",
            "[9,   120] loss: 0.0190160310\n",
            "[9,   130] loss: 0.0179516555\n",
            "[9,   140] loss: 0.0160635377\n",
            "[9,   150] loss: 0.0169424072\n",
            "[9,   160] loss: 0.0190848377\n",
            "[9,   170] loss: 0.0170827906\n",
            "[9,   180] loss: 0.0171120077\n",
            "[9,   190] loss: 0.0162261412\n",
            "[9,   200] loss: 0.0175660203\n",
            "[9,   210] loss: 0.0154787944\n",
            "[9,   220] loss: 0.0165447891\n",
            "[9,   230] loss: 0.0152591405\n",
            "[9,   240] loss: 0.0153970563\n",
            "[9,   250] loss: 0.0175241604\n",
            "[9,   260] loss: 0.0161498781\n",
            "[9,   270] loss: 0.0160649545\n",
            "[9,   280] loss: 0.0184326521\n",
            "[9,   290] loss: 0.0164325683\n",
            "Epoch 9/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[10,    10] loss: 0.0296853420\n",
            "[10,    20] loss: 0.0155342004\n",
            "[10,    30] loss: 0.0160329349\n",
            "[10,    40] loss: 0.0153330670\n",
            "[10,    50] loss: 0.0162587577\n",
            "[10,    60] loss: 0.0150691107\n",
            "[10,    70] loss: 0.0169508403\n",
            "[10,    80] loss: 0.0173933230\n",
            "[10,    90] loss: 0.0152145810\n",
            "[10,   100] loss: 0.0163491160\n",
            "[10,   110] loss: 0.0141108697\n",
            "[10,   120] loss: 0.0157656837\n",
            "[10,   130] loss: 0.0167480412\n",
            "[10,   140] loss: 0.0148839482\n",
            "[10,   150] loss: 0.0153215683\n",
            "[10,   160] loss: 0.0167685629\n",
            "[10,   170] loss: 0.0170517687\n",
            "[10,   180] loss: 0.0168560006\n",
            "[10,   190] loss: 0.0171565361\n",
            "[10,   200] loss: 0.0177515186\n",
            "[10,   210] loss: 0.0184888384\n",
            "[10,   220] loss: 0.0169997028\n",
            "[10,   230] loss: 0.0158824085\n",
            "[10,   240] loss: 0.0186852682\n",
            "[10,   250] loss: 0.0172638689\n",
            "[10,   260] loss: 0.0169494060\n",
            "[10,   270] loss: 0.0171704282\n",
            "[10,   280] loss: 0.0153673655\n",
            "[10,   290] loss: 0.0163847077\n",
            "Epoch 10/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[11,    10] loss: 0.0270878842\n",
            "[11,    20] loss: 0.0179209429\n",
            "[11,    30] loss: 0.0158093324\n",
            "[11,    40] loss: 0.0149768829\n",
            "[11,    50] loss: 0.0156278235\n",
            "[11,    60] loss: 0.0165472020\n",
            "[11,    70] loss: 0.0170738983\n",
            "[11,    80] loss: 0.0145364334\n",
            "[11,    90] loss: 0.0172222203\n",
            "[11,   100] loss: 0.0150248718\n",
            "[11,   110] loss: 0.0159317589\n",
            "[11,   120] loss: 0.0143288061\n",
            "[11,   130] loss: 0.0155353028\n",
            "[11,   140] loss: 0.0160639860\n",
            "[11,   150] loss: 0.0153802769\n",
            "[11,   160] loss: 0.0163227110\n",
            "[11,   170] loss: 0.0149223503\n",
            "[11,   180] loss: 0.0160495717\n",
            "[11,   190] loss: 0.0175974938\n",
            "[11,   200] loss: 0.0166080427\n",
            "[11,   210] loss: 0.0149875433\n",
            "[11,   220] loss: 0.0159477681\n",
            "[11,   230] loss: 0.0140000239\n",
            "[11,   240] loss: 0.0152549389\n",
            "[11,   250] loss: 0.0160959987\n",
            "[11,   260] loss: 0.0167065774\n",
            "[11,   270] loss: 0.0155652417\n",
            "[11,   280] loss: 0.0171884346\n",
            "[11,   290] loss: 0.0156506656\n",
            "Epoch 11/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[12,    10] loss: 0.0273685382\n",
            "[12,    20] loss: 0.0156114945\n",
            "[12,    30] loss: 0.0143193744\n",
            "[12,    40] loss: 0.0150303690\n",
            "[12,    50] loss: 0.0148751518\n",
            "[12,    60] loss: 0.0147085287\n",
            "[12,    70] loss: 0.0153933911\n",
            "[12,    80] loss: 0.0149400666\n",
            "[12,    90] loss: 0.0129365707\n",
            "[12,   100] loss: 0.0145358425\n",
            "[12,   110] loss: 0.0141679998\n",
            "[12,   120] loss: 0.0164626878\n",
            "[12,   130] loss: 0.0160438752\n",
            "[12,   140] loss: 0.0149949376\n",
            "[12,   150] loss: 0.0149016076\n",
            "[12,   160] loss: 0.0143557239\n",
            "[12,   170] loss: 0.0159580040\n",
            "[12,   180] loss: 0.0164874069\n",
            "[12,   190] loss: 0.0131365692\n",
            "[12,   200] loss: 0.0156369158\n",
            "[12,   210] loss: 0.0138823346\n",
            "[12,   220] loss: 0.0149013077\n",
            "[12,   230] loss: 0.0151926412\n",
            "[12,   240] loss: 0.0151454408\n",
            "[12,   250] loss: 0.0143392975\n",
            "[12,   260] loss: 0.0162825617\n",
            "[12,   270] loss: 0.0169293770\n",
            "[12,   280] loss: 0.0157512496\n",
            "[12,   290] loss: 0.0156665177\n",
            "Epoch 12/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[13,    10] loss: 0.0262912451\n",
            "[13,    20] loss: 0.0133463081\n",
            "[13,    30] loss: 0.0137541353\n",
            "[13,    40] loss: 0.0142274021\n",
            "[13,    50] loss: 0.0136380490\n",
            "[13,    60] loss: 0.0147313583\n",
            "[13,    70] loss: 0.0137998475\n",
            "[13,    80] loss: 0.0144595441\n",
            "[13,    90] loss: 0.0133193674\n",
            "[13,   100] loss: 0.0133316103\n",
            "[13,   110] loss: 0.0142158355\n",
            "[13,   120] loss: 0.0176494224\n",
            "[13,   130] loss: 0.0139875691\n",
            "[13,   140] loss: 0.0152758792\n",
            "[13,   150] loss: 0.0140407466\n",
            "[13,   160] loss: 0.0140215399\n",
            "[13,   170] loss: 0.0131885392\n",
            "[13,   180] loss: 0.0146747953\n",
            "[13,   190] loss: 0.0158078423\n",
            "[13,   200] loss: 0.0150540775\n",
            "[13,   210] loss: 0.0167054415\n",
            "[13,   220] loss: 0.0158370952\n",
            "[13,   230] loss: 0.0152163233\n",
            "[13,   240] loss: 0.0170698152\n",
            "[13,   250] loss: 0.0135248224\n",
            "[13,   260] loss: 0.0163292971\n",
            "[13,   270] loss: 0.0137653591\n",
            "[13,   280] loss: 0.0137044595\n",
            "[13,   290] loss: 0.0142288665\n",
            "Epoch 13/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[14,    10] loss: 0.0269170836\n",
            "[14,    20] loss: 0.0152945367\n",
            "[14,    30] loss: 0.0129861418\n",
            "[14,    40] loss: 0.0134878437\n",
            "[14,    50] loss: 0.0142542241\n",
            "[14,    60] loss: 0.0127743302\n",
            "[14,    70] loss: 0.0126665989\n",
            "[14,    80] loss: 0.0136740204\n",
            "[14,    90] loss: 0.0133147568\n",
            "[14,   100] loss: 0.0134861980\n",
            "[14,   110] loss: 0.0134439879\n",
            "[14,   120] loss: 0.0146194581\n",
            "[14,   130] loss: 0.0136631569\n",
            "[14,   140] loss: 0.0157370435\n",
            "[14,   150] loss: 0.0138335059\n",
            "[14,   160] loss: 0.0140769349\n",
            "[14,   170] loss: 0.0137142310\n",
            "[14,   180] loss: 0.0136298686\n",
            "[14,   190] loss: 0.0150118047\n",
            "[14,   200] loss: 0.0143102249\n",
            "[14,   210] loss: 0.0137911373\n",
            "[14,   220] loss: 0.0127156203\n",
            "[14,   230] loss: 0.0153538522\n",
            "[14,   240] loss: 0.0142984562\n",
            "[14,   250] loss: 0.0144189334\n",
            "[14,   260] loss: 0.0123320226\n",
            "[14,   270] loss: 0.0129803687\n",
            "[14,   280] loss: 0.0129633845\n",
            "[14,   290] loss: 0.0141781848\n",
            "Epoch 14/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[15,    10] loss: 0.0249773210\n",
            "[15,    20] loss: 0.0128196840\n",
            "[15,    30] loss: 0.0128664193\n",
            "[15,    40] loss: 0.0126393940\n",
            "[15,    50] loss: 0.0139674394\n",
            "[15,    60] loss: 0.0122356679\n",
            "[15,    70] loss: 0.0121390241\n",
            "[15,    80] loss: 0.0147670440\n",
            "[15,    90] loss: 0.0136432148\n",
            "[15,   100] loss: 0.0130177183\n",
            "[15,   110] loss: 0.0147560897\n",
            "[15,   120] loss: 0.0130423672\n",
            "[15,   130] loss: 0.0143040426\n",
            "[15,   140] loss: 0.0141147950\n",
            "[15,   150] loss: 0.0135801934\n",
            "[15,   160] loss: 0.0139753845\n",
            "[15,   170] loss: 0.0148560746\n",
            "[15,   180] loss: 0.0147151729\n",
            "[15,   190] loss: 0.0142798441\n",
            "[15,   200] loss: 0.0123765881\n",
            "[15,   210] loss: 0.0129412240\n",
            "[15,   220] loss: 0.0142735146\n",
            "[15,   230] loss: 0.0133373149\n",
            "[15,   240] loss: 0.0127869230\n",
            "[15,   250] loss: 0.0134479310\n",
            "[15,   260] loss: 0.0157924503\n",
            "[15,   270] loss: 0.0167083001\n",
            "[15,   280] loss: 0.0159665009\n",
            "[15,   290] loss: 0.0122685586\n",
            "Epoch 15/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[16,    10] loss: 0.0231636682\n",
            "[16,    20] loss: 0.0133710435\n",
            "[16,    30] loss: 0.0132859561\n",
            "[16,    40] loss: 0.0129661312\n",
            "[16,    50] loss: 0.0127832647\n",
            "[16,    60] loss: 0.0124703323\n",
            "[16,    70] loss: 0.0132698949\n",
            "[16,    80] loss: 0.0127974590\n",
            "[16,    90] loss: 0.0127071770\n",
            "[16,   100] loss: 0.0122508282\n",
            "[16,   110] loss: 0.0129088426\n",
            "[16,   120] loss: 0.0125487129\n",
            "[16,   130] loss: 0.0130286558\n",
            "[16,   140] loss: 0.0117831990\n",
            "[16,   150] loss: 0.0124685445\n",
            "[16,   160] loss: 0.0136147298\n",
            "[16,   170] loss: 0.0146997533\n",
            "[16,   180] loss: 0.0114592949\n",
            "[16,   190] loss: 0.0136590590\n",
            "[16,   200] loss: 0.0137908515\n",
            "[16,   210] loss: 0.0137446116\n",
            "[16,   220] loss: 0.0122602759\n",
            "[16,   230] loss: 0.0130043247\n",
            "[16,   240] loss: 0.0131184296\n",
            "[16,   250] loss: 0.0146264268\n",
            "[16,   260] loss: 0.0137000372\n",
            "[16,   270] loss: 0.0126388175\n",
            "[16,   280] loss: 0.0125218037\n",
            "[16,   290] loss: 0.0127534651\n",
            "Epoch 16/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[17,    10] loss: 0.0225768230\n",
            "[17,    20] loss: 0.0119465367\n",
            "[17,    30] loss: 0.0130502210\n",
            "[17,    40] loss: 0.0122339036\n",
            "[17,    50] loss: 0.0116427083\n",
            "[17,    60] loss: 0.0117711695\n",
            "[17,    70] loss: 0.0132711034\n",
            "[17,    80] loss: 0.0113560244\n",
            "[17,    90] loss: 0.0134165046\n",
            "[17,   100] loss: 0.0117332012\n",
            "[17,   110] loss: 0.0129137704\n",
            "[17,   120] loss: 0.0112633152\n",
            "[17,   130] loss: 0.0123582695\n",
            "[17,   140] loss: 0.0139553002\n",
            "[17,   150] loss: 0.0132697482\n",
            "[17,   160] loss: 0.0144976243\n",
            "[17,   170] loss: 0.0140139566\n",
            "[17,   180] loss: 0.0127439667\n",
            "[17,   190] loss: 0.0122967321\n",
            "[17,   200] loss: 0.0120405103\n",
            "[17,   210] loss: 0.0115711239\n",
            "[17,   220] loss: 0.0131671730\n",
            "[17,   230] loss: 0.0128547982\n",
            "[17,   240] loss: 0.0112750172\n",
            "[17,   250] loss: 0.0117680875\n",
            "[17,   260] loss: 0.0128129152\n",
            "[17,   270] loss: 0.0131612529\n",
            "[17,   280] loss: 0.0131232540\n",
            "[17,   290] loss: 0.0122575309\n",
            "Epoch 17/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[18,    10] loss: 0.0231685726\n",
            "[18,    20] loss: 0.0124227804\n",
            "[18,    30] loss: 0.0111797733\n",
            "[18,    40] loss: 0.0135184807\n",
            "[18,    50] loss: 0.0131668595\n",
            "[18,    60] loss: 0.0114324912\n",
            "[18,    70] loss: 0.0132130545\n",
            "[18,    80] loss: 0.0115391130\n",
            "[18,    90] loss: 0.0105893116\n",
            "[18,   100] loss: 0.0112020730\n",
            "[18,   110] loss: 0.0113861095\n",
            "[18,   120] loss: 0.0108427387\n",
            "[18,   130] loss: 0.0150697590\n",
            "[18,   140] loss: 0.0114172612\n",
            "[18,   150] loss: 0.0103937453\n",
            "[18,   160] loss: 0.0101562732\n",
            "[18,   170] loss: 0.0115004566\n",
            "[18,   180] loss: 0.0111962533\n",
            "[18,   190] loss: 0.0117938086\n",
            "[18,   200] loss: 0.0111186370\n",
            "[18,   210] loss: 0.0129883807\n",
            "[18,   220] loss: 0.0126119161\n",
            "[18,   230] loss: 0.0127991775\n",
            "[18,   240] loss: 0.0114284027\n",
            "[18,   250] loss: 0.0135766831\n",
            "[18,   260] loss: 0.0130802852\n",
            "[18,   270] loss: 0.0129272889\n",
            "[18,   280] loss: 0.0126505198\n",
            "[18,   290] loss: 0.0113011519\n",
            "Epoch 18/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[19,    10] loss: 0.0196465851\n",
            "[19,    20] loss: 0.0095120066\n",
            "[19,    30] loss: 0.0109272108\n",
            "[19,    40] loss: 0.0121819998\n",
            "[19,    50] loss: 0.0118219049\n",
            "[19,    60] loss: 0.0133760203\n",
            "[19,    70] loss: 0.0129453123\n",
            "[19,    80] loss: 0.0106241037\n",
            "[19,    90] loss: 0.0128771100\n",
            "[19,   100] loss: 0.0126658355\n",
            "[19,   110] loss: 0.0121340598\n",
            "[19,   120] loss: 0.0112694111\n",
            "[19,   130] loss: 0.0168143715\n",
            "[19,   140] loss: 0.0141782164\n",
            "[19,   150] loss: 0.0138563010\n",
            "[19,   160] loss: 0.0130406692\n",
            "[19,   170] loss: 0.0121609005\n",
            "[19,   180] loss: 0.0118943295\n",
            "[19,   190] loss: 0.0120419070\n",
            "[19,   200] loss: 0.0122736204\n",
            "[19,   210] loss: 0.0116869236\n",
            "[19,   220] loss: 0.0117072966\n",
            "[19,   230] loss: 0.0119078364\n",
            "[19,   240] loss: 0.0109040000\n",
            "[19,   250] loss: 0.0115009207\n",
            "[19,   260] loss: 0.0114762934\n",
            "[19,   270] loss: 0.0105158455\n",
            "[19,   280] loss: 0.0123687124\n",
            "[19,   290] loss: 0.0131312583\n",
            "Epoch 19/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[20,    10] loss: 0.0204010752\n",
            "[20,    20] loss: 0.0104125616\n",
            "[20,    30] loss: 0.0105888421\n",
            "[20,    40] loss: 0.0111185455\n",
            "[20,    50] loss: 0.0114531640\n",
            "[20,    60] loss: 0.0085434214\n",
            "[20,    70] loss: 0.0103837791\n",
            "[20,    80] loss: 0.0095600606\n",
            "[20,    90] loss: 0.0120099227\n",
            "[20,   100] loss: 0.0114217253\n",
            "[20,   110] loss: 0.0123350935\n",
            "[20,   120] loss: 0.0122120807\n",
            "[20,   130] loss: 0.0131403971\n",
            "[20,   140] loss: 0.0113624790\n",
            "[20,   150] loss: 0.0106277920\n",
            "[20,   160] loss: 0.0117735370\n",
            "[20,   170] loss: 0.0105080296\n",
            "[20,   180] loss: 0.0111997362\n",
            "[20,   190] loss: 0.0107894916\n",
            "[20,   200] loss: 0.0109028993\n",
            "[20,   210] loss: 0.0110566396\n",
            "[20,   220] loss: 0.0110284383\n",
            "[20,   230] loss: 0.0141493488\n",
            "[20,   240] loss: 0.0114385752\n",
            "[20,   250] loss: 0.0099354298\n",
            "[20,   260] loss: 0.0119505958\n",
            "[20,   270] loss: 0.0107629706\n",
            "[20,   280] loss: 0.0130732188\n",
            "[20,   290] loss: 0.0112413504\n",
            "Epoch 20/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[21,    10] loss: 0.0205753621\n",
            "[21,    20] loss: 0.0114981309\n",
            "[21,    30] loss: 0.0118089328\n",
            "[21,    40] loss: 0.0115360732\n",
            "[21,    50] loss: 0.0119391042\n",
            "[21,    60] loss: 0.0104509337\n",
            "[21,    70] loss: 0.0114183745\n",
            "[21,    80] loss: 0.0102277748\n",
            "[21,    90] loss: 0.0128161823\n",
            "[21,   100] loss: 0.0105820268\n",
            "[21,   110] loss: 0.0113924372\n",
            "[21,   120] loss: 0.0102881304\n",
            "[21,   130] loss: 0.0106974782\n",
            "[21,   140] loss: 0.0106171928\n",
            "[21,   150] loss: 0.0101707327\n",
            "[21,   160] loss: 0.0101570440\n",
            "[21,   170] loss: 0.0113399113\n",
            "[21,   180] loss: 0.0102882207\n",
            "[21,   190] loss: 0.0106076360\n",
            "[21,   200] loss: 0.0115628709\n",
            "[21,   210] loss: 0.0116595656\n",
            "[21,   220] loss: 0.0108785796\n",
            "[21,   230] loss: 0.0112430431\n",
            "[21,   240] loss: 0.0105595122\n",
            "[21,   250] loss: 0.0107637735\n",
            "[21,   260] loss: 0.0106074664\n",
            "[21,   270] loss: 0.0113735488\n",
            "[21,   280] loss: 0.0113175207\n",
            "[21,   290] loss: 0.0100276946\n",
            "Epoch 21/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[22,    10] loss: 0.0182868171\n",
            "[22,    20] loss: 0.0100908290\n",
            "[22,    30] loss: 0.0096368502\n",
            "[22,    40] loss: 0.0105093616\n",
            "[22,    50] loss: 0.0107084400\n",
            "[22,    60] loss: 0.0103745082\n",
            "[22,    70] loss: 0.0107062208\n",
            "[22,    80] loss: 0.0112981658\n",
            "[22,    90] loss: 0.0113111352\n",
            "[22,   100] loss: 0.0101851729\n",
            "[22,   110] loss: 0.0111664611\n",
            "[22,   120] loss: 0.0100810952\n",
            "[22,   130] loss: 0.0098258644\n",
            "[22,   140] loss: 0.0109939975\n",
            "[22,   150] loss: 0.0124508744\n",
            "[22,   160] loss: 0.0094366013\n",
            "[22,   170] loss: 0.0100403596\n",
            "[22,   180] loss: 0.0110104375\n",
            "[22,   190] loss: 0.0104715913\n",
            "[22,   200] loss: 0.0123632988\n",
            "[22,   210] loss: 0.0099095513\n",
            "[22,   220] loss: 0.0108093012\n",
            "[22,   230] loss: 0.0122939035\n",
            "[22,   240] loss: 0.0101517446\n",
            "[22,   250] loss: 0.0104268458\n",
            "[22,   260] loss: 0.0090755027\n",
            "[22,   270] loss: 0.0085546581\n",
            "[22,   280] loss: 0.0097827925\n",
            "[22,   290] loss: 0.0105826161\n",
            "Epoch 22/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[23,    10] loss: 0.0190204883\n",
            "[23,    20] loss: 0.0119192780\n",
            "[23,    30] loss: 0.0106413605\n",
            "[23,    40] loss: 0.0100986877\n",
            "[23,    50] loss: 0.0098779111\n",
            "[23,    60] loss: 0.0085440645\n",
            "[23,    70] loss: 0.0104112867\n",
            "[23,    80] loss: 0.0099379086\n",
            "[23,    90] loss: 0.0103616945\n",
            "[23,   100] loss: 0.0095291808\n",
            "[23,   110] loss: 0.0107138868\n",
            "[23,   120] loss: 0.0104807165\n",
            "[23,   130] loss: 0.0095399256\n",
            "[23,   140] loss: 0.0103372064\n",
            "[23,   150] loss: 0.0087537009\n",
            "[23,   160] loss: 0.0108736604\n",
            "[23,   170] loss: 0.0094974249\n",
            "[23,   180] loss: 0.0109913860\n",
            "[23,   190] loss: 0.0098579319\n",
            "[23,   200] loss: 0.0097710177\n",
            "[23,   210] loss: 0.0105992977\n",
            "[23,   220] loss: 0.0096004219\n",
            "[23,   230] loss: 0.0090076821\n",
            "[23,   240] loss: 0.0115146845\n",
            "[23,   250] loss: 0.0148991389\n",
            "[23,   260] loss: 0.0114144106\n",
            "[23,   270] loss: 0.0117836239\n",
            "[23,   280] loss: 0.0107912206\n",
            "[23,   290] loss: 0.0110428821\n",
            "Epoch 23/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[24,    10] loss: 0.0177633593\n",
            "[24,    20] loss: 0.0107766902\n",
            "[24,    30] loss: 0.0108745893\n",
            "[24,    40] loss: 0.0097899532\n",
            "[24,    50] loss: 0.0101761247\n",
            "[24,    60] loss: 0.0101386350\n",
            "[24,    70] loss: 0.0087083732\n",
            "[24,    80] loss: 0.0104244394\n",
            "[24,    90] loss: 0.0088306523\n",
            "[24,   100] loss: 0.0092325336\n",
            "[24,   110] loss: 0.0091045143\n",
            "[24,   120] loss: 0.0096961831\n",
            "[24,   130] loss: 0.0108064078\n",
            "[24,   140] loss: 0.0108416833\n",
            "[24,   150] loss: 0.0089455185\n",
            "[24,   160] loss: 0.0098289960\n",
            "[24,   170] loss: 0.0086113786\n",
            "[24,   180] loss: 0.0076387466\n",
            "[24,   190] loss: 0.0104567217\n",
            "[24,   200] loss: 0.0110929996\n",
            "[24,   210] loss: 0.0099601231\n",
            "[24,   220] loss: 0.0107171721\n",
            "[24,   230] loss: 0.0100294717\n",
            "[24,   240] loss: 0.0102019505\n",
            "[24,   250] loss: 0.0099822602\n",
            "[24,   260] loss: 0.0098104326\n",
            "[24,   270] loss: 0.0096181299\n",
            "[24,   280] loss: 0.0094728089\n",
            "[24,   290] loss: 0.0095213990\n",
            "Epoch 24/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[25,    10] loss: 0.0172914946\n",
            "[25,    20] loss: 0.0093676763\n",
            "[25,    30] loss: 0.0096129099\n",
            "[25,    40] loss: 0.0085686537\n",
            "[25,    50] loss: 0.0096456541\n",
            "[25,    60] loss: 0.0094894914\n",
            "[25,    70] loss: 0.0093028055\n",
            "[25,    80] loss: 0.0096692317\n",
            "[25,    90] loss: 0.0091046475\n",
            "[25,   100] loss: 0.0097432825\n",
            "[25,   110] loss: 0.0106914697\n",
            "[25,   120] loss: 0.0090191104\n",
            "[25,   130] loss: 0.0081428839\n",
            "[25,   140] loss: 0.0094745470\n",
            "[25,   150] loss: 0.0102188911\n",
            "[25,   160] loss: 0.0084699589\n",
            "[25,   170] loss: 0.0099973757\n",
            "[25,   180] loss: 0.0087727543\n",
            "[25,   190] loss: 0.0086716318\n",
            "[25,   200] loss: 0.0082156419\n",
            "[25,   210] loss: 0.0087793570\n",
            "[25,   220] loss: 0.0085820910\n",
            "[25,   230] loss: 0.0090614361\n",
            "[25,   240] loss: 0.0100499985\n",
            "[25,   250] loss: 0.0105711026\n",
            "[25,   260] loss: 0.0087392324\n",
            "[25,   270] loss: 0.0098309974\n",
            "[25,   280] loss: 0.0115202624\n",
            "[25,   290] loss: 0.0106479235\n",
            "Epoch 25/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[26,    10] loss: 0.0165443224\n",
            "[26,    20] loss: 0.0091004057\n",
            "[26,    30] loss: 0.0084576641\n",
            "[26,    40] loss: 0.0084367798\n",
            "[26,    50] loss: 0.0083835114\n",
            "[26,    60] loss: 0.0088532778\n",
            "[26,    70] loss: 0.0088821562\n",
            "[26,    80] loss: 0.0087485350\n",
            "[26,    90] loss: 0.0077361559\n",
            "[26,   100] loss: 0.0070493715\n",
            "[26,   110] loss: 0.0079304456\n",
            "[26,   120] loss: 0.0097054049\n",
            "[26,   130] loss: 0.0093148316\n",
            "[26,   140] loss: 0.0091747742\n",
            "[26,   150] loss: 0.0088874081\n",
            "[26,   160] loss: 0.0084605810\n",
            "[26,   170] loss: 0.0090993050\n",
            "[26,   180] loss: 0.0108954000\n",
            "[26,   190] loss: 0.0097289454\n",
            "[26,   200] loss: 0.0087207450\n",
            "[26,   210] loss: 0.0105317983\n",
            "[26,   220] loss: 0.0083722775\n",
            "[26,   230] loss: 0.0090709908\n",
            "[26,   240] loss: 0.0081289291\n",
            "[26,   250] loss: 0.0086897944\n",
            "[26,   260] loss: 0.0087302088\n",
            "[26,   270] loss: 0.0087802405\n",
            "[26,   280] loss: 0.0084690152\n",
            "[26,   290] loss: 0.0093375833\n",
            "Epoch 26/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[27,    10] loss: 0.0158702061\n",
            "[27,    20] loss: 0.0079276614\n",
            "[27,    30] loss: 0.0084867748\n",
            "[27,    40] loss: 0.0078816157\n",
            "[27,    50] loss: 0.0085787210\n",
            "[27,    60] loss: 0.0094775547\n",
            "[27,    70] loss: 0.0084506111\n",
            "[27,    80] loss: 0.0083079914\n",
            "[27,    90] loss: 0.0093113186\n",
            "[27,   100] loss: 0.0094580062\n",
            "[27,   110] loss: 0.0083609079\n",
            "[27,   120] loss: 0.0079030813\n",
            "[27,   130] loss: 0.0079840739\n",
            "[27,   140] loss: 0.0086433244\n",
            "[27,   150] loss: 0.0086329348\n",
            "[27,   160] loss: 0.0077221968\n",
            "[27,   170] loss: 0.0078541321\n",
            "[27,   180] loss: 0.0108002184\n",
            "[27,   190] loss: 0.0114688019\n",
            "[27,   200] loss: 0.0098266630\n",
            "[27,   210] loss: 0.0085430691\n",
            "[27,   220] loss: 0.0095568785\n",
            "[27,   230] loss: 0.0089081204\n",
            "[27,   240] loss: 0.0095156968\n",
            "[27,   250] loss: 0.0092425737\n",
            "[27,   260] loss: 0.0089100518\n",
            "[27,   270] loss: 0.0090935002\n",
            "[27,   280] loss: 0.0097366524\n",
            "[27,   290] loss: 0.0078285891\n",
            "Epoch 27/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[28,    10] loss: 0.0152961095\n",
            "[28,    20] loss: 0.0095925153\n",
            "[28,    30] loss: 0.0072875248\n",
            "[28,    40] loss: 0.0076739259\n",
            "[28,    50] loss: 0.0082711615\n",
            "[28,    60] loss: 0.0084644063\n",
            "[28,    70] loss: 0.0092605918\n",
            "[28,    80] loss: 0.0083790024\n",
            "[28,    90] loss: 0.0079202502\n",
            "[28,   100] loss: 0.0085858990\n",
            "[28,   110] loss: 0.0079540189\n",
            "[28,   120] loss: 0.0079138164\n",
            "[28,   130] loss: 0.0100283884\n",
            "[28,   140] loss: 0.0077566699\n",
            "[28,   150] loss: 0.0094692200\n",
            "[28,   160] loss: 0.0086388996\n",
            "[28,   170] loss: 0.0084999069\n",
            "[28,   180] loss: 0.0080701562\n",
            "[28,   190] loss: 0.0097099306\n",
            "[28,   200] loss: 0.0077542837\n",
            "[28,   210] loss: 0.0088225081\n",
            "[28,   220] loss: 0.0076856426\n",
            "[28,   230] loss: 0.0087445086\n",
            "[28,   240] loss: 0.0080042405\n",
            "[28,   250] loss: 0.0089974947\n",
            "[28,   260] loss: 0.0075741028\n",
            "[28,   270] loss: 0.0079267571\n",
            "[28,   280] loss: 0.0084083835\n",
            "[28,   290] loss: 0.0080435764\n",
            "Epoch 28/49\n",
            "----------\n",
            "LR 0.0001\n",
            "[29,    10] loss: 0.0146386068\n",
            "[29,    20] loss: 0.0084906381\n",
            "[29,    30] loss: 0.0076777662\n",
            "[29,    40] loss: 0.0080386584\n",
            "[29,    50] loss: 0.0079204400\n",
            "[29,    60] loss: 0.0091002991\n",
            "[29,    70] loss: 0.0076233490\n",
            "[29,    80] loss: 0.0080485770\n",
            "[29,    90] loss: 0.0087662587\n",
            "[29,   100] loss: 0.0090098394\n",
            "[29,   110] loss: 0.0083524650\n",
            "[29,   120] loss: 0.0074444558\n",
            "[29,   130] loss: 0.0073052282\n",
            "[29,   140] loss: 0.0082570146\n",
            "[29,   150] loss: 0.0075366204\n",
            "[29,   160] loss: 0.0096121825\n",
            "[29,   170] loss: 0.0087504965\n",
            "[29,   180] loss: 0.0094721633\n",
            "[29,   190] loss: 0.0085559214\n",
            "[29,   200] loss: 0.0083533491\n",
            "[29,   210] loss: 0.0086137761\n",
            "[29,   220] loss: 0.0078871112\n",
            "[29,   230] loss: 0.0084400404\n",
            "[29,   240] loss: 0.0085092014\n",
            "[29,   250] loss: 0.0072102374\n",
            "[29,   260] loss: 0.0074696839\n",
            "[29,   270] loss: 0.0075153155\n",
            "[29,   280] loss: 0.0075591100\n",
            "[29,   290] loss: 0.0079716349\n",
            "Epoch 29/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[30,    10] loss: 0.0172189602\n",
            "[30,    20] loss: 0.0082141248\n",
            "[30,    30] loss: 0.0074992976\n",
            "[30,    40] loss: 0.0075075868\n",
            "[30,    50] loss: 0.0083693394\n",
            "[30,    60] loss: 0.0066192735\n",
            "[30,    70] loss: 0.0074090703\n",
            "[30,    80] loss: 0.0065646796\n",
            "[30,    90] loss: 0.0073714047\n",
            "[30,   100] loss: 0.0068202765\n",
            "[30,   110] loss: 0.0081664184\n",
            "[30,   120] loss: 0.0077842739\n",
            "[30,   130] loss: 0.0068914000\n",
            "[30,   140] loss: 0.0066112012\n",
            "[30,   150] loss: 0.0074593031\n",
            "[30,   160] loss: 0.0063829176\n",
            "[30,   170] loss: 0.0061649010\n",
            "[30,   180] loss: 0.0074015615\n",
            "[30,   190] loss: 0.0062552626\n",
            "[30,   200] loss: 0.0067533478\n",
            "[30,   210] loss: 0.0082809544\n",
            "[30,   220] loss: 0.0063779680\n",
            "[30,   230] loss: 0.0080216379\n",
            "[30,   240] loss: 0.0065747247\n",
            "[30,   250] loss: 0.0083706226\n",
            "[30,   260] loss: 0.0075538364\n",
            "[30,   270] loss: 0.0066742530\n",
            "[30,   280] loss: 0.0067412749\n",
            "[30,   290] loss: 0.0066389294\n",
            "Epoch 30/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[31,    10] loss: 0.0129402484\n",
            "[31,    20] loss: 0.0072346785\n",
            "[31,    30] loss: 0.0065264228\n",
            "[31,    40] loss: 0.0072739490\n",
            "[31,    50] loss: 0.0068613645\n",
            "[31,    60] loss: 0.0064158993\n",
            "[31,    70] loss: 0.0080998246\n",
            "[31,    80] loss: 0.0071596659\n",
            "[31,    90] loss: 0.0071116455\n",
            "[31,   100] loss: 0.0072575384\n",
            "[31,   110] loss: 0.0063317542\n",
            "[31,   120] loss: 0.0070687751\n",
            "[31,   130] loss: 0.0061296381\n",
            "[31,   140] loss: 0.0060622461\n",
            "[31,   150] loss: 0.0071072290\n",
            "[31,   160] loss: 0.0068813789\n",
            "[31,   170] loss: 0.0071720024\n",
            "[31,   180] loss: 0.0067747929\n",
            "[31,   190] loss: 0.0071655786\n",
            "[31,   200] loss: 0.0068820516\n",
            "[31,   210] loss: 0.0072480209\n",
            "[31,   220] loss: 0.0064671771\n",
            "[31,   230] loss: 0.0073055613\n",
            "[31,   240] loss: 0.0082186081\n",
            "[31,   250] loss: 0.0064475527\n",
            "[31,   260] loss: 0.0065166458\n",
            "[31,   270] loss: 0.0071492519\n",
            "[31,   280] loss: 0.0067479918\n",
            "[31,   290] loss: 0.0062528918\n",
            "Epoch 31/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[32,    10] loss: 0.0125897210\n",
            "[32,    20] loss: 0.0069610948\n",
            "[32,    30] loss: 0.0070690101\n",
            "[32,    40] loss: 0.0067144252\n",
            "[32,    50] loss: 0.0075796335\n",
            "[32,    60] loss: 0.0062232279\n",
            "[32,    70] loss: 0.0061460620\n",
            "[32,    80] loss: 0.0066218575\n",
            "[32,    90] loss: 0.0063854570\n",
            "[32,   100] loss: 0.0063450554\n",
            "[32,   110] loss: 0.0067729783\n",
            "[32,   120] loss: 0.0063208936\n",
            "[32,   130] loss: 0.0065894001\n",
            "[32,   140] loss: 0.0064742862\n",
            "[32,   150] loss: 0.0065510056\n",
            "[32,   160] loss: 0.0062822975\n",
            "[32,   170] loss: 0.0071790212\n",
            "[32,   180] loss: 0.0063634423\n",
            "[32,   190] loss: 0.0081747632\n",
            "[32,   200] loss: 0.0070355387\n",
            "[32,   210] loss: 0.0073609839\n",
            "[32,   220] loss: 0.0069781741\n",
            "[32,   230] loss: 0.0068626951\n",
            "[32,   240] loss: 0.0071782706\n",
            "[32,   250] loss: 0.0076155772\n",
            "[32,   260] loss: 0.0064695267\n",
            "[32,   270] loss: 0.0061582114\n",
            "[32,   280] loss: 0.0071905053\n",
            "[32,   290] loss: 0.0061806683\n",
            "Epoch 32/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[33,    10] loss: 0.0118562629\n",
            "[33,    20] loss: 0.0068990833\n",
            "[33,    30] loss: 0.0063379435\n",
            "[33,    40] loss: 0.0065765653\n",
            "[33,    50] loss: 0.0073268263\n",
            "[33,    60] loss: 0.0077076687\n",
            "[33,    70] loss: 0.0077802069\n",
            "[33,    80] loss: 0.0070807945\n",
            "[33,    90] loss: 0.0060056834\n",
            "[33,   100] loss: 0.0073835822\n",
            "[33,   110] loss: 0.0069174555\n",
            "[33,   120] loss: 0.0071462581\n",
            "[33,   130] loss: 0.0064185768\n",
            "[33,   140] loss: 0.0072232928\n",
            "[33,   150] loss: 0.0072096605\n",
            "[33,   160] loss: 0.0061059552\n",
            "[33,   170] loss: 0.0067883970\n",
            "[33,   180] loss: 0.0068697019\n",
            "[33,   190] loss: 0.0064633022\n",
            "[33,   200] loss: 0.0070585112\n",
            "[33,   210] loss: 0.0067039744\n",
            "[33,   220] loss: 0.0058287928\n",
            "[33,   230] loss: 0.0064234464\n",
            "[33,   240] loss: 0.0061387643\n",
            "[33,   250] loss: 0.0069383873\n",
            "[33,   260] loss: 0.0067564990\n",
            "[33,   270] loss: 0.0060737533\n",
            "[33,   280] loss: 0.0057818983\n",
            "[33,   290] loss: 0.0059801196\n",
            "Epoch 33/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[34,    10] loss: 0.0123153143\n",
            "[34,    20] loss: 0.0066980918\n",
            "[34,    30] loss: 0.0059685912\n",
            "[34,    40] loss: 0.0067191016\n",
            "[34,    50] loss: 0.0064019684\n",
            "[34,    60] loss: 0.0067471369\n",
            "[34,    70] loss: 0.0061380577\n",
            "[34,    80] loss: 0.0057578935\n",
            "[34,    90] loss: 0.0067744573\n",
            "[34,   100] loss: 0.0069454985\n",
            "[34,   110] loss: 0.0069554022\n",
            "[34,   120] loss: 0.0070744691\n",
            "[34,   130] loss: 0.0076889035\n",
            "[34,   140] loss: 0.0066600670\n",
            "[34,   150] loss: 0.0068486757\n",
            "[34,   160] loss: 0.0064179277\n",
            "[34,   170] loss: 0.0067137277\n",
            "[34,   180] loss: 0.0060980184\n",
            "[34,   190] loss: 0.0063080011\n",
            "[34,   200] loss: 0.0056631013\n",
            "[34,   210] loss: 0.0068488779\n",
            "[34,   220] loss: 0.0062515829\n",
            "[34,   230] loss: 0.0073989982\n",
            "[34,   240] loss: 0.0061039148\n",
            "[34,   250] loss: 0.0063524700\n",
            "[34,   260] loss: 0.0062785944\n",
            "[34,   270] loss: 0.0071656054\n",
            "[34,   280] loss: 0.0066089751\n",
            "[34,   290] loss: 0.0061778621\n",
            "Epoch 34/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[35,    10] loss: 0.0116323137\n",
            "[35,    20] loss: 0.0069686325\n",
            "[35,    30] loss: 0.0073033056\n",
            "[35,    40] loss: 0.0065366038\n",
            "[35,    50] loss: 0.0065573318\n",
            "[35,    60] loss: 0.0057583010\n",
            "[35,    70] loss: 0.0060790599\n",
            "[35,    80] loss: 0.0068419949\n",
            "[35,    90] loss: 0.0071644869\n",
            "[35,   100] loss: 0.0057649989\n",
            "[35,   110] loss: 0.0067284894\n",
            "[35,   120] loss: 0.0074275900\n",
            "[35,   130] loss: 0.0065507985\n",
            "[35,   140] loss: 0.0069844510\n",
            "[35,   150] loss: 0.0064993105\n",
            "[35,   160] loss: 0.0062705109\n",
            "[35,   170] loss: 0.0071063040\n",
            "[35,   180] loss: 0.0065095966\n",
            "[35,   190] loss: 0.0060164651\n",
            "[35,   200] loss: 0.0062714729\n",
            "[35,   210] loss: 0.0066869686\n",
            "[35,   220] loss: 0.0067261607\n",
            "[35,   230] loss: 0.0057653681\n",
            "[35,   240] loss: 0.0059079630\n",
            "[35,   250] loss: 0.0064465859\n",
            "[35,   260] loss: 0.0072694441\n",
            "[35,   270] loss: 0.0059532568\n",
            "[35,   280] loss: 0.0059259532\n",
            "[35,   290] loss: 0.0071591729\n",
            "Epoch 35/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[36,    10] loss: 0.0112979292\n",
            "[36,    20] loss: 0.0063699914\n",
            "[36,    30] loss: 0.0057312214\n",
            "[36,    40] loss: 0.0063109266\n",
            "[36,    50] loss: 0.0064922748\n",
            "[36,    60] loss: 0.0054543516\n",
            "[36,    70] loss: 0.0060904607\n",
            "[36,    80] loss: 0.0059587021\n",
            "[36,    90] loss: 0.0061037342\n",
            "[36,   100] loss: 0.0063419759\n",
            "[36,   110] loss: 0.0068039266\n",
            "[36,   120] loss: 0.0076990248\n",
            "[36,   130] loss: 0.0068903054\n",
            "[36,   140] loss: 0.0066430348\n",
            "[36,   150] loss: 0.0064104581\n",
            "[36,   160] loss: 0.0070509239\n",
            "[36,   170] loss: 0.0068677164\n",
            "[36,   180] loss: 0.0066966622\n",
            "[36,   190] loss: 0.0068148689\n",
            "[36,   200] loss: 0.0059894783\n",
            "[36,   210] loss: 0.0065113116\n",
            "[36,   220] loss: 0.0059688454\n",
            "[36,   230] loss: 0.0066320912\n",
            "[36,   240] loss: 0.0067765164\n",
            "[36,   250] loss: 0.0066775010\n",
            "[36,   260] loss: 0.0066171984\n",
            "[36,   270] loss: 0.0059959264\n",
            "[36,   280] loss: 0.0054006830\n",
            "[36,   290] loss: 0.0067651697\n",
            "Epoch 36/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[37,    10] loss: 0.0118697811\n",
            "[37,    20] loss: 0.0067139349\n",
            "[37,    30] loss: 0.0061475936\n",
            "[37,    40] loss: 0.0069936212\n",
            "[37,    50] loss: 0.0065649683\n",
            "[37,    60] loss: 0.0064328633\n",
            "[37,    70] loss: 0.0068350378\n",
            "[37,    80] loss: 0.0067093350\n",
            "[37,    90] loss: 0.0059980431\n",
            "[37,   100] loss: 0.0065146222\n",
            "[37,   110] loss: 0.0071125816\n",
            "[37,   120] loss: 0.0054976930\n",
            "[37,   130] loss: 0.0062402261\n",
            "[37,   140] loss: 0.0064242354\n",
            "[37,   150] loss: 0.0063978577\n",
            "[37,   160] loss: 0.0058115077\n",
            "[37,   170] loss: 0.0063087981\n",
            "[37,   180] loss: 0.0065020581\n",
            "[37,   190] loss: 0.0065719145\n",
            "[37,   200] loss: 0.0069532361\n",
            "[37,   210] loss: 0.0057406489\n",
            "[37,   220] loss: 0.0062376364\n",
            "[37,   230] loss: 0.0059983844\n",
            "[37,   240] loss: 0.0062203943\n",
            "[37,   250] loss: 0.0064920825\n",
            "[37,   260] loss: 0.0055412911\n",
            "[37,   270] loss: 0.0067230069\n",
            "[37,   280] loss: 0.0059593517\n",
            "[37,   290] loss: 0.0060143308\n",
            "Epoch 37/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[38,    10] loss: 0.0116965825\n",
            "[38,    20] loss: 0.0067044848\n",
            "[38,    30] loss: 0.0068506177\n",
            "[38,    40] loss: 0.0066348573\n",
            "[38,    50] loss: 0.0058582481\n",
            "[38,    60] loss: 0.0070399014\n",
            "[38,    70] loss: 0.0062016894\n",
            "[38,    80] loss: 0.0061496462\n",
            "[38,    90] loss: 0.0068875474\n",
            "[38,   100] loss: 0.0059510032\n",
            "[38,   110] loss: 0.0052345295\n",
            "[38,   120] loss: 0.0060187339\n",
            "[38,   130] loss: 0.0063097742\n",
            "[38,   140] loss: 0.0058958839\n",
            "[38,   150] loss: 0.0064178335\n",
            "[38,   160] loss: 0.0059786471\n",
            "[38,   170] loss: 0.0061836910\n",
            "[38,   180] loss: 0.0067945405\n",
            "[38,   190] loss: 0.0064377637\n",
            "[38,   200] loss: 0.0058687663\n",
            "[38,   210] loss: 0.0063020856\n",
            "[38,   220] loss: 0.0054022194\n",
            "[38,   230] loss: 0.0063445914\n",
            "[38,   240] loss: 0.0062177164\n",
            "[38,   250] loss: 0.0073046507\n",
            "[38,   260] loss: 0.0057361239\n",
            "[38,   270] loss: 0.0065332841\n",
            "[38,   280] loss: 0.0061585309\n",
            "[38,   290] loss: 0.0058474579\n",
            "Epoch 38/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[39,    10] loss: 0.0112611918\n",
            "[39,    20] loss: 0.0066588606\n",
            "[39,    30] loss: 0.0058892847\n",
            "[39,    40] loss: 0.0053885805\n",
            "[39,    50] loss: 0.0059455249\n",
            "[39,    60] loss: 0.0072989650\n",
            "[39,    70] loss: 0.0066609026\n",
            "[39,    80] loss: 0.0067733162\n",
            "[39,    90] loss: 0.0058812820\n",
            "[39,   100] loss: 0.0060689993\n",
            "[39,   110] loss: 0.0055553902\n",
            "[39,   120] loss: 0.0060842507\n",
            "[39,   130] loss: 0.0060726279\n",
            "[39,   140] loss: 0.0058840070\n",
            "[39,   150] loss: 0.0058036752\n",
            "[39,   160] loss: 0.0059722764\n",
            "[39,   170] loss: 0.0056564401\n",
            "[39,   180] loss: 0.0060548728\n",
            "[39,   190] loss: 0.0061806584\n",
            "[39,   200] loss: 0.0058025800\n",
            "[39,   210] loss: 0.0057833976\n",
            "[39,   220] loss: 0.0058838588\n",
            "[39,   230] loss: 0.0074805592\n",
            "[39,   240] loss: 0.0061036331\n",
            "[39,   250] loss: 0.0066669109\n",
            "[39,   260] loss: 0.0073981254\n",
            "[39,   270] loss: 0.0061184958\n",
            "[39,   280] loss: 0.0060744819\n",
            "[39,   290] loss: 0.0065637953\n",
            "Epoch 39/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[40,    10] loss: 0.0112351912\n",
            "[40,    20] loss: 0.0051698872\n",
            "[40,    30] loss: 0.0055664339\n",
            "[40,    40] loss: 0.0064556621\n",
            "[40,    50] loss: 0.0058737334\n",
            "[40,    60] loss: 0.0070778193\n",
            "[40,    70] loss: 0.0058433104\n",
            "[40,    80] loss: 0.0060209293\n",
            "[40,    90] loss: 0.0058158634\n",
            "[40,   100] loss: 0.0059317402\n",
            "[40,   110] loss: 0.0069205896\n",
            "[40,   120] loss: 0.0067201293\n",
            "[40,   130] loss: 0.0060456149\n",
            "[40,   140] loss: 0.0067795189\n",
            "[40,   150] loss: 0.0061660858\n",
            "[40,   160] loss: 0.0064471906\n",
            "[40,   170] loss: 0.0056521053\n",
            "[40,   180] loss: 0.0057705987\n",
            "[40,   190] loss: 0.0069495410\n",
            "[40,   200] loss: 0.0058440043\n",
            "[40,   210] loss: 0.0055183358\n",
            "[40,   220] loss: 0.0061850230\n",
            "[40,   230] loss: 0.0061901526\n",
            "[40,   240] loss: 0.0063382576\n",
            "[40,   250] loss: 0.0069366694\n",
            "[40,   260] loss: 0.0061592374\n",
            "[40,   270] loss: 0.0063172448\n",
            "[40,   280] loss: 0.0061274881\n",
            "[40,   290] loss: 0.0052923479\n",
            "Epoch 40/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[41,    10] loss: 0.0112074046\n",
            "[41,    20] loss: 0.0058356287\n",
            "[41,    30] loss: 0.0053633940\n",
            "[41,    40] loss: 0.0063670016\n",
            "[41,    50] loss: 0.0063485913\n",
            "[41,    60] loss: 0.0060718175\n",
            "[41,    70] loss: 0.0063222009\n",
            "[41,    80] loss: 0.0064947729\n",
            "[41,    90] loss: 0.0065577159\n",
            "[41,   100] loss: 0.0062248753\n",
            "[41,   110] loss: 0.0065849125\n",
            "[41,   120] loss: 0.0058551510\n",
            "[41,   130] loss: 0.0059066498\n",
            "[41,   140] loss: 0.0057604948\n",
            "[41,   150] loss: 0.0058409594\n",
            "[41,   160] loss: 0.0054943866\n",
            "[41,   170] loss: 0.0058018072\n",
            "[41,   180] loss: 0.0069002429\n",
            "[41,   190] loss: 0.0055632642\n",
            "[41,   200] loss: 0.0058346232\n",
            "[41,   210] loss: 0.0060943344\n",
            "[41,   220] loss: 0.0060902668\n",
            "[41,   230] loss: 0.0057470535\n",
            "[41,   240] loss: 0.0056974719\n",
            "[41,   250] loss: 0.0062525161\n",
            "[41,   260] loss: 0.0054947182\n",
            "[41,   270] loss: 0.0061935835\n",
            "[41,   280] loss: 0.0055204221\n",
            "[41,   290] loss: 0.0062572113\n",
            "Epoch 41/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[42,    10] loss: 0.0109755475\n",
            "[42,    20] loss: 0.0061487798\n",
            "[42,    30] loss: 0.0059069845\n",
            "[42,    40] loss: 0.0061120875\n",
            "[42,    50] loss: 0.0058200697\n",
            "[42,    60] loss: 0.0056867261\n",
            "[42,    70] loss: 0.0065900439\n",
            "[42,    80] loss: 0.0061322850\n",
            "[42,    90] loss: 0.0061922706\n",
            "[42,   100] loss: 0.0067392487\n",
            "[42,   110] loss: 0.0055801487\n",
            "[42,   120] loss: 0.0061727975\n",
            "[42,   130] loss: 0.0067826651\n",
            "[42,   140] loss: 0.0058009757\n",
            "[42,   150] loss: 0.0058082933\n",
            "[42,   160] loss: 0.0059292229\n",
            "[42,   170] loss: 0.0056606033\n",
            "[42,   180] loss: 0.0059999742\n",
            "[42,   190] loss: 0.0055596560\n",
            "[42,   200] loss: 0.0056728765\n",
            "[42,   210] loss: 0.0058342296\n",
            "[42,   220] loss: 0.0057252447\n",
            "[42,   230] loss: 0.0057318602\n",
            "[42,   240] loss: 0.0065353872\n",
            "[42,   250] loss: 0.0051095934\n",
            "[42,   260] loss: 0.0062446482\n",
            "[42,   270] loss: 0.0060294162\n",
            "[42,   280] loss: 0.0063924555\n",
            "[42,   290] loss: 0.0062222268\n",
            "Epoch 42/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[43,    10] loss: 0.0100393509\n",
            "[43,    20] loss: 0.0061837474\n",
            "[43,    30] loss: 0.0060528040\n",
            "[43,    40] loss: 0.0060037341\n",
            "[43,    50] loss: 0.0056583331\n",
            "[43,    60] loss: 0.0059418338\n",
            "[43,    70] loss: 0.0059220365\n",
            "[43,    80] loss: 0.0059762419\n",
            "[43,    90] loss: 0.0060137980\n",
            "[43,   100] loss: 0.0057705393\n",
            "[43,   110] loss: 0.0061099203\n",
            "[43,   120] loss: 0.0060796564\n",
            "[43,   130] loss: 0.0057286385\n",
            "[43,   140] loss: 0.0065242820\n",
            "[43,   150] loss: 0.0059374290\n",
            "[43,   160] loss: 0.0062384426\n",
            "[43,   170] loss: 0.0049267798\n",
            "[43,   180] loss: 0.0060885245\n",
            "[43,   190] loss: 0.0061044616\n",
            "[43,   200] loss: 0.0063831856\n",
            "[43,   210] loss: 0.0057550489\n",
            "[43,   220] loss: 0.0059618889\n",
            "[43,   230] loss: 0.0056958028\n",
            "[43,   240] loss: 0.0064085658\n",
            "[43,   250] loss: 0.0056541124\n",
            "[43,   260] loss: 0.0058030194\n",
            "[43,   270] loss: 0.0059802538\n",
            "[43,   280] loss: 0.0051647301\n",
            "[43,   290] loss: 0.0053479991\n",
            "Epoch 43/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[44,    10] loss: 0.0116171119\n",
            "[44,    20] loss: 0.0057058356\n",
            "[44,    30] loss: 0.0063753228\n",
            "[44,    40] loss: 0.0052329509\n",
            "[44,    50] loss: 0.0064434107\n",
            "[44,    60] loss: 0.0060227866\n",
            "[44,    70] loss: 0.0054978267\n",
            "[44,    80] loss: 0.0055919211\n",
            "[44,    90] loss: 0.0056596337\n",
            "[44,   100] loss: 0.0056273864\n",
            "[44,   110] loss: 0.0056351526\n",
            "[44,   120] loss: 0.0056160850\n",
            "[44,   130] loss: 0.0059492383\n",
            "[44,   140] loss: 0.0061796464\n",
            "[44,   150] loss: 0.0052751781\n",
            "[44,   160] loss: 0.0052505525\n",
            "[44,   170] loss: 0.0051070544\n",
            "[44,   180] loss: 0.0065828876\n",
            "[44,   190] loss: 0.0061237051\n",
            "[44,   200] loss: 0.0063740995\n",
            "[44,   210] loss: 0.0057109998\n",
            "[44,   220] loss: 0.0066492940\n",
            "[44,   230] loss: 0.0055493680\n",
            "[44,   240] loss: 0.0056025520\n",
            "[44,   250] loss: 0.0056528728\n",
            "[44,   260] loss: 0.0059958834\n",
            "[44,   270] loss: 0.0053295616\n",
            "[44,   280] loss: 0.0062072789\n",
            "[44,   290] loss: 0.0053957606\n",
            "Epoch 44/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[45,    10] loss: 0.0108987094\n",
            "[45,    20] loss: 0.0058321831\n",
            "[45,    30] loss: 0.0066756972\n",
            "[45,    40] loss: 0.0055354335\n",
            "[45,    50] loss: 0.0055839620\n",
            "[45,    60] loss: 0.0058378340\n",
            "[45,    70] loss: 0.0055813793\n",
            "[45,    80] loss: 0.0057749006\n",
            "[45,    90] loss: 0.0058819516\n",
            "[45,   100] loss: 0.0055256989\n",
            "[45,   110] loss: 0.0058810939\n",
            "[45,   120] loss: 0.0053046773\n",
            "[45,   130] loss: 0.0061007556\n",
            "[45,   140] loss: 0.0062808762\n",
            "[45,   150] loss: 0.0057840031\n",
            "[45,   160] loss: 0.0054449477\n",
            "[45,   170] loss: 0.0064895267\n",
            "[45,   180] loss: 0.0055520130\n",
            "[45,   190] loss: 0.0060076535\n",
            "[45,   200] loss: 0.0057660830\n",
            "[45,   210] loss: 0.0057033546\n",
            "[45,   220] loss: 0.0058468682\n",
            "[45,   230] loss: 0.0061028298\n",
            "[45,   240] loss: 0.0059304805\n",
            "[45,   250] loss: 0.0056756962\n",
            "[45,   260] loss: 0.0054479351\n",
            "[45,   270] loss: 0.0057624787\n",
            "[45,   280] loss: 0.0050002520\n",
            "[45,   290] loss: 0.0055422877\n",
            "Epoch 45/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[46,    10] loss: 0.0107196182\n",
            "[46,    20] loss: 0.0057114629\n",
            "[46,    30] loss: 0.0049955247\n",
            "[46,    40] loss: 0.0059611652\n",
            "[46,    50] loss: 0.0051811644\n",
            "[46,    60] loss: 0.0057122763\n",
            "[46,    70] loss: 0.0059044214\n",
            "[46,    80] loss: 0.0057231165\n",
            "[46,    90] loss: 0.0059561664\n",
            "[46,   100] loss: 0.0053208876\n",
            "[46,   110] loss: 0.0060785883\n",
            "[46,   120] loss: 0.0057268298\n",
            "[46,   130] loss: 0.0051164378\n",
            "[46,   140] loss: 0.0059658419\n",
            "[46,   150] loss: 0.0053292751\n",
            "[46,   160] loss: 0.0057020033\n",
            "[46,   170] loss: 0.0054588128\n",
            "[46,   180] loss: 0.0055867139\n",
            "[46,   190] loss: 0.0057474627\n",
            "[46,   200] loss: 0.0054730715\n",
            "[46,   210] loss: 0.0058333468\n",
            "[46,   220] loss: 0.0060980383\n",
            "[46,   230] loss: 0.0060469314\n",
            "[46,   240] loss: 0.0057813025\n",
            "[46,   250] loss: 0.0054712431\n",
            "[46,   260] loss: 0.0052417276\n",
            "[46,   270] loss: 0.0060383502\n",
            "[46,   280] loss: 0.0059293374\n",
            "[46,   290] loss: 0.0059744911\n",
            "Epoch 46/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[47,    10] loss: 0.0117790157\n",
            "[47,    20] loss: 0.0050496444\n",
            "[47,    30] loss: 0.0054973805\n",
            "[47,    40] loss: 0.0058027393\n",
            "[47,    50] loss: 0.0060506750\n",
            "[47,    60] loss: 0.0060233928\n",
            "[47,    70] loss: 0.0051691804\n",
            "[47,    80] loss: 0.0060665517\n",
            "[47,    90] loss: 0.0046563503\n",
            "[47,   100] loss: 0.0064227074\n",
            "[47,   110] loss: 0.0062009356\n",
            "[47,   120] loss: 0.0055359508\n",
            "[47,   130] loss: 0.0055271941\n",
            "[47,   140] loss: 0.0049465103\n",
            "[47,   150] loss: 0.0052828757\n",
            "[47,   160] loss: 0.0052865512\n",
            "[47,   170] loss: 0.0055922510\n",
            "[47,   180] loss: 0.0060763786\n",
            "[47,   190] loss: 0.0062454268\n",
            "[47,   200] loss: 0.0053281349\n",
            "[47,   210] loss: 0.0052597275\n",
            "[47,   220] loss: 0.0051555113\n",
            "[47,   230] loss: 0.0060572411\n",
            "[47,   240] loss: 0.0053300736\n",
            "[47,   250] loss: 0.0055133836\n",
            "[47,   260] loss: 0.0055387270\n",
            "[47,   270] loss: 0.0061431011\n",
            "[47,   280] loss: 0.0051488762\n",
            "[47,   290] loss: 0.0065846584\n",
            "Epoch 47/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[48,    10] loss: 0.0100866672\n",
            "[48,    20] loss: 0.0053594673\n",
            "[48,    30] loss: 0.0060392311\n",
            "[48,    40] loss: 0.0056813299\n",
            "[48,    50] loss: 0.0059125496\n",
            "[48,    60] loss: 0.0056039249\n",
            "[48,    70] loss: 0.0052520354\n",
            "[48,    80] loss: 0.0052268536\n",
            "[48,    90] loss: 0.0057818817\n",
            "[48,   100] loss: 0.0055316893\n",
            "[48,   110] loss: 0.0052801722\n",
            "[48,   120] loss: 0.0061867750\n",
            "[48,   130] loss: 0.0053502535\n",
            "[48,   140] loss: 0.0049495602\n",
            "[48,   150] loss: 0.0058880708\n",
            "[48,   160] loss: 0.0053190354\n",
            "[48,   170] loss: 0.0059507333\n",
            "[48,   180] loss: 0.0048348387\n",
            "[48,   190] loss: 0.0058821243\n",
            "[48,   200] loss: 0.0056035631\n",
            "[48,   210] loss: 0.0053483196\n",
            "[48,   220] loss: 0.0061874030\n",
            "[48,   230] loss: 0.0064016261\n",
            "[48,   240] loss: 0.0052972246\n",
            "[48,   250] loss: 0.0060185066\n",
            "[48,   260] loss: 0.0051823130\n",
            "[48,   270] loss: 0.0050023141\n",
            "[48,   280] loss: 0.0054047313\n",
            "[48,   290] loss: 0.0061458791\n",
            "Epoch 48/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[49,    10] loss: 0.0109196460\n",
            "[49,    20] loss: 0.0054452882\n",
            "[49,    30] loss: 0.0056439313\n",
            "[49,    40] loss: 0.0057237635\n",
            "[49,    50] loss: 0.0054788509\n",
            "[49,    60] loss: 0.0051120491\n",
            "[49,    70] loss: 0.0064230365\n",
            "[49,    80] loss: 0.0054329990\n",
            "[49,    90] loss: 0.0057534021\n",
            "[49,   100] loss: 0.0053106902\n",
            "[49,   110] loss: 0.0054720796\n",
            "[49,   120] loss: 0.0057856466\n",
            "[49,   130] loss: 0.0054823002\n",
            "[49,   140] loss: 0.0053492360\n",
            "[49,   150] loss: 0.0061534367\n",
            "[49,   160] loss: 0.0052841589\n",
            "[49,   170] loss: 0.0051493777\n",
            "[49,   180] loss: 0.0055333828\n",
            "[49,   190] loss: 0.0060157045\n",
            "[49,   200] loss: 0.0053422425\n",
            "[49,   210] loss: 0.0053803834\n",
            "[49,   220] loss: 0.0050566224\n",
            "[49,   230] loss: 0.0061148312\n",
            "[49,   240] loss: 0.0049605615\n",
            "[49,   250] loss: 0.0053453577\n",
            "[49,   260] loss: 0.0051593270\n",
            "[49,   270] loss: 0.0054340948\n",
            "[49,   280] loss: 0.0052835141\n",
            "[49,   290] loss: 0.0054483604\n",
            "Epoch 49/49\n",
            "----------\n",
            "LR 1e-05\n",
            "[50,    10] loss: 0.0099635560\n",
            "[50,    20] loss: 0.0057442900\n",
            "[50,    30] loss: 0.0052025243\n",
            "[50,    40] loss: 0.0054108755\n",
            "[50,    50] loss: 0.0052131759\n",
            "[50,    60] loss: 0.0052332686\n",
            "[50,    70] loss: 0.0060391071\n",
            "[50,    80] loss: 0.0051399822\n",
            "[50,    90] loss: 0.0057187839\n",
            "[50,   100] loss: 0.0058699132\n",
            "[50,   110] loss: 0.0058575570\n",
            "[50,   120] loss: 0.0051896949\n",
            "[50,   130] loss: 0.0057471486\n",
            "[50,   140] loss: 0.0051145120\n",
            "[50,   150] loss: 0.0050735021\n",
            "[50,   160] loss: 0.0055260210\n",
            "[50,   170] loss: 0.0056888892\n",
            "[50,   180] loss: 0.0056338650\n",
            "[50,   190] loss: 0.0052768087\n",
            "[50,   200] loss: 0.0049794437\n",
            "[50,   210] loss: 0.0048684221\n",
            "[50,   220] loss: 0.0047574181\n",
            "[50,   230] loss: 0.0054011629\n",
            "[50,   240] loss: 0.0058180144\n",
            "[50,   250] loss: 0.0055935532\n",
            "[50,   260] loss: 0.0057662740\n",
            "[50,   270] loss: 0.0056373233\n",
            "[50,   280] loss: 0.0055998858\n",
            "[50,   290] loss: 0.0056022164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wxKlOUxh_Z5",
        "colab_type": "text"
      },
      "source": [
        "**Dont run the save command if the training is not performed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mejY3FUVhSeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(unet.state_dict(), os.path.join(\"/content/drive/My Drive/Dataset/cityscape_400x400/\",\"unet_7M_fine_w_pennfudan\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edDjMDAOiLlO",
        "colab_type": "text"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr8OGI9CHeTZ",
        "colab_type": "text"
      },
      "source": [
        "**Load the pretrained dataset here if available**\n",
        "\n",
        "**Note:**\n",
        "\n",
        "* Ensure the directory is correct to search the .pth file\n",
        "* Ensure correct name for .pth file matching the choosen model architecture\n",
        "* If architecture matched we will see: **All keys matched successfully**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfdg43xL9IjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "6ccd491a-063b-4ccc-c920-035aedbed27a"
      },
      "source": [
        "unet.load_state_dict(torch.load(os.path.join(\"/content/drive/My Drive/Dataset/cityscape_400x400/\",\"unet_7M_fine_w_pennfudan\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d6b87abfdfe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Dataset/cityscape_400x400/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"unet_7M_fine_w_pennfudan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'unet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T98Y15oigAO",
        "colab_type": "text"
      },
      "source": [
        "**IOU metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCDpK2VJ9IjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iou(pred, target, smooth=1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    union = pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) \n",
        "    #print(intersection,union)\n",
        "   \n",
        "    loss = ((intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) - intersection + smooth))\n",
        "    \n",
        "    return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhCCeoxIGEj",
        "colab_type": "text"
      },
      "source": [
        "**Checking the IOU for our test set**\n",
        "\n",
        "Change the Iou threshold if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yb4EQduiUoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b930222-a083-4268-ff98-e94eeee52417"
      },
      "source": [
        "iou_threshold = 0.6 # enter the threshold for IOU metrics\n",
        "correct_prediction = 0\n",
        "total_prediction = 0\n",
        "for i, data in enumerate(dataloaders['test']):\n",
        "    inputimage, targetimage = data\n",
        "    \n",
        "    if gpu_available:\n",
        "        inputimage = inputimage.cuda() \n",
        "        targetimage =  targetimage.squeeze(0).cuda()\n",
        "        \n",
        "\n",
        "    prediction = unet(inputimage)\n",
        "    prediction = torch.sigmoid(prediction)  \n",
        "\n",
        "    lab_channel = torch.empty_like(prediction)\n",
        "    lab_channel[:,0,:,:] = 1 - targetimage\n",
        "    lab_channel[:,1,:,:] = targetimage\n",
        "    lab_channel = lab_channel.cuda()\n",
        "\n",
        "    loss_raw = ((iou(prediction,lab_channel,1e-9)).cpu())\n",
        "    #print(loss_raw)\n",
        "\n",
        "    total_prediction = total_prediction + 1\n",
        "    if loss_raw > iou_threshold:\n",
        "      correct_prediction = correct_prediction + 1\n",
        "\n",
        "print(\"IOU: \" + str(correct_prediction/total_prediction) +str(\" for IOU threshold of: \") + str(iou_threshold))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7315, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7762, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7710, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5829, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6359, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5262, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7222, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7367, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7038, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7130, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7671, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6586, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6099, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5409, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6825, grad_fn=<CopyBackwards>)\n",
            "tensor(0.9337, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6613, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6407, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6484, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5371, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7352, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5452, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7477, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7539, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7350, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7881, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4988, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5132, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7122, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6933, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6712, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8167, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5658, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7697, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6923, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6594, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5724, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5384, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6816, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7049, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7821, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7547, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5147, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4875, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6466, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5230, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5857, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8399, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5032, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8275, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5636, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6980, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5507, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7159, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6792, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7454, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7505, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5744, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7793, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7805, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8278, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6502, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5612, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8221, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5078, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7598, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6221, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7366, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6285, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5924, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7259, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8185, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7081, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8478, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6618, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5519, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8716, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5625, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7986, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7795, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7052, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7373, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6776, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5218, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7989, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6328, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8589, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6226, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7912, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7145, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6836, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6049, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6283, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5397, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8682, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7324, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6998, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6033, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6448, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6713, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7208, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6118, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4986, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7227, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7928, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7697, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6791, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7037, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5572, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5817, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6622, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8272, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5913, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6929, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6998, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5077, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7149, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6485, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8831, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6722, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5402, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7498, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7127, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6250, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5226, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5456, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6839, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8601, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4977, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6284, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8461, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7093, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7511, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5167, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6636, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8324, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7636, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6487, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8420, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6003, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6912, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8455, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7203, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5386, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6198, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6645, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6752, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7791, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7740, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7885, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7863, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7741, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6993, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8744, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7291, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6361, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6029, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6343, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6992, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5258, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6288, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4996, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7327, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7002, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6494, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8250, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7089, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8096, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5395, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7575, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6325, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6174, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6430, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4983, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6581, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5236, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5853, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8114, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5622, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6365, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5902, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7645, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6926, grad_fn=<CopyBackwards>)\n",
            "tensor(0.4996, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6835, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7435, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7645, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8474, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5935, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6336, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6028, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8569, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6403, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8824, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5618, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7539, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5677, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7228, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5562, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6398, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6962, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7807, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6358, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6825, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6473, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7037, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6622, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7306, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5635, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6861, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7770, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8160, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6844, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5576, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7544, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8155, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5572, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7215, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5916, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7294, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7671, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7257, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6400, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6628, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7223, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6809, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5069, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7157, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8363, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5243, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6759, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7181, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7044, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5814, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6601, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6927, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8478, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6333, grad_fn=<CopyBackwards>)\n",
            "tensor(0.5725, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7220, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7494, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6528, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7835, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6510, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6034, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7298, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7127, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7700, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7647, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7535, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8060, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8084, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6059, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6925, grad_fn=<CopyBackwards>)\n",
            "tensor(0.9120, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7223, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7939, grad_fn=<CopyBackwards>)\n",
            "tensor(0.8374, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7903, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6438, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7354, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7169, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6012, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6376, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6814, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7673, grad_fn=<CopyBackwards>)\n",
            "tensor(0.7825, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6799, grad_fn=<CopyBackwards>)\n",
            "tensor(0.6923, grad_fn=<CopyBackwards>)\n",
            "IOU: 0.7881040892193308 for IOU threshold of: 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GpjdOPCqIi6p"
      },
      "source": [
        "**Visualising the predicted output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzEnkwMB-N9E",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "e765a0f3-82e0-4159-a4b1-20f2295d642a"
      },
      "source": [
        "import math\n",
        "\n",
        "# Get the first batch\n",
        "inputs1, targetimage = next(iter(dataloaders['test']))\n",
        "inputs = inputs1.cuda()\n",
        "\n",
        "\n",
        "# Predict\n",
        "pred = unet(inputs)\n",
        "\n",
        "# The loss functions include the sigmoid function.\n",
        "pred = torch.sigmoid(pred)\n",
        "pred_max = torch.argmax(pred, dim=1)\n",
        "print(inputs1.shape)\n",
        "\n",
        "#printing image\n",
        "fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(12,12),facecolor='w')\n",
        "ax1.imshow(pred_max.squeeze(0).cpu(),  interpolation='none',cmap='jet')\n",
        "ax2.imshow(targetimage.squeeze(0).squeeze(0).cpu(),  interpolation='none',cmap='jet')\n",
        "ax3.imshow((inputs1.squeeze(0).cpu())[1,:,:],  interpolation='none',cmap='gray')\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')\n",
        "ax3.axis('off')\n",
        "ax1.set_title('prediction',fontsize=20)\n",
        "ax2.set_title('Label',fontsize=20)\n",
        "ax3.set_title('input',fontsize=20)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 400, 400])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAADoCAYAAAAqlLZjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOx9eZRcZZn+U/u+V3f1mnR31k4CSQiBkEiIUQiohMUZZXBGkPGgcAjLOSOOOgqoHOaIyiKoHJzRkdE5CgqILGFN2JoQyEKWztL7UtXVte9Vt5b7+6N/75uvOp3IjGIi+Z5zcrr71q17v7tU6rnP97zPq1FVVYWEhISEhISEhITESQrtiR6AhISEhISEhISExPEgCauEhISEhISEhMRJDUlYJSQkJCQkJCQkTmpIwiohISEhISEhIXFSQxJWCQkJCQkJCQmJkxqSsEpISEhISEhISJzUkIT1JEBHRwc6Ojrqlv3iF7+ARqPBL37xiw9svxqNBuvWrfvAti8hcarh6quvhkajwdDQ0Ae2j9tvvx0ajQZbtmz5wPYhIXEyYWhoCBqNBldfffWJHorECYQkrB9izESEJSROdWg0Gmg0mhM9DAkJiQ8h/hpi06kK/YkegMTMuOyyy7Bq1So0Nzd/YPvo7e2F1Wr9wLYvISEhISHx56K1tRW9vb1wuVwneigSJxCSsJ6kcLlcH/iHc+HChR/o9iUkJCQkJP5cGAwG+X0lcWpYAkT/y4EDB3DppZfC6/XCZrPhIx/5CJ5//vm69UVJ/7nnnsO6devgcrnqphErlQp+/OMfY9WqVXA6nbBarVi+fDkeeOAB1Gq1o8agqioeeOABLF68GGazGa2trbjhhhuQSqVmHPPxphXGxsZw4403Yt68ebBYLPB6vTjrrLPwne98BwCwZcsWaDQaDA8PY3h4mKdAp3uAjuVhTaVS+NrXvoYFCxbAbDbD4/Fgw4YNePHFF49al/Z1++23Y9euXfjkJz8Jt9sNq9WK8847D2+++eaMxych8beAJ554Av/4j/+I+fPnw2azwWazYcWKFbj//vtn/JwTarUafvjDH2LhwoUwm81oa2vDLbfcgnQ6PeP6Y2NjuOGGG9DV1QWTyQSfz4eNGzdi+/btH9ShSUj8zWAmD6voF3/ooYdw2mmnwWw2IxAI4Nprr53xu5VscqlUCjfccANaW1thNpuxaNEi3H///ZjeqV78fpsJ021369atwxe+8AUAwBe+8IW6794P0td+quCUUlgHBwdxzjnn4LTTTsOXvvQlhEIh/OY3v8FFF12EX//61/jsZz9bt/5jjz2G5557DhdddBG+/OUvY3h4GABQLpdx8cUXY/PmzViwYAGuvPJKmM1mvPLKK9i0aRO2bduGRx55pG5bN998M+6//340Nzfj2muvhcFgwJNPPolt27ZBURQYjcb3dQzvvPMONmzYgHg8jrVr1+Lyyy9HPp/H/v37cfvtt+Ob3/wmOjo6cNttt+Hee+/lfROWLVt23O0nk0msWbMG+/fvx8qVK3HzzTcjGo3it7/9LS644AL85Cc/wZe+9KUZx/W9730P55xzDr74xS9iZGQEv/vd7/Cxj30Mu3btwoIFC97X8UlInEz413/9V2i1Wpx99tlobW1FKpXCyy+/jJtuugnbt28/6nNOuOWWW/Dqq6/iM5/5DC655BJs3rwZ9957L1577TW8/vrrMJvNvO6OHTtwwQUXIB6PY8OGDbj88ssRjUbxxBNP4CMf+Qgef/xxfOITn/hrHbKExN8Ubr31VmzevBkXX3wxLrjgArzyyit4+OGH0dfXh5dffvmo9RVFwcc//nEkk0lcccUVUBQFv/vd73DTTTfh4MGDePDBB//PY7n66qvhdrvx5JNP4pJLLqn7vnW73f/n7Ur8f6inAAYHB1UAKgD1X/7lX+pe2759u6rX61W3262mUilVVVX15z//uQpA1Wg06rPPPnvU9m677TYVgHrDDTeolUqFl1cqFfWaa65RAahPPPEEL3/jjTdUAOqcOXPUWCzGywuFgrpq1SoVgDp79uy6fdAYfv7zn/OyUqmkdnR0qADUX/3qV0eNa3R0tO7v2bNnH7VdEQDU8847r27ZtddeqwJQr732WrVWq/HyQ4cOqU6nUzUajerg4CAvf+WVV/jcimNVVVX96U9/qgJQr7vuumOOQULirw26X98P+vr6jlpWrVbVz3/+8yoA9a233qp77aqrrlIBqD6fTx0aGqp7z+WXX64CUL/97W/z8nK5rM6ZM0c1mUzqli1b6rY1Pj6utrS0qE1NTWqxWOTl9P/PK6+88r6OQULibx30HX7VVVfxMvqstbe3q8PDw7y8XC6r5557rgpA3bZtW912Zs+erQJQ16xZU/eZisVialdXlwpA3bp1Ky+n77fbbrttxnHN9B0703e3xF8Gp4QlgOByufCtb32rbtmZZ56Jz33uc0gmk3j88cfrXrvkkktw4YUX1i2r1Wr40Y9+hKamJtxzzz3Q6XT8mk6nww9+8ANoNBr86le/4uU///nPAQDf+MY34PV6ebnZbMZdd931vsf/1FNPYWhoCBs3bsSVV1551OttbW3ve1szQVEU/Pd//zfsdjvuuuuuOgvEvHnzcOONN0JRFPzyl7886r1r1qw5KnLkmmuugV6vx9tvv/1njUtC4kRhzpw5Ry3TarW46aabAACbN2+e8X033XQTZs+eXfeeu+++G1qtFv/5n//Jy59++mn09/dj06ZNOO+88+q20dLSgltvvRUTExN46aWX/hKHIyHxocO3vvUtzJo1i//W6/U8LX+s75677roLJpOJ//Z6vfjmN78J4Mj3tcTJh1PKEnDGGWfA4XActXzdunX4r//6L+zcuRNXXXUVLz/rrLOOWvfQoUOIx+OYN28evvvd7864H4vFgt7eXv57x44dAHDUFxIAfOQjH6kjvcfDW2+9BQC46KKL3tf6/1scPHgQ+Xwea9asqSPWhPXr1+O73/0udu7cedRrZ5555lHLDAYDAoEAEonEBzJeCYkPGrFYDHfffTeeeeYZDAwMIJfL1b0+Pj4+4/tm+qx3dXWhvb0dQ0NDSCaTcLvd6OnpAQAMDw/P6JM7fPgwgKlED2kLkJA4GjN997S3twPAjN89er0eq1evPmo51XPM9P0mcXLglCKsgUBgxuVNTU0AcJRJm5aLiMViAKa+SO64445j7iubzfLvtN2Z9q/X6+H3+//EyKeQTCYBTEV8fBCgcR4rSouW0zhEHMufo9frUa1W/0IjlJD46yGZTGLlypUYHBzEWWedhc9//vPwer3Q6/VIJpO47777UCqVZnzv8f6vGR4eRiqVgtvt5v9PHn300eOORfz/REJC4ghm+u7R66eozUzfPX6/f0aR6Fg8QOLkwSlFWMPh8IzLJyYmAOCoGKmZwsVpncsuuwy///3v39d+6T3hcBhdXV11r1UqFUSj0fc1nU8fzGOpOn8uaJx0PqYjFArVrSch8WHGz372MwwODuK22247Sv3s6enBfffdd8z3hsPhGQsNp/9fQz+ffPJJbNy48S80cgkJiWMhGo2iWq0eRVpn4gFa7ZRrslKpzLgtmimR+OvglPKw7tixA5lM5qjl1OJw+fLlf3IbCxcuhNvtxltvvYVyufy+9nvGGWcAALZu3XrUa6+//vr7ViBXrVoFAHj22Wff1/o6ne5/pW4uWLAAVqsVu3fvnlFFfeWVVwAcOR4JiQ8z+vr6AACf/vSnj3ptps/yn3p9YGAAo6Oj6Ojo4C85+ky/9tprf+5wJSQk3gcqlcqMcYsz8QCPxwMAGB0dPWr9vr6+GdVYIsJyZvEvj1OKsKZSKXz729+uW/bOO+/gV7/6FVwuFy677LI/uQ29Xo9NmzYhFArhxhtvRKFQOGqdUCiE/fv3899UjHTnnXciHo/z8mKxiK997Wvve/wXX3wxOjo68Ic//AH/8z//c9TrY2NjdX/7fD5EIpEZxzgTjEYjPve5zyGTybABndDf34/7778fBoMB//RP//S+xywh8bcKylekLzLCzp07/2Sx5H333ccxeMBUseZXvvIV1Go1LggBpgo758yZgwcffBDPPPPMjNvq6elBPp//vx2EhITEUfja175WZ+eJx+NckyJ+PhcuXAin04knn3wSk5OTvLxQKODGG2+ccds+nw8AMDIy8kEM/ZTGKWUJWLt2LX72s59h27ZtWLNmDeew1mo1PPTQQ3A6ne9rO9/85jexe/du/PSnP8VTTz2F9evXo7W1FZOTkzh8+DDeeOMN3HnnnVi0aBGAqQr6TZs24Uc/+hGWLFmCv/u7v+McVo/H877brxqNRjz66KO44IILcOWVV+Khhx7CqlWrUCwW0dvbi5deeqlu6uJjH/sYtm/fjgsvvBBr166FyWTC0qVLcfHFFx9zH//+7/+O1157DQ888AC2b9+Oj370o5zDmslk8MADD6Czs/N9jVdC4mTG9FQLET/+8Y/x+c9/HnfffTduvvlmvPLKK5g3bx4OHz6MP/7xj7j88svxm9/85pjvX7NmDZYtW4bPfvazcLlc2Lx5M3bv3o0VK1bg1ltv5fUMBgN+//vfY8OGDfjkJz+J1atXY9myZbBarRgdHcX27dsxMDCAUCgk2yhLSPwF0NzcjFKphCVLlmDjxo0ol8t47LHHEAqFcP3112Pt2rW8rsFgwE033YTvfOc7WL58OS677DJUKhW88MILaGlpQUtLy1HbP+ecc2C1WnHvvfciFouxN3bTpk3STvfn4kTnav01IGa47d+/X924caPqdrtVi8Wirl69Wn3uuefq1n8/OWq1Wk395S9/qa5fv171eDyqwWBQW1pa1DVr1qh33nmnOjIyctT6P/rRj9SFCxeqRqNRbW5uVq+//no1mUz+r7PchoeH1euuu07t6OhQDQaD6vV61bPOOku9884769bLZrPql7/8ZbW1tVXV6XRH5dhhhhxWVVXVRCKh3nrrrercuXNVo9Goulwu9eMf/7i6efPmo9b9v+TUSUicSOD/57Ae718ikVBVVVX37dunXnzxxWpDQ4NqtVrVM844Q3344YdnzIVU1SPZkP39/er3v/99dcGCBarJZFJbWlrUm266ibOepyMcDqtf/epX1cWLF6sWi0W12Wzq3Llz1U9/+tPqI488opbLZV5X5rBKnGo4Xg6rmAtOONb3En0fJZNJ9frrr1dbWlpUo9GoLly4UL3vvvvqsscJtVpNveuuu9Suri7VYDCo7e3t6le+8hU1l8sd8/vt2WefVVetWqXabDb+P2WmcUr876BR1Wm9yD6EGBoaQmdnJ6666qoZW51KSEhISEhIfLhBNh/ZJvVvE6eUh1VCQkJCQkJCQuJvD5KwSkhISEhISEhInNSQhFVCQkJCQkJCQuKkxinhYZWQkJCQkJCQkPjbhVRYJSQkJCQkJCQkTmocN4dVo7n9rzQMCYm/Dajq7Sd6CMeF/MxKSNTjZP7M3n///Vi7di30ej23AQWmGk3Q37VaDQCgqio0Gg1oUlSj0aBSqUCn00FVVUSjUW7bXavVYDQaYTAYYDQaoaoqDAYDb0un08FkMkFVVaiqik2bNuHhhx+G2Wzm/dK+6Cf9Xq1WeZ1qtcrLab+VSgV6vR7lchl33HEH7r77bt6GoijcFlVVVdRqNZhMJlQqFSiKAp1OB4PBgEqlwmMuFovQ6/W8jWKxiEgkgmq1CofDgYaGBiSTSVSrVVgsFlQqFWSzWVgsFuRyOaiqCq/XC1VVUSqVkMvloNVq0djYiHK5jEqlglgsBofDAWCqKYDFYoHL5YLD4UC5XEYul0OxWMTs2bMRi8UAAJFIBIFAAG+//TbeeOMNPPbYY/jGN76BLVu24I033sCvf/1rbN26FaFQCLt27cLExAROP/10DA0NoVQqwWw281j8fj9aW1vx1ltv4Sc/+QleffVVzJ07F48++ii6u7vx2GOPwel0QqPRwGq1IhQK4dJLL0U+n8ehQ4c49eDqq69Gb28vEokEqtUqqtUqstksisUistks319LlizB4cOH0d3djUqlgsnJSe7QZTKZMDk5iWKxiHvuuQff+973UKvVEAqFYLfbkc1msXTpUixatAif+tSn8LnPfQ7nn38+59O6XC60t7fjoosuwj333AMAuOKKK/D888/jYx/7GB599FG0trYiEAhg//79KJVKUFUVc+fORTqdRjgcPubn5ZRqHCAhISEhIXGyoLW1FTqdro4kii09iWDSa8AU2SRCSyQDALxeL/r7+7F3715Uq1WUSiW4XC6k02nYbDYYDAaUSiUUCgXo9XreBnVmmg5VVaHVarkZjUajQa1Wg06nQ7lchlar5TERtFotE2Tah6IoMBgM0Ov1sNlsqFarTGyJhIrvI0JM27darUyYVVWFxWJBIBDgv4nQarVaVKtVaDQaJt4mk6nuPOr1elgslrrj0+v1cDgcMBqNqFarMJvNMJlMqNVqKJVKTLCNRiOKxSKPy263Q1EUFAoF3k88HmciPTY2hmw2i1qtBrPZDJvNBqPRCL1ez+M0GAw8bqPRiMbGRkQiESiKgnA4DFVVkcvlAEw1DtJoNHUPB0T26Dzm83kUi0VUq1V+cKBrZzKZUCqV+DzTAw+tJz4MGY1G1Go17u5Fyw0GAwDwAwV17lQUBaVSCcFgEG63G6qq1rV3N5vN0Ov1KJVKMBgM/LBiNBpRKpV4LOJD20yQlgAJCQkJCYkTgGg0Co1Gw4SLSBQRUfpJBA44Qr6I9ABThEKn02HlypVYvXo1SqUSUqkUbDYbNBoNdDod7HY7mpubUalUYLPZoNVqUSwW0d/fDwDIZDJMTAi1Wq1OQSWiIRIcInD0j4gojZneUy6XeVt0jEReaJl4zLQ/GpNOp+P32O12WK1WGAwGVouJ/InnUySItA2TyQSLxVJHYu12O/R6PQwGA8xmM6vRpVIJ5XKZCauiKDxWu92OSqWCeDwOjUaDDRs2IBgMQq/XIxAI4L333kM6nUalUoHFYoHFYmGCTMTPZDIxsTeZTJg1axbGxsZQKpVQLBZRq9WQTqeh1+tZMQcAi8WCYrHI65hMJhiNRmQyGSas4jEbjUbulEcPABqNBoqi8PGJSjqdI1Ls6R4i4k3bJ0JLD0Kjo6OsmGezWb6m9ACTy+VgNpsBTJFeg8HA14seho4HSVglJCQkJCROAIjEEIgYEvmbrraKhHL6uvSF73Q6ceaZZyISiSAYDCKRSKBUKmFoaAjpdJoJmVarRTQaZRXu1VdfRT6f5+3SuLRaLZM72pdIIgGwMgqgTiklokoEp1gsMnEVySWRUVJ0p6u34hjoNSJi4j8idiL5F7dDZFo8Z/S7Xq9nZZaOjx4K6NySKk3Ec3JyEuPj4wgEAjjttNOQTqfh8/nQ0dGBt956i0mlxWJhwqfVapmoGY1G3q7FYkFzczMOHz6MQqEAo9HIdoUlS5bUEdb29nZks1mUSiXUajV4PB4EAgG+1kQ8STEmkt/S0gKr1YpSqYT29nYUi8W6c0L3mNFohNlsxuDgIL/m8XhgMplgs9nY3jE2NsZEvlAoYGJiApdccgl8Ph+y2Sz8fj8r0waDAalUihVuUt4tFgtsNhtfi+NBElYJCQkJCYkTACJXInEj9ZJInKi20tQ6QSSV5At1u93YsmUL3G43stksNBoNEokEyuUyRkdHkUgkMDQ0hGQyydPpAJDP5/Hyyy8jl8vVkTkaA/0uqp7TFVBxSp+USHEKm6aqiSgRkaXt6PV6Pv5KpcIESiS9InkWya7BYIDJZIJGo4HFYoHZbOZxk5JLRF1UjkUFmRRYIqSEcrnMRJt8r6RsptNp7Nq1C5VKBYVCAcPDw4jH49Dr9TCZTHC73WhubobT6YTP54PH48GiRYv4fBkMBlSrVeRyOWSzWWQyGYyPj7NtolKpwOl0wm6387E1NjZicnISfr8flUoFPp8PgUAA0WiUFW06T36/HzabDTqdDmeffTYsFgtKpRIaGxv5eojXj5Rpg8GAvr4+voZNTU3QarVwOByoVquIxWLo7e3FmWeeyQprJpNBd3c3XC4XEokEvF4v5s+fj2QyCYPBgGg0CqvVyuo+2USsVutRD2QzQRJWCQkJCQmJEwixkAoAq3ykOhLRIjJCU+Gk/InElUiAy+WCxWJhJY88rAaDAS6Xi0lNOp1mv+fw8DAOHDhQV/QlTtmL08y0nEghrTP9WIj4ij5UIn6KotSRK3ofHcf0IjOaxhbJDW2fSDuNhwgjqZu0XDy/dHy0PypiE+0J9Bqde/F4c7kc2tvbMW/ePASDQTQ3N+OTn/wkNBoNyuUygsEgbDYbBgcH0d3dDYPBAIfDAY/Hw8dG/tWGhgZYLBZks1nodDr09PSwYtzU1AQAXKhlNpsxd+5c9PX1sV80Go3CbDbXkfAVK1YgEomgUqnAbDZjz5490Ov1aG1txcjISN3DAXllAfA+qDiNlN3Zs2fzeRkYGEB/fz8mJyeZ+Gq1WpjNZlQqFYRCIRiNRjidzroiPb/fz/eS1+vl8ynaXo4FSVglJCQkJCROAA4cOHCUqkTkSCRhRJBIgQWOEC2RLNL6Ho8HnZ2daG1tRbFYRDqdZoXO7XYjmUzCarXCarWyWrh69Wpcf/31WL58OZMecSqcCDSAuulbkViLaiaAOhJLxyQqpAaDAYqioFKpoFQqcYoAjUksvhItEqRykio7nfxNHw8RdlH1pZ/TiS8wZdWg9acfR7lc5vd1dHRAo9EgHA4jn8+zEmyz2ZiA2mw2LF++HNlsFgMDA0in0xgaGoJer4fVauV9HD58GPl8Hh6PB62trTjnnHNgNptRLBahKArbJcxmM0/F0/mpVCqYM2cOF1AR+d6zZw8XNWUyGej1evaakleVrikVRtH5yGQy0Gg0CIVCUBQF6XQafX19/Bqpw0TyifiaTCZOWrBYLDAajYjFYqjVavB6vUgmkyiVSuwtpmva1tZWZ4GZCZKwSkhISEhInAAsXLiQ1VL6R0VNRB5EsicWXomKIS0Tl2u1WrS3t7PamMlkoNPpkMlkuOiI4qQAYO/evUz0RJ+oqH7S9L1oQaAxEYEU1c/ppJaWiYSY3kvbE6f/6Xdx3+J5ILIrKr90Hmif00mqeHzAETuFGC1GpJQsByKIuNIYbTYbTCYTHA4HLBYLUqkUli5dikAgAAAYHx/HwMAAisUi4vE44vE4JwAAR3zMyWQSOp0OyWQStVoNExMTcLvd0Ov1GBoawoIFCwCAFXQ69y6XC1qtFn19fSiXyygUCqx2EnEkYp/NZvl9lOAgnidRCW9sbITf7+f7wOFw8DrkGaZiNfIT53I5eL1eFAoFdHZ2sg2ACPfs2bNRKBSg0+nQ3NzM6QqUOOD3+4/7eZGEVUJCQkJC4gSAopRmInYiORPVQNFfKU6Di+orMBVBRCrh/PnzsW7dOlxwwQVYv349e11dLhfOO+88AGDvJm2XQGMgEiQSOFGhFBVMURWdHts1PQWACI/oYyUQKSSfpUiIab8iYRX3LxJ9cRyiai3GYZGqS0RZLPIS3yN6S7VaLSYnJzm6KpVKIRqNoqenB+l0msldNptFMBjkbZZKJVQqFSxbtoz3SwkElUoFnZ2dGBwcxMTEBPL5PAqFAvbs2cOFWJlMBsDUQwpluSqKgnw+zw9A4sONmGVLxJ+uQ2NjI58vShuggrx0Os35ti0tLXA4HFi5ciXK5TKr462trfxwNT4+zv7kPXv2sDe1VqvB5/Nh7969/PfixYuRTqcBTJHwrq4uthwcC5KwSkhISEhInACQP3V6gdV0JVAkXNMtANOn3+l3sVBKVBOB+nzXfD5fR3ZFSwJwpLBqJg+o6GWdqcqbCNhMRVrTx07V6kRIiYSKKiyRHZHAirmuInEV7QviPsVzJBJzkaxPtyFMV55Ftbe9vR2RSAS7d+9GKpVi9TSTySCbzaKxsREtLS08TS+qy0NDQygUCpxJSj9jsRhMJhOKxWJdcRhN+dO0vli4NtPYdTodvF4v+5fpGomFfRStVqlUkM/n2UNLiRNWqxV2ux2HDx9GuVzGe++9B1WdynwFgOHhYeTzeVQqFVitVo7KqtVqmD9/Pnt9o9EoCoUCj3VkZITH43Q6MTY2hkOHDh3/83LcVyUkJCQkJCQ+EIyOjjK5mE5CRZUMOOJZnU5KxCIlKp4CwNPLRAiamprqVFrapjjNL1oQyEMqqpQi0RXJp1g4Re+j99C64t/T7QHHglisM93rK/pYSSGlcYvbFQnq9GM41u+kKIskXLQOiCr4ueeeC2CqIGn9+vVoamrCqlWr0NTUxFPh4+PjyOVydSo1FShRxzGtVou2tjYoioI9e/YgFotx7qnT6YTD4YDVaoXX6wUAtnKQT9dgMMDj8XDOqcfjgV6vRzgcrrsmWq0WixYtQmtrKzo7O+vuK7KUkPJvsVjg8XjYOqAoCmKxGBYtWgSNRsOklSwddA7JhtDf3w+DwQC32133cENKbqlUYjsE5cQeD5KwSkhISEhInAB0dnbWEVDRO0pKFBHR6SRVVMmAenUNAJMlil8ivyN5HCl+ilqSilaD6ZFPM5E+UZEU/Y8iMRFVW9EnOV2NnW4FmK5+0rpim1paLpJuKtqaHltF4xRJ77EilKZ7XadHaYkWAWCqWGnTpk3w+/1YtGgRgsEgJicnedp+cnISCxYs4CYOYlEaPbCQInv48GF4vV643W6YzWZ0d3fD4XBAURRusTo5OQmTycTB/FarlT2lDQ0NcDqdqFarKBQKXHBF547sJ7Nnz+aoKVVVeRqfGhl0dXVBp9NhbGwM0WgU+XyeFWK73Y6GhgY+D/ResaEFWRDC4TDS6TROP/30OhvLLbfcArvdDgBwOBy45ppr4Ha7MXfu3GN8UqYgCauEhISEhMQJgEgoxOnqcrmM3/3ud3UFTkRcxZB98o2SukXT1QRSwBRFYRJMRTqkRpIiJ6qg0wnm9PERKQVQR6LF7dDvYiHU9O2IiquoFotT+wR6TVRCaR+i1UFRlLpiLFKCKYVA3LfY2IDOB6m1RFSJmNI6RPTFqCyfz4crr7wSW7duBQCOiTIajRgfH0cwGERLSwsMBgM6Ozvh9XqPOgcajQaBQP7/oEsAACAASURBVIC7WJXLZUQiETQ2NrJ6TCkB+Xyex0dT8OVyGcPDw5icnIROp2MLgHg9KMf3xRdfhKIoWLBgATdcEH3Ehw4dqjsXdrud29KSn1Zs/UoJFKTKUjFaOp1GQ0MDWlpaON7KaDQiHA6jWCwCAH7wgx+gtbWVVdfjQX/cVyUkJCQkJCQ+ELjdbiZA0zs5DQwM1E3Ji4RSrPQWkwWAKfJHXkFFUWA0GhGJRPDmm29y9illZRLZAY70qqdtUctOApHI6cqkqD6Kr4u+V5G4iqBjECOsKGe2XC7XWRfE4xb3QT/F8yP6YamYKR6PY8eOHZgzZw5ntJKiaDKZeBxEzux2e914qV2rSDRpnPQ3Zd/abDYAU9PymUyGi6NaWlowOjoKu92OXC7HpJNak/b09MBisaBcLmPx4sVYt24d/vCHP3C7U1VVUSgUeDwmkwm5XI6bRFDxFaUc0IMOKdjifaaqKoaHh9HW1lbXrED0KtPfbrcbsViMr0EikYBGo+FjpweiUqnE92CxWMTChQuRSCTw3HPPIRKJQK/X41Of+hSi0SjGx8eh0UzFrAWDQQBgb/KxIAmrhISEhITECUA8Hp9xGpSm6qdPYYtqGRUDictE8hiJRKDRaFAsFuH3+7Fy5Uquyv7tb38Lu93OHZaImIiWAPIxikRQJMy0H1JERXIp+iIrlQp7GmmMRKZEdZS2IU7hi+rjTOoq7U8k2mK8V6VSwde//nXeBgXyu91ueDwe2O12GAwGTE5OwuVyIZfLwWKxoK2tDatWrYLD4eC8UPE80/iICJIaSZ3F+vr60NLSwqRMURQkk0kEAgE4nU6kUilotVr4/X5MTEywEkrnolKpoLe3F9VqFalUih8wNBoNbDYb8vk8VFXlrlPpdJoVWJPJxIS1Wq0yKadCqFqthg0bNuDZZ5/F7t27+RrZ7XYuuKLzSh7WOXPmYGRkBKqqwu/3I5lMwul0IhqNQqvVolQqcVMDajKgKAp6e3thMBgQCAT43lm2bBmee+45PufiPUNq/7EgCauEhISEhMQJAKl2omeTVEFRORXXESvCRRIrdpQi0kJV5qVSCalUqi6vFJgqjqFiFyKs5XKZf4qkk8gsFQ6J5AqoV15pHGKBkqjsEfkUVVk6NpGETy+cEt83vRsXEVQiTLVaDfv378fcuXN5Cl2c0k+n04jH43A4HAiHw0ilUli0aBFeeuklbN++HQ0NDVi6dCmfY7oO4vkjYkzbbW1txYEDB+B0OhEOh+H3+zE2NsYV98lkkpVvg8GASCSCpqYmhEIhmM1mjqAym82wWCwIBoPwer2wWq1wOBzIZDJIJBK8//HxcW5HSx5kipwSi9HmzZuHUCiEZDIJm82GZDLJnlRS2onQU75qW1sbhoaG0NbWhq1bt6JWq8FqtcJgMMBisXC6hEajgcfjQSwW43ujVCpx6kGtVkM2m4XBYMCiRYuwZcsWbkZw5pln8nUV7+1jQXpYJSQkJCQkTgCo0hs4UhRDXZ+y2SxPGRNBE6v4Rd+lqKwSSRQ9nKOjo4jH4wiFQgiFQqy+VSoVjIyMAAD6+vp4mpu8hhS5Rdmc9PpM3lZRDRX9qEC9P3a6/1WESMJF0DFOJzSikguASSXtLx6Po7OzE0uWLMGyZcuwfPlynHHGGeju7kZ3dzeWLVuGWbNmYcWKFVi0aBF0Oh3Wrl2Lc845B4lEgiOngCONEcRjJRsF7S8UCqGpqQkTExOwWq0YHh7mIjexCt5ut8PhcKCjowPZbBYA0NLSwmNfunQpk9JoNIq5c+cik8kgFAoddW1JeS0UCjw28bwoisLJEaQWT05OQq/XY/bs2XzPEOkHgGw2y5FbO3fuZE9wLpdDKBRCuVzmLl0UKabT6eoK/Zqamvhhp7GxEVarFddddx2Gh4cRDAah1+vx+uuv87nT6XTw+XzH/bxIwiohIYHbcMeJHoKExCkH+sIXA+sffvhh/PKXv8R7772HRCLBU/YAuBK+t7eXyepMle8ajQatra1MLsPhMBobGzF//ny0t7cDmFJ3rVYrFi1aBAA47bTTAKDOw0jjA47EOhFpJRJLBHk6cRU7d9G2xMp/4EghkxijRevSsYj5tNOLsEQCT8tEMk3+VLPZzC1b6W8itxQJRcdjsVjgcrmQzWZ5TGLHLMo9pYKt6YkJuVwOzc3N0Ol06O7uhtPpZJXR5/Mxwevo6MDExARMJhOq1SoGBga4in/nzp1YvXo1/H4/SqUSE18K6zcYDKhWq3UZvlQ8JR4XXau9e/cimUxCURTYbDYkEglYrVZuYEBeZ2CKTJvNZiQSCWSzWSiKUqfe07UWo6iy2Sznw9I1HRsb4/NE6vHPfvYzKIrCBVx2u50TBtauXcv34rEgCauExCkGSU4lJE4OOJ1OVuBomvTNN9/Eyy+/jGw2i+uuuw4PPvggf/GTXeBb3/pWXSV7sVisU1yBKUJKnZTmz58PVZ1qe0rJAeL2gKO7WxExoWIdUVGdrsgRmSN1ViRRYqHUdE+sGOM1UzGZSFxnwnRlVyzCojivfD7P0+jkJ6X9m0wmGAwGmM1mtkTo9XoYjUYmWaIyLI6Z9kM/9Xo98vk8QqEQarUaJicnMTIyUqduxuNx7lal1+vR0tLCflY6Ho/HA1VV8eabb0Kv18Pv92NkZASZTAZOp5OVTDr3FG9GU/BicwJVVdHc3Ay32422tjZYrVakUin2NlP7VLPZDLPZzLaGYrHIVgMismKnLLpn0uk0W0XEXFwi82RPmTVrFhoaGpDP5zE6Ogq9Xg+Px4MlS5bg0KFDmJycxL59+/DEE08c9/MiCauExIcUkphKSJzcyGQyeO2111AoFHD48GHs2LEDHo+Hp+MVRcG7775b1zaUfIfFYhG5XA4vvvgifvrTn6JQKKBQKKBYLB7ltWxqauLKbafTWVfgMz1manqRFUEkr6Knlkie2O6UXhP9lWIjBCKvhOlT/WI6ASGdTvO+xXa2NDZxuxrNVKh9rVbD4OAghoaGoNPpcOjQIRw8eBC7du3CCy+8AI1Gg8HBQfa97t69G3v37kVvby/nnqbTaeRyOZRKpbrCMDo/pVKJI7OKxSIr1waDAbNmzUKpVGIyS8QWAN5++20cPHiQQ/mJbC5btoyJsMfjQS6Xg6qq8Hq9SCaT7FGlgjEAKBQK/IBAlgtqVGC326HT6RCPx2EymdDe3o62tjZUKhWMjo6ira2NleFarcbHLha6USIAXScx2kvsZEavk7pL5ymfz9ep0Xa7HWeddRbOPPNM9Pf3Y8uWLThw4MCftATIoisJiQ8ZbsMduAO34Q7cxr//b94nISHx14HRaMRTTz2FVatWoa2tDW+//TZcLhe3yySCSNPAtVoNjz32GDo6OvDwww8jHA4jHA5Dr9fjhz/8IVf3h8NhaLVaeL1e5HI57Nq1C7FYDOl0Gj6fD5lMBsVikYuxRLVWzGidKVZKnH4XK+dJNSQFslarwWKxMFGl7YmJAsCRzli1Wg2lUonXF60CpVIJzz//PC699FKUSiUMDQ1xtyUxPYDOGf09NDSEbDYLVVVx4MABTkkgNXBiYgLVahWJRAIAOLGBrBapVApWq7XOsiGS82q1ipGREeRyORw6dAhutxsLFixApVLBrFmzYLfb4XQ6MTk5CaPRCKfTiXg8DrPZjFQqBYPBUBfBpdVq8c4777AC+t5776FQKMBqtXIYPx2nOP3u9/s5UYCSBMh3OjY2hsWLF2NsbIzzX6mAKhqNwu/3cwEWxXSZzWb+WSqV4PP5EI/H2atKDwXlchkejwelUon9tDRO+jufz7PtYnh4GKeffjo+8YlPYNeuXdi/fz8qlQrOO+88vP3228dV0wFJWCUkPrR4vwRUKrESEicGzz//PPdo7+3txZo1a7B///469ZDIEvkWn332WXi9XvT09LDaqtfrEY1GmeBRtTi9FolE8O6776JYLMJoNHLWZ61W4ynsxx9/HPPnz4fD4WDSSfFI0/2n4vQ7kTsiOdMVWipMEu0DpBiXy2WOzwKmFM7FixdzvFQ2m8XBgwdZNc5ms9ixYwePb3rUlUiiKe6pra0NBw8eZIKXy+Vgs9lgNBpRLpfR3Nxc55cVVVAal1h5LyYmKIqC0dFR+P1+hEIhGAwGjqpqbW1FLBbDnDlzUKvVuGOUmAJAMVR0HokMUycri8UCo9HIIft+vx/RaJSzdMnmkcvl+Bzo9Xr2qhaLRWQyGfT09PCDDE3/E6Gl+0aMFLNarVzZXygUEI/H62wafr8f6XQaZrOZi71IbY1EIigUCnwtzGYzrFYrZs2ahcWLF8PhcGDz5s3o7u5GMBjE+vXrmfBOL8KbDklYJSQ+ZCCSKtVSCYmTG1u3boVOp8Ptt9+ORCKBZ555hv19hUKBlVBSPwuFAjZs2IDNmzfXeSHF6nCaCqfioGq1WpevShFPhGQyiVqthl27duGLX/wivv/976Otra3ONkAEEAATE5EcigqqTqdjoks+UJEAkjVBURQEg0HOP21sbMTevXuRy+UQiUTQ0NCAZDKJZDKJ+fPnI5fLYdu2bchkMli+fDlHJ5VKJS4+EhU6nU4Hl8vFQf2kkJrNZp6mJsLZ1NQEVVUxMTHBBGzevHk8HU/HJSYVVKtVLogaHh5GMplkhZemwCmftFwuw+/3cytW8pI6nU7EYjF+GCFbAdkqVFWF3W6HxWJBe3s7+vv7uTiM7AcGg4HzT8VCPPJGA0ceesTEA/rpcrm44xo90IhT93QOROWaLANiDJndbke5XGaVl4rJLrjgAiSTSfj9frz77ruIRqPIZrNwOByo1WpwOp0IBoN1aRfHgvSwSkicwpA2AAmJEwciUBQVFIlEeNqVvvDF7NDHH38cZ599Nrq6urBmzRp4PB4A9dXx5CklkuH1enkZFdhQ9bzNZuN4okqlglQqheuuuw7PPvsscrkc+xbpHym6YjqBSDJoupjUVKvVWqeGEsFKpVLYvXs3xsfH8fjjj2Pnzp3YtWsXDAYD+vv7oSgKQqEQxsbGoNFokMlkkMlkEIvF4Ha7USwWkUgkkEwm8e6770JRFO6yRGPM5/PIZDLw+/3IZrPI5/N1hWFarZaV01wuV0f6yc9JhJ2m7gHUKZGJRAKqqiKbzXKVPqmjRHBJgS0Wi9y2VCSOJpOpzv87a9YsVlCBKWLs8/kwODjIVfk0PiKbAPgn+UdpPHSsdHylUglNTU0wm81oampCJpNhgk0KstVqxdlnn83WFPLj0n1EiiitT8dC157u3yuuuAKvv/463nnnHWzduhWhUIjj2ui6mc3mo9IjjgWpsEpInMKQZFVC4sTBbDbDZrPVKZTAlJdy586dTFapVWhLSwsymQyAI33hfT4fEokEZ2xSoRMpVlQYBUyRLavVimQyyX+LnY0cDgey2Sx+/OMfY/v27bjuuuvgcrl4Sl9UwUhpnB4vJRYliconkWIqIIrFYohEInA4HDCZTNi+fTtisRi6u7thNpsRDAbZu9nb28s+02q1CofDgV27drHaS+RLr9cjHA5j0aJF7NPMZrNoaGhgZZeOlbpvUSZqrVZDe3t7XWMEh8NR5y8Vjxk4Qo7j8Tg6OjowNjaGYDAIjUaDiYkJ9rxWq1Vu+arT6Th7NRAIYHR0lB8CqFCNxhSJROD1erF3714sXboUAwMDXLxFrVBFPy1dm3w+j4ULF2JiYoIVdHo4KhQKPEZS44nYNjQ0MEnduXMnX/NKpYLh4eG6YrdqtQqLxcJJAaQSazQabNy4EZ2dnRgfH+cIq6amJjQ0NGBwcJCVXK/Xyw9DdF2OB6mwSkicghB9q9LDKiFxYpDJZBCNRhGNRhGPxxGNRnkKeXx8nHNXBwYGYDAYsHr1arz00kuszJFq5nA44PF4WE2l4hcATEbIuypWfut0Ong8HlZnSfEqlUro6enBLbfcwgRDjNYSp5jL5TL7ZQGwN5bISzabRTQarcuSrdVqiEQiMJlMmJiYwL59+1Cr1WC32wFMEcHOzk7odDokEgnYbDYsWLAAJpMJo6Oj2Lt3L2q1GtLpNBoaGrBt2zYMDQ3h9ddfxx//+EeMjIzAZrPxeU4mk8jlckin0zz97XQ660icqqoYGhrCwMAARkZGWDHMZDIol8soFAqIxWJ1kVZNTU2sZvb398PpdMLlckGn0yEWi7GlIZfLwePx8INHpVJBc3MzhoeH6wrdFEVBuVzGnDlzAEzFng0ODqJcLuPQoUN1im8gEEC1WuUxUGIAPTgEAgEmxgD4ehABr1QqHFkFgEP+Ozs7YbfbsWLFCj62crnMUVZicV4ul+NIMLfbze2Ek8kknnrqKc6ZXb9+PQKBAFasWAGv14tAIACbzYbdu3ezvYSU5uNBElYJCQkJCYkTgIaGBhiNRjQ3N8NqtcLpdKK9vR2HDh1i1Y26B8ViMRiNRia3k5OTPA1MhUs0Ve/z+dDZ2Yn29nZ4PB44HA6OytJqtWhsbITf74fP52PvI3BkuttoNHIV+a233ootW7ZwTJIYYSR2WxKzN8lKQArxH/7wByay2WwW+/btAwDEYjEA4OgnsjLs2bMHyWSS7RHBYJDHl0qlEAwGUa1WEY/HsW3bNiiKgpdeegnBYBAmkwk9PT3o6+tj0un1eplYkW0hHA7DYDBgaGgI+Xy+rjCMyHehUMDrr7+OarWKgwcPYvfu3XVJCQaDAWvXroXRaITf70cikcDQ0BCKxSKsVitOO+00uN1uNDY2IhQKQavVwufzsW3AarWiWq3y9aPc2PHx8ToyKBL/arUKq9WKXC4Ht9vNBFlUfQFgcnKSs2UtFgtbBUQfbqFQAADOniXrRCqVwp49e1hBFpVWer/Y0MFoNKK9vR0rV67E4OAgDh8+jEgkgq1btyKbzcJsNmNychKTk5NYunQpPvOZz+Ciiy7Cueeei3379rFd4k9ZA6QlQEJCQkJC4gSAqrszmQyMRiNPj4+OjgIARzzpdDokk0kYjUb09fVhyZIleO2117iLEgAOkycyQ0kBIhEg5ZU8pVR9TwSMpmopA5aKdx566CH09PRg06ZNcLvddX7P6VYBsgWQ5zUajcJms6G3txderxf5fJ4Lnmw2G8bHx1EulxGNRtnOQD7XaDTKCvDg4CBSqVRdtbrT6UQymYTFYkFjYyNXqA8NDaFSqbD1gZRVUjApIqxUKiEQCPA5crlcrFwDR5TZ0dFRFItFJJNJJlekSFNhHKmVlHxgt9tx+PBhpNNpLF68mLtnEekke4D4e0NDA9sk8vk8k0KdTscNHwwGA1paWvhcUcoEEVWPx8MdqlKpFEwmEx8TeWtFC4per4fVakUgEGCiXC6X4XK5UKlUuD0tFV2JiRFutxt///d/j2KxiGeeeQaHDh3Cgw8+iPfee6+uMI/OVzKZRHt7Oy644ALs2rULfX19OHDgAMbHx9HZ2cmzAseCJKwSEqcgpHdVQuLEQ1EUOBwOAODqbJruBqbIX2NjI+655x7odDpuIdrX1weXy1Xn/wOOFN6QckZh92QTUFWVyRGAOlWRfKZETmgqGJhS4N59913cfPPN+Ld/+ze0trZyQdX0OCIxP7VcLuP555+Hx+PB5OQkMpkMduzYgVgsxqSHiqE0Gg0sFgvy+TxKpRKSySQCgQD7QE0mE0ZGRrhtKE1553I52O12ZLNZFAoFbhkai8XgdDqxe/duaLVatLe3Y2xsDOVymaeuSXWkfQDg1q06nQ7Dw8PcvSqZTGJ8fByZTAYmkwnFYhGRSATRaJQ9r1TURudlcnISGo0Go6Oj8Pl8MJvN7OkUO2BRK1Uim+3t7di3bx8/eJCvFgCT66GhIXR0dPA9RN28VqxYgeeeew6FQgFOpxNOpxMOhwMjIyMAwMVm9JBhMpkQDAYxMTHB1hGPx4N0Os12CBonAC7Smz9/Pj7xiU/g3XffRSqVYlXdbrdzcRURcnpwIDJ/8OBBHDhwAJdeeileeOEF7Nmzh4sAjwdpCZCQOMUgyaqExMkBUgldLhcURUEul0MoFILD4YDb7ea8TpvNhlKphK6uLqxYsQKRSATZbJYVMqowp8gmUtVIcTWZTHA4HHA6nax2iR2aaCyk9pEVgTyPNL2fTqfx9a9/HS+++GJdG1hxmpz+pvxOp9OJdDrNXaaKxSJOP/10KIqCcDgMnU7HBBEAOjo6eNobADc3GB8f52r9SqWCRCLBpIsIs9/vh9PpRCAQQDKZRKlU4vajlUoFFosFer0emUyGY5wymQwT/VQqhXA4zM0ASKUGplRaOn96vR47duzA66+/jvHxcSiKwgQvl8vB5/NxsgN1paLq+2KxCLfbDa/XC6C+09jg4GBdpivlpZIthFTrYrGIs846i69NPp/n4r2nn34aGo0G8XgcWq2WibbocyXSa7FYkMvl6rytiqIgmUxyswqtVsv3lcfjgdvtxjXXXIN58+bhscceQyqVQiAQgMfjgV6vx9tvv83RXETcM5kMstksKpUKq9IGgwFOpxNWqxWFQoEJ8fEgFVYJCQkJCYkTAIPBwGojTXOTKmUymbjdqqqqnNlJSimFylO1OJEKg8HAU6tihTt5IolcEomj/dByIq1iBitFGZFC+Nvf/hYbN25kogPUR1qpqoqnn36auy8RKezo6IBGo8Hw8DCKxSJPG6fTaVx44YXo6emB3++H1WpFX18fGhsbOfCfgvZpujscDqNSqXBeq8/nQ7lc5jxQOrcU2USWC5o6z+fzHB1GxNtgMKBUKnFObDweh9vtxtDQEIApFTydTsNut2Pu3LmYnJxEX18fK7zkTc3lctzRSqvVIhAIsLJI55KaGHi9XoTDYWg0GrS0tMBoNLIPWDznpD6bzWaMj4/D7XYz8QaOpDaIY1FVFVarFel0ui4ejc5bNpuF3+/H5OQkE2IiwIsXL2avdLVahcfjwT/8wz8wqX/11VeRTCaxbt06vgepiIruG4LFYkEgEEBTUxP27t2Ld955BwDw7LPPwmq1Ys6cOfD5fEilUsf9vEiFVULiFIdUXCUkThxIYSOFkohjqVTi6dtKpcIKHpGr7u5uVCoVVgAVRUGhUGCSQ4orTbdTxymLxQK73Q6bzVanbBIxpQKgUqnEflGakqafpCASIQbq81grlQocDgdCoRCMRiOSySQ2bNiAhoYGFAoFJs8ul4un45csWYJqtYr9+/dj4cKFOOOMM+D1elEsFplUi0U+xWKRX89ms8hkMlxgZbVauRDK7XbDarVy8ZDVaoXdbsfs2bNRLpfR1dUFt9sNYEqhnTt3LpqampBOp5HP57mdK2XkvvnmmwiFQujv70c+n4fH42GVkCLHstksisUiisUiF1yFw2EuXMrlcnydIpEIt7ENh8PsOyY1lFRkIrl0n+zbtw8TExMAwC1VGxsb0dnZWaeYklpKpL2hoQHVahWRSIS9w4qicK6r1WqFxWLhtACfz4eNGzfi0ksvxdatW/H888+jXC4jk8lAURQ8/fTT6OnpQVdXFxRFQSwWY3JMflmv14tMJsNpFxTd1dXVhUsvvRSnnXYak/bjflb+nA+ahITEhwN34DZJXCUk/sqwWq1MEimz1Gg0wmazcdW8GPhfLBa5neihQ4e4ApwKn4AjrU/Fan7giAJKKJfLnMtKxVPko6XqclL6RDJNRGj69ohM0bY+/vGPw+12Y/fu3WhsbMTw8DB2796NVCpVpwB7vV4YDAb8x3/8B8dU9fX1YXR0lNVOamlKflUi49TmNJ/PczX66OgoUqkUT/1PTEygVqtxQRGlHYRCIej1ehw4cICVvUQigYGBAZ6CJ9KdSCR4nBqNBu+++y56e3vR1dUFnU6H0dFRLF26lK8bTd1TN7LW1lbUajV+kGhqakKxWORuVERYqciJHh7sdjt7iinyK51OY8WKFfD7/VyYRQp0OBwGALS0tMBsNsPv9/PDkNfrxerVq+tIrqqqMJlMbCvx+Xxob2/njN+FCxfiiiuuQCwWwwsvvICRkRFYrVa89NJLUBSFUytGRkaYiNKDDnmnNRoN+vv7cfjwYRSLRW7MQGQ5Ho/D5/NxcdfxIC0BEhISEhISJwBUWU5KFHCEFFKwvahgkjeU+sGT/5CIrTi9TUVaRISJuJBKSmH5NIVLlgRSYymUHgAXaomV3+QdJZKqKAoXCJXLZfbNLlmyBLlcDocOHUKtVuOpbIvFgmw2y+ONRCLYsGEDXnjhBbhcLoyNjaG5uRmtra1sIQDApG7u3Llc+GSz2ZDJZBAMBjFr1iyk02k4HA7EYjGcddZZHNFEPkmyWlSrVbjd7rpMWSr6omOgh4pEIsGENR6Ps/1AVVW43W5s27YNWq0Wra2tGB8fR3d3N5NDOs+Tk5Oo1WpcIEX7oExZUkQtFgtmz56N/v5+ruhPJpOcGNDS0oKenp66ZAJqP+twONgbPHv2bJjNZrS3tyMSiWBgYADNzc3Q6/UYGRlhGwBFnG3cuBFarRaJRAKKouDFF1/Em2++yfer1WqFw+HA6OgoK7Z0z65cuRK/+MUvoCgKWw/MZjO3xNXr9ejv78dXv/pV2O127N+/H9FoFPPnz2fLhcViOe7nRRJWCQkJCQmJEwCDwQCr1crqGxFQKtYRfaXiF38ul4PRaITRaKwrmgIwY1tXMYOTFFBal95HhJksCmImKZFiUmWJ2IpWhqeeegqBQADd3d148cUX8alPfQrZbJY7ISmKwpFNpN6SNzccDqOpqQlvvvkmAoEAYrEYV50bjUa0tbVxvim1ZiVvKhG/lpYWjI+P8xR+Pp+H3W5HJBKBz+djolssFuFwODgq6qMf/Sh27NgBABy0L/px6QEhkUiwuguA1ct8Po/W1lYUCgU0NjZybFihUIDdbkdTUxM3hSBbg9g5S1SLAXCHqPnz52Pfvn1QFIVbutI1efrpp5nI6vX6utirZDKJJUuWoFQqob+/H9lsFtlsFi6XC8FgEJ/+9Kfxxz/+EVarFStWrMCqxiDzjAAAIABJREFUVatgs9kQiUSwfft2TExMoFAo4Mwzz+Tz6HQ6uWhsfHwcNpuNmwnYbDbUajU0NDTwfS1aRSgFoVwuQ6PRYO/evWx1SSaTeO+992CxWP4kWQUkYZWQkJCQkDghcDqdXGhFRVBEQmhKmabfAXAUkqqqSKVScLlcAI4E/hOxFVVWIgsEqgQXVVcCZajSNkmVJI8jvRaPx5n8EiFpamrC/v37odFoYLPZMDY2hsWLF2PLli1c2U9k22KxYN26dXjhhRcQCoU4m9XlcjGBEwvS2tvbkUwmEY/HMTExAa/Xy9PpbW1tTIypUUAwGIRer8esWbOYDHZ0dLCySsdntVrR09MDABgbGwMArsynnFrynAJTyiypuaSMLlu2DH6/HxqNBnv27EFnZydOO+00bNmyBeeffz43JqD90nUCjhR5EYGnqn+TyYSxsTF0d3czoSOyq9PpOMGAxmKz2VAsFrmJwMDAABdeNTY2chqAz+fD+eefzz7dcDiMAwcO4ODBg0gkEohGo3xOyUNLKqrRaKzLhgXAswANDQ3Q6/Xw+/11Vgi3241zzz0X77zzDmfMvvHGG8hkMvB4PACAWbNm1bV8PR4kYZWQkJCQkDgByGazdeontWUlckgkTwxUV1UVNpsNiqJwHikVY5EyKnYMomgi+keKLK1DpJaUyulKq5jVSsqj2NqVioKGh4fR1NSESqWCefPmoa+vDw6HAxs2bMCTTz4Jg8HA0/QajQavvPIKTzH39vbCaDRyeD2dG2oTOzY2xuSO1EQ6JwaDAdFoFIFAALVaDSMjIxypRMQyGo1yoRApkoqioFKpwGw2IxQKccJCIpHg/dpsNni9Xp7CNxgMrJzSddm+fTvvS3xooLgym82GYDDIxXOkflOaQq1W4xSA7u5uVmhNJhN2797NFgKyc5CqLF4Dumfi8Tiy2SyWLVuGw4cPY+7cucjn8xyVZTab0dvbi3379iEYDCKVSrHKO3v2bC4ao9gpAFiyZAmfZzoHZEEBwO1tH3nkEaxcuRLpdBrnn38+31PpdBrNzc0wmUxMbAuFAhwOB9+3qqpy04zjQRJWCQkJCQmJEwQxemp60QnlrJICB4D9gR6Ph6eam5ubmdSQekdTzrVajW0HVIxF3tPpkVT0HnFcYs4rgDqlVdzG5ZdfjkcffRQAuKNTPp9HMplkNc9ms3H2JhG7arWK5uZmZDIZDA0NwWw2AwBnl8bjcbS1tXG0EimHpPhR8dTY2BgH11P8FSUekGKtKAq3RrXb7bDb7Vi9ejWee+45Llaj80HvoRaxZrOZ7RGUYUteYspxDQaDqFQqsNlsMBgMCIfDPG0eiUSOigpzu90Ih8Nc3EapCYqisIeXCs+IzNPxU4asVqtllZaKncbHx9lqYbVaMTAwwH7e7du3cwestrY26HQ6burwz//8z7j33nvhdDpZER4cHGRiTHFqdC9Mt46QQk+K/rx58xCLxTA6Osr3idForCuw6u3t5fNBSvaxIFMCJCQkJCQkTgBKpRJPbSuKgnw+X/c7FQARMdDpdBwQbzAY4PV6odFoEI1G69q0EkhtLZfLmJiYQCqVQj6fRyaTYSKWSqW4A5ao2hHRE6eAicCKCQK5XI6zOon87Nq1C7lcDsFgEIODg6xWWiwWNDU1QavVchcmqvx3OBxcaU4tUKmQLBwOw2w2I5vN1k2fe71edHV1sRUAAE/l0zlKp9Mc69TV1YVMJoNYLIZIJIJ8Po833niDW7Amk0nOUhW9peRlLRQKTCgpvQEAR46RZ3XhwoVYsGABZs+ejXQ6zQVItD6pjBRHpaoqfD4fMpkM3w/U5atQKCCdTqNcLuP000/HypUr+dqQkkxqvEajwfLly2GxWNjnm8vlkEgkoNfr2UPc3NyMtWvXoqmpCbVarU4NJm80KanUInd0dBRarRYNDQ2YO3cuX6vGxka0traivb0dNpsNF154IUZGRmA0GhGJRPjBJxKJIJVKQVEUbmUbDAbR3NwMi8XC2bnHg1RYJSQkJCQkTgAolkkM8ScyJgbri9X4QP10PlX0kzdU7Pwk+l9FkCeVulkBYK8q+VJJbaUiLbGfPPlid+7ciVAoxFX51WoV/f390Gg0dR5bUjSpEp5azMZiMbY2RKNRAGAfL/0kAhoMBgGAp7+9Xi83BmhoaEAqlWLFmTpKkRoYi8W4Ep9IPPlUy+UyrFZrXdB/tVrlFAHquEXZscBUNy6bzYbTTz8du3bt4kIum80Gm82GOXPm4Oyzz8ZDDz3E6QJ+vx/ZbJbVWJ1Oxx2tVFVFPp/Hnj17+JjD4TBcLhefFypAo+tD8WahUIjvCZ1Oh/nz56OnpwcOhwPBYBD5fJ49peFwGO3t7fB4PNi2bRtaWlrw2c9+FhMTE3j00UfxyCOPsDWFpurJf0ypA5ScQFm8FMNFU/xEpuPxOD8oAGB7htFoRCqVQmNjI2fOUqMGOr/HglRYJSQkJCQkTgDI81koFJDP51lRpIIa6kxFFfli9imRCZ/PB4vFwtX4ogJpNBpZadTr9fB4PPB4PDwFK07p0vQ2eTMpqH56MQztIxqNYs+ePQgGg5g7dy73jDebzXC73TCZTMjn80x0q9UqbDYbfD4fFEVBNpuFxWJBc3Mzt/zUarVIpVJMlkidJK8nqbrAkRSAWCwGvV6PhoYGNDU1Yd68eXwu+/r6MDk5iVKphHQ6jYmJCW6KQISVKuCJ1AHgn2QDIGtGa2sr5s2bxw0XiKwGAgG2GJhMJrjdbiZrpBrm83lYrVbYbDZWremY6EFEo9HA5XJh/vz5bGsgWwc9AJjNZnR3d7PlQPQar/5/7L15lFx1mT7+1Hpr3/feu9OdpDsxO5DEBAVRoiiYGY8OLqijqHOO466jogzqYZyDMAPCeEaYcUEdnWFxBSKbAULokL2XpNN7dXft+77X74/+vS+38oWAEEiU+5yTo11U37p1762u5z6f532ebdswMzMDv9/Py/AKhYKLCMgvG4vF0Gw2YTAY4Ha7cejQISbaFosFdrudb5To/bvdbuzbt4/tCCaTiZ9HCjLZI9RqNX70ox/BbDbj61//OgCgq6sLjUYDhUKBb6zoBkEcj3UmSIRVggQJEiRIOAcgEmk0GuHxeACACRUpcdVqlQsDaDmayJBMJkOlUoHRaOThIYPBwIosLfOTP5LI8elFAOL9qdfrLQ1YYkVQ7F198sknUSgUIJfL4ff7kc1mmUySd5Qm6SlHlZRQs9kMtVqNpaUlpNNpVtpoCZ7ek3iYSRxGn8lk+Jik02nUajVks1nUajUmpfQ7VFSg0+lgNptZISYVcXFxEdlsloeX6BhTWxWRLDqG5XKZ3+/CwgL7Men4iBVrt9vNxQb0GJFlGoajzF3aP61Wi5MnTyIejzOxpHNx7NgxRKNRqNVq+Hw+VnTJC/y2t72Nh+pWrFjBjWODg4OQyWRYvXo1W03e8573oFgscgNaqVTCxMQE9Ho95ubm+DWJEC8tLTFxp5sgWgEgUr5u3To+RwsLC/iv//ovjquiGwS9Xg9BEPDmN78ZX/7yl2EwGHj4Smq6kiBBggQJEs5D0NS7Uqnk6XFSqkh9IoVRnI8q9pXS41QRGgwGmZyKq1tp+ZuyRqmC8/myWKlBixTacrnMS/TAMmENhULQ6XSoVqsIBALI5/OskEYiEY48EgQBDocDJpMJMzMzMJlMAIBQKMTEh5a7iWxVKhVkMhneBhE+mkgnO4PRaES5XIZMJmPy3NnZCbPZzOo1sHwTkMlkuGSABogMBgOT4lAohHw+z4omJTYQ8dVqtUilUhwvFQwGIZfLEY/HEQ6HYbfb2TtL1bHpdBpGoxHt7e3o6upCs9mE2+1GV1cXdu3axR7kYrHIlgY6BuJBOJlMhu7ublx99dXYtWsXwuEw3G43vvWtb7F3WBAE3HfffZibm4PFYoHH44HNZoNCocB73vMe2O12TE5OQqlU4pprrsHQ0BAmJydb6mELhQIsFgsTWAA8cEaEkm5q5ufnUavV+PjLZDKMj49zVvAtt9wCm82Gb33rW3wOt2zZgu7ubjgcDhw6dAh33303gGXLyOkRa88HibBKkCBBggQJ5wBUi0neUIpaKpVKqNfrrKaSukiKn3gZWTz9T0utsViMM03FyigNyVCVJw3biLdFE+BETog8039vNBro6+vjaK1sNotoNIpQKMTEh5S4eDzOCi1N8OdyOQSDQTQaDXi9XhQKBV62p9em5xNRpol9Og4KhQLlchnz8/PQarU8rEY+VVJv6Wag0Wi01Lz6fD6YTCak02keHnI4HKz2UdIADZN5vV4YjUZEIhFMTU2xSprNZlEul5FKpRAIBPi8UTxYLBaDz+dDs9lELBaD1WpFV1cX1q9fj4WFBXi9XgDPZd66XC6O4CJrh0KhgMfjgdPpRCQSweOPPw4ATPDFxLLRaGDlypXQaDSYn59HOp2G0+nE+Pg4XC4X+vv7WY1Wq9X49Kc/jXA43BInpdfrsXPnzpZEg0QiwZXBzWYTGo0GarWabyrIWkHJDbVaDe973/vwhS98ASMjI3wtLywsYGJiAuPj4yiVSty6tWHDhpeUwyoRVgkSJEiQIOEcQBwXReREqVSyp0/cKEVLsfS4OHKKvuzFy+o0dCSOjyKVjIaiBEFoaSUCnguKp9eh1yZiIpPJ4Pf7sbS0hEQiwWpvOp1GMplkm4Lf7+fX1+l0TCTVajWT6Gw2i2AwCKfTiVwux+9PXPtqs9nYX0pqLBFu8oQSSSIFmZRRyj4lJVen08HtdiMSicDpdLJHlW4WaKgpFArxgBbloNpsNhgMBvaBFgoF9Pb2oqOjAw6HA36/v+VYHj16lO0cgiBgcHAQarUa73rXu2C327Fu3Tr09PQwodZoNHyTAYCJutVqRSwWw5NPPomDBw9i9+7d7Ln94Q9/yOq70WjEl7/8ZXzjG9+AVqvFunXr4PV60dXVBb/fj0QigYWFBa73LZfLsFgs0Ov1SKfTnC9bqVS4jpWOm8fjgVqthsvl4qE0i8UCg8HAx4h80qRqf+9738OhQ4cwODgIpVKJQqGAhYUFvumiZiyNRsMVt5IlQIIECRIkSDgPMTs7C7/fj2KxiEQiwYorLfHScj8ATg2gnnv6gqclfSJKNPhDw0gECn4n9Y6Wnk9fhhWXDhDEsVYGgwHt7e0Ih8NQqVQoFApIJBKsDIsD8nU6HVQqFZPBTCbD+ahyuRypVArbt2/Hzp07WybFxTmxRCYNBgNHW9HydblcRjqdhk6ng9PpRD6fRzabRT6fZ8WW1E6lUgmDwcAeS7FSSwpmNBplGwJ5S+12OxqNBrLZLAqFAntrG40G8vk8gsEgYrEY2zXC4TBHaKXTaQDA0NAQfD4f6vU6Hn74YSwuLrKFgiwbF1xwAQqFAqxWK3tC3W43CoUCPB4P3G43fD4fcrkcHA4HBEHg5XhKUrjooovYp3vy5EnY7XaoVCrMzc0hmUxyLBdZGOhakMvlyOfz6OrqQk9PD0en0bmnNAm/3w+dTtcSd0bXKLWylUolOBwOuN1uZDIZrF27lq8dsqm43W6utgXA238xS4AUayVBggQJEiScAxgMBs7iJFJIipl4yIgsAFQMoFKpOA6JVE9xFqnJZEK9XkckEoHVam3xQtLQSzgcZj8mQaxyEQEWk2HyGVqtVm5JorgnWvo3mUxQKpUcXJ/JZFAul3kpmRRYijkKBoNob29nYmoymVqavcjnS95b8vpSFiqwTOZzuRwrqKdOneLtAc8N/BCxo5xbUgbJn+p2uxGPx6FQKHh5v7+/H+FwGKlUiiPEKAVgamqKjwmdCxqIi8ViUKlUnDOby+XQ3t6OQCDApJtuUKrVKoaHh+F2u5FOp/nGIh6PY3BwEEtLS9DpdLBYLOjo6AAAzM/PIxKJMBGUy+WsjJpMJgSDQUSjUWzatAlGoxE9PT1IpVJIp9OYn59HIBDAj370Ix7eUyqVmJmZgdvtbrkGyMNL5LJQKKBer2Nubg5qtZpTFiKRCOfy6nQ6zM3NodFoYGxsjJusyGcMAD6fD36/n5veni9+7XRICqsECRIkSJBwDiCOllIoFC2kUxAEmEwmuFwueL1eeL1erF69mif4yT5AdZkGgwFmsxkGgwF6vR5erxcKhQLZbJaHo2g5lkhWsVjk4a7Tl2TFFa7kcaSJcpVKBavVyuSUPJikopbLZSQSCej1elbdKpUKlxSQCiuTyTA7O8uqK/kyyZZAS/akBALgwSayOBBZo3aphYUFJuh0HMlSkEgkeKKflurlcjkSiQTS6TQWFxdZsSZSms/neeiLiHQkEoHH44HJZIJcLofFYoHD4UC9Xuf9feKJJzh39ZFHHsHJkyeRTCbhcDjgcrmwZs0aDA0NQalUQqfTsQ+UYrHITnHBBRcgHA6zKq7VahGNRrkuVmyzuOuuu3DzzTfDbrfD6XRizZo1SCaTWLlyJVfb0o2Qy+XC1VdfzapmrVbD+9//fuzYsQMul4uvA1KSlUolenp6OAe3vb2dCXyxWITb7WZLQCAQQCaTgcViwejoKN9krV69mtVieoxsLc8XoXY6JMIqQYIECRIknAPEYrGWf+FwGMFgEPPz85iensb09DRGRkZw+PBhHD16FE899RT7ColoUBQT2QWIHNZqNa5ATafTTGxSqRRnoNLQkRji2CcA6O3tRWdnZ8tzms0mdDodAoEA+vr6uI1LrVYjn88jn88jGo1yYD8AbnCKRCIIhUKsHBcKBfzqV7/iZf50Os0KMymycrmcM0gtFgt7XIms0nGgYSrKRKX3QySfBshKpRLHQVEDFJUmpNNp3jYR8GKxiEqlAp1Ox9aEZDLJx9rlcrHHljywn/zkJ9HX14d6vY61a9eit7cXPT09sNvtiMViGB8fh9FohFarZS/o1NQUOjs7ObNWo9FgZmYGCoUC/f39fDNTr9exdetWtLW1we12Y/v27ZDJZDh69CgOHDiA8fFxNJtNLC0t4fDhwzhx4gQrvs1mEz09Pawwb968GcViEYIg4Mknn8Rjjz2GO+64o+V8K5VKvP3tb+d8YJvNhmg0ymkBoVCISSd5gpvNJnK5HG6++WYAYGVfrVbzyoLP52N7Bp2rM0EirBIkSJAgQcI5gEajgVar5WEpmsQWh/gDYOVJo9EglUpxZWcymeSBIyIKpL6SSmg0GplYEUms1+swGo0AngvJp6V/+kdq78mTJ1sGoshrqFAokM/nWypdC4UCms0mh8eTF3LFihX8uNVqhUajYTItCAIUCgVSqRQAtEzZ0/ui6lalUsn7TftRqVRgsVhQLpe5bpUGsQBwgUG9Xkcul8Ps7CwcDgdbFPL5PPsprVYrk89isYienh7E43E4HA4AQDqdZrJFqjcNHdlsNia2IyMjsNlsWLNmDXw+H77yla/wzy6XC0tLSwiHw7j33nv5WDscDo64Ik/p29/+dni9Xuh0OkQiEU6DoOtj+/btCAaD2L9/P8rlMmfQ0g1BR0cHVq1aBY/Hg2QyyX5Zk8nE6QPBYBCpVAoOhwMXXXQRvva1r/ENiMFgQFtbG1QqFe655x6USiWsWrUKX/jCF5DJZDAwMMBNZTTMR/YLhUKBXbt2YevWrZwIQWoqeZgPHDjARJdU8zNBIqwSJEiQIEHCOYA4cop8fEQGxYNH4v9OU/L05U//DQAH5gPLS/rFYhE6nY4JIS2jk9JGMUSkKIohbs2igRoAPFzVbDZ5up9UMvLJkv+TQvUXFxchl8uxatUqrFq1Ck6nk4n2G9/4RiapwHOlA0TW7XY79Ho9ZDIZbDYb17uSR5WW6YmQAstqLsVUUWoA7XulUsHc3ByT/mw2y5329XqdG6koxcDr9XLFKcVbmUwm5HI5TgpoNBo80KRUKpHNZrFv3z68+93vRigUgsPhwNjYGI4dO4YTJ07A6/XiH//xH/HWt74Vl156KVKpFA+OLS4uorOzE3q9Hn/84x/RbDZxySWX4NChQ1xeQNfOkSNHYDQaW246ms0mOjs7EY1GsW/fPhQKBczMzHB0l1wux8aNG9HR0YGPf/zjOHjwIHw+H7Zv3477778f8/PzvFSfy+WwtLTEavPAwACazSZ+/vOfAwDGxsb4PNF1RZYTjUbDmbsymQyCIKC7u5tTMIio02uJz/kLQSKsEiRIkCBBwjkAkTtqnyKCKo6p0mq10Ov1MJlM/88wjFqtZh+mUqls8QRSvijVlmo0mhZfab1eh9ls5qEbGnoh8kMElSKtxFPe1J4ViUQQiURgNpuRy+V4GZ6US/JMxmIxeL1eXHnllchms7jwwgvZg3vw4EEAaElIIHWZVFy1Wo1kMgkAvHQvHnbK5/MAwCkEFosFmUyGa16JUJJtQq1WQ6vVMmGyWCzcmAWAVVd63OPxQKfTodFoYHJyEslkEplMBm63GwsLC9yURSCPbK1Wwxe/+EVUq1VcffXVyOVybGPYs2cPNBoNWzJqtRp6e3s5m5X2z2azQa/XQ6lU4uTJk5icnOQyh8XFRaTTadhstpZ0B6/Xy+fM6XTyjYxGo4HNZkN3dze+8Y1vYN26dejo6EB7ezuWlpawevVqKBQKzMzMsNpJiRQ0tPaxj30MoVAInZ2d0Ol0fINFUWNUMrBy5UocOXIES0tLrKqSOk3Xh91u55uIl5ISIBFWCRIkvGq4Hjec612QIOG8hdls5vB+q9XKP1ssFphMJhiNRhiNRvb/CYLAsUvi/nlStcRkkoL3SfmjytZ4PA69Xg/gubgqsgkQkQTAhIWWeYHWyKtEIsFL+rFYDMCyJ5fKDnK5HKuuFEY/PDyMeDyO4eFhThUghZbsDKSGVioVVjyJiM7NzfHUOhFXGuaiIS7yydZqNV6uJwJPLVfiZWybzQaz2Yx8Ps+pCWazmWOu2tvbmXwGAgH09/cz8RNXutJwGdXMzs7OolKp4NixYwCAX/ziF0zK9Xo9ly10dHRAo9GgXq8jHo9zXBepzzKZDA888ADe+c53IhQKYe/evUysqZK3p6eHSSUN72WzWSiVSkxMTCAajcJms6G3txfZbBZWqxVWqxWbNm3C+Pg4Dh48iLGxMVx11VXo6uriRAS5XA6tVguv1wuz2YyxsTF87GMfw+HDhxEIBFqU/nA4zGq3QqFAJBJBqVRCKpVqyRf2+XxYu3YtstkspyoUCoWWFYMXgkRYJUiQIEGChHMAUvjMZnPL0igRRFLfSElVq9VcqUqDSQRSWYHn7ANEYGh5nzI6M5lMS3yUTCaDRqPBtm3bWgoGiBRT9qg4E5Ym7kn51el0vK+VSgWCIMBgMDBJefrpp3H06FEEg0EIgsAJAGQHoGl0j8fDhJv+OxFS8jlSFBW9R6VSyZPsAFoC+w0GQ8vjKpUKHR0dqFQqUKlUiMfjnElqMBhgMpng8/mYrBUKBSa7HR0dqFarSKVSqNVqnLNqNBqZqMpkMpTLZZw4cQLBYBDJZBLNZhO1Wg3hcBhzc3NculAqlZDJZAAsk7xNmzZBEAQ0m02sXbsW9XodBw8ehNFoRCAQgMPhwGOPPYZarYbZ2Vl0d3dj7dq1GBsb46E3mUwGo9GInTt3wmAwwGq18vHJZDJMtD//+c/D4XDgs5/9LCqVCpaWllAoFHDzzTfzjQYNwgWDQZTLZQQCAVgsFnzuc5/ja6lcLnPUl9ls5nO0c+dOXHzxxbjjjjsgk8lgt9uRy+WQSqXwm9/8BpOTk9DpdFyxK3lYJUiQIEGChPMURDjFdgAicNVqFel0GoVCAfl8nj2T+XyeUwBIYSRyR+T09IiqUqnEy/M0yZ/JZHh6vtlsYmBgADMzMy1RW7ScbrFYWvbb7/fz8FOpVEJPTw8+8IEPwGw2M+FSKpXw+/2o1Wq4/PLLcdFFF0Gv10Ov17OntVAosF+XFOJgMMhL/AA4O5Wan8gqIPbr0rGg/6UcWKPRyMeB/LX1eh0LCwtMgNVqNUZHR7ltKRqNcmoDqaYWiwVWqxWlUglOpxNqtZqtFlTkIB5Yo8atn/70p1haWmKvLdXTim0adMzz+Ty6u7s5vaBWq7EHlK4FUlYzmQwOHjyIY8eOsceU2qc0Gg2CwSAymQyy2SwGBgY4sotSIqrVKo4fP47//M//xL59+7hUolwu44orruChKzo3AwMDeO9734v3vve92L9/P7q7u/HMM88gGAy2+GepjnfHjh1IpVJ45JFHcMkll6DZbGJsbAyLi4vQaDTo6urCxz72MaxatQrxeJwtMS+WxSoRVgkSJLwqON0OINkDJEhoBammpIhSnqrBYIBOp+MYJUEQoFKpoFarW4LWxUoq0NpaJVZfSb0lIkfEgsjtwMAATCYTlpaWmDSQukv+QwBM8gwGA+eU0rDS0aNHYTAYmHyUy2WoVCr2a7rdbuh0OnR3d8NgMCAej0OtVmPnzp2s6ALLVgQ6JgQiT0TkxW1UlEVK6jQpnIVCgfeb1MJms8nkV6PR8JI+qXyFQqElpoosCbOzs0gmk2g0Gpibm+P2q3g8Drfb3fIaRMSz2Szi8ThSqRTuvvtuvslQq9Ww2WzYvHkzE0yfzwe9Xo9Dhw4xcYvFYhgeHsbs7CxMJhOSySQEQYDZbObEBxpAo+MQCoVQLBYRDAbx1FNPoV6v49e//jWuuuoq9i+3tbUhm83i9ttvx8mTJ7GwsMDn6he/+AXUajVOnDjB5F6hUMBut0Oj0SAQCOAjH/kIrr76aphMppbrjYb3SqUSDAYD7HY7rr32Wlx11VUAllu76NorlUr4wQ9+wPW3ZCl5MUiEVYIECa8ZJNIqQcJzoAgqGoKiARcCETHqW6eAeEoKAJ6bDCdV7PQEAXoOKZ/VapXrPyORCLRaLSqVCkKhELLZLKuuAwMDsFgsz9t6RPmq7e3tGB0dRSqVwtLSEgCwh5VsDaRSzs7OQqVSYXBwEBs2bECz2YQgCEzSiGDbbDYAYGuCmGySGqzRaHhan0gpsEwadTrEKa1yAAAgAElEQVQdq83iaCtSP6kONRKJIB6PY35+Hjabjf2gpJBSjSudh3A4zO1cpKgC4HzTWq2GQqGAarUKnU4Hr9cLp9OJSqWC4eFhVqmp3rbRaODIkSNIJBKIxWIwmUwYHx9HvV5nVRdYboTq6upCe3s7+5Jpyr5SqWBhYaGFrNPv+Hw+9PX1oaOjAx/84AdZrT1+/Di++MUvYseOHVzc8La3vQ1OpxOlUgnXXXcdcrkcX4c08R+Px7FlyxZOG/jUpz7V0sRG1yQNUF1//fWcDwuAVwPIlqHT6djTSxYEaehKggQJ5wQ34HrcgOtf8GcJEl7vIAIqbq0ixZAeI0WVSKA47oqW78XDUKSM0ZI5kWFaUqfoIZ1Ox8H4c3NzKJVKKJVKsNvt6OzsRLVahUajQV9fH0qlEqu7AOB0OjE9PY1isYhSqcRqpvh11Go1V86+8Y1vhN1ux9atW6HVajE9PQ2Px4NsNotcLsdqMQCkUikeIALQQloJPp8PWq0WSqUSBoMBLpcLXV1dLV5Wmj6n5XmyXVCRAFkNSMmemppqifZKp9Pc3kTng1TEarUKp9PJUWF03gAw4azVauxPTafTMJvNaDabrHbT8SPSKpfLsW3bNiZwtVoNmzdvxurVq9HZ2Qmfz8cFEQaDgZMB6PyKa3q3bNmCgYEBzM/PY9u2bbj//vvZy6rVanH99dfjyJEj+MxnPoPdu3cjFArB7XbD7XZzogK1m1E+7UMPPYSOjg7ceOONWLlyJd73vvdxrSzdRNENE2XmkjeYiiZIDS6VSnC5XLjwwgv5WqQbijPhzKFXEiRIkCBBgoRXBTQdTVPyYjWTlt9JFaUvdmB5uZ7C9SkGi5QuIjGkqBIRIGJFhJVIWDQaRbPZ5Ml6IsD0ewMDA0ilUkwkqZJVoVBgcXGRs0kLhQKi0Si/hlKp5N957LHH4HK5sHLlSoyPj0Mul+PCCy/Eb37zmxalmN7H6c1HtL+VSgV6vR5+vx8ej6dlwCuZTLYM7ZAaSceLJtIplL/RaECpVMLtdrd4eimbVhyAn0gkYDQa4Xa7EQgE2GNrMBhYSRb7cEulEkKhEC+NU9JBrVbjeC5gOT6LCKhcLseWLVswOjrKZQyFQgHFYhHz8/PYtGkTK5BqtRputxu1Wg3xeJyvBXqvMzMzXBYhl8vx93//93jwwQchk8lgMBiwfv16KBQKHDp0CNPT05icnESlUsFHP/pRnDp1ClqtllV4mUyGVCqFrq4uJJNJXHjhhXxO6X2bTCZuAqN4LoK46YzOMbWudXd34+mnn2Z1WHzj9XyQCKsECRIkSJBwDkCEk8iqeFlXrKQS2RRnpBIZpY55IkukbNIAEj2ffp+Wr+kxjUaDXC7HJIL2i5BOp5FIJJiM0KQ3TXgXi0Vu3erq6kIkEuFYKyKMHR0deOc734l/+7d/Y7J0/PhxWK1WGAwGFAoFlEolJi0WiwXFYhHAc9FbNPxFU/snT57kASur1YqOjg4sLi4yKaJjS4pvW1sbZmdnWQkEwBFaFosFsViMh8BUKhWcTicymQzkcjnsdjsEQWBPKqnhhUKBB6/I+gAse31pwIz8oZVKBalUCmazGQsLC8hkMqxiUhzWz372M3zgAx/ArbfeysUF2WwWkUgEPp8PHR0dmJ6exmWXXcaJBs8++yxfP+vWreMEg0AggFqtxgUJ6XQa+Xwe27dvBwDcf//9WLduHaamplAqlaDRaLBnzx5Eo1Hs3LkT8/PzvOR/4sQJBAIBmEwm3HrrrbjrrruwceNGtguQJYUGy+j40nXrcrnw+c9/noe+7rrrLiiVSh4Yo+E3yRIgQYKEv1hc//8bCSRI+GsEqZz0BT83N4eFhQUEg0FEIhEkEokW5U+r1bKvlUgTqar0s/j/E9klcivObiUiaDab+WfxvpDKGgwGkU6nWf3UaDSQyWQIBAJwuVyIRCLQ6/Ww2+34whe+gP7+fo7fIjKu1+txzz334LLLLkM8Hsfu3btx8cUXQ6fT8QATqclUeCBWm0mBLhQK0Gg0qFQqrNyJVVWySBDoPcrlcszOznKUFrDslaWBtlgsxlWxTqeT1ViTyYS5uTnE43Gufu3p6eHBLpvNBq1Wy1my9FoajYZV0kwmw2TVYDBAoVBg+/btaDabyGazqFQq6Orqgt/vR39/P37zm98wOVer1bjmmmuwfft2zMzMIJPJwOl0oq+vj5vCbrrpJn6/TqcT1WoVmUyGSeh9992HaDQKnU6HQqGAU6dOAQC+8pWv4IorrsCVV16JCy64AHK5HMViER0dHVi7di2/F1rSVyqVaG9vh8lkQm9vLx544AH20Q4ODnKpBABEo1HeJ7r+RkZG8N3vfhff+973+HXGxsbQbDb5vUqEVYIECRIkSDgPQb5UUsJoep0IKvkuicyVSiVukKJ/FGsFPNecRdP0tVoNS0tLPFxEYe9EBmk4SUxkxXmuSqWyZfBKPMhFr+lwOLC4uAiHw4EDBw5wIDzlpTYaDezbtw8ejwf79+9HNBrFY489hmeffZbJkNgCQTYFWmImRZhIKxF3skCI92fbtm2sTIv/EWkivyUt269YsYL9kzabDT6fD9lsFuVyGUajEaVSCUajEZVKBeFwGCqVCslkEhaLBe3t7QDAxJCOZalU4kareDyOaDTKxE9802CxWOBwOHhy3mg08tQ/JQ3I5XIkk0lEo1FEIhEkk0lUq1Wulq1UKpifn2elViaTIZfLIR6Psw+2Wq3illtugdlshkKhgMFg4KpWcRVwR0cHLr74YlxxxRU8eCbOx125ciV6enpQrVaxefNmTE1NAVi+oXjnO9/JtoRms4np6WnkcjlMTExgdnYWxWIR+/fvx1NPPYVoNIqJiYmWooFEIvGSPi8SYZUgQYIECRLOMUgZ1Gg0vJxsNBqh1WqZcIkJmphE0vI3tT/R80hx3LRpEzQaDZxOJ7+WeGiLfIhGo5FVR4pQymaz7GUkckNDQkQktVotxsfHMTw8zAS7VCrxME4ul8P+/fuRSCSgVCpx7NgxVCoV2O12ZLNZbuEiRZb2izy+4uOTyWSQz+dbYpVomOyJJ57gY0LHhYi1VqtFd3c3V4Q2Gg32ApPf1mw2A1j2W1LmbXt7O3Q6HYrFIg+O5XI5TE5O8uQ7AA7RJ6sFlSlQ7qrZbIZOp4Ner8fc3Byy2Sx6e3uxZcsWjtIql8tcTkDbPnjwIA9xEegaAcBKdqVSYVsH3TTUajUUi0UsLCygVCqh2WwiEAi0eEwpWcHj8cBkMuFv//ZvIZfL4XA4ACxP9xsMBlx77bWIx+PcCHb8+HEeepufn+eKXwB45plnsGPHDtx888247777eOiKYDAYkEwmOQ83m822vL8X/Iy86DMkSJAgQYIECWcdpKbqdDr2AhLhI/IhzlCln8lnSfYAcWYqsDx4Q//ocZqMJzVTPKAFgF+DluQ1Gg3XiFKoPg1viWOr6LmCIGD37t1cckDL+xSpRUUD5XKZUwwEQWBCS9P7tLRsMBgALJMbIme077TETh5VYJl4bdy4scXuIFaQ5XI5lpaWmKACy0NPoVAIwPJyOtkj1Go1L+tns1kAzw1xjY6OsipO6i/5RMmqQMcokUhwtJVarUYkEkE+n+ec3Wq1ykr6tddeiw0bNrScMxoyo0YtihwjWwS9L3EpAhUA+Hw+yGQyJt4qlYoHn8TYsGED3v3ud+MTn/gE2wkSiQQTUIVCgZ07d2LPnj04efIkbrjhBtxxxx0YGBjA4OAgVqxYgVAoxLm1FDtWrVZhNBrhcrng9Xrx/ve/n5XgYrEIq9UKhUIBj8cDrVb7ogkBgERYJUiQIEGChHMCUguz2SxHJpEyKP4Cp0zSZrPJg1HU9U6qJLVZkQpKimitVsPc3BxyuRxisViLx5X+V7w9WpYXJxDQPpwOIjaUzfmtb30Lk5OTnC1LlgCFQoF0Oo1KpcKDRKVSCclkEna7vaU6FQDHJSmVSrz1rW/Frl274HA4mLCf7q0ElsnpoUOHmMCSukkEkNIEBEHgJXtqoNLr9exltVgsEAQBcrkcPp8PqVSK61X7+voQiUR4Kr5QKHCMlVarZYJeq9U4Nox8v/TetFotvvOd7/ByON2kDA0NYWJigo8t5bVStS0AmEwmbrKiPFPyNZPVgc6n0+lssT8QAQ2Hw8jlcvw6+Xwev/3tb/Htb38bDzzwAH73u99xtiuBSDUp51S40Gg0YLfbsWfPHn5tUmcNBgN27dqFd73rXejv78fAwAAuuOACtraII7/oOJxOpk/HWSOs5+NgxPm4TxIknK+QBpwkSHhtQdFR4mV88Re/OOg+HA6zgqVSqbBr1y5W6YiQ0BI4KaBEkijmiEgSKYQ01U2PietFyYsJgMkjkVwituRxrNVqnAhAE+NEnIiAp9NpCIKAQqHAqQCBQAA2mw21Wg2CIKBSqfBrEHk5cOAA6vU6MpkM9Hp9i6pIAfqUE0uxTQqFAjabDV1dXTAYDKxkk7pLy+2kVAcCAaTTaT6GCoWCY6j0ej2T70QigUsvvZQJIt08ECkWk3rar3w+D7lczoq43+9HIBDg/aTjZTKZsHPnTvaxUpKD3W5nz24oFIJWq2WbAR1vakxrNBowmUy8TE+qp0wmw8LCAl9fH/nIR/C5z30Of/d3f4df//rXePbZZzE1NYVisYjf//73fN0QiWw2m8hkMnwDRHnAgiCgVCqxv5huspxOJzZu3MgqvVKpRCKRQK1Wg1arhdfr5Rsr8i6Lb45eCC9KWF/KF9jzPedcf/lJX7wSJLTi+apSz9fPyfm6XxIknG2QQkYKJ/DchL6YuJVKJZw4cYLJ1+23345Dhw5Bo9FAq9VCEARotVpWV+l3afmffibFk4iZOOuUIFZaAbS0cYkzWqksIJ1OQ6lUci0rPRdojefyeDzo7+/H+vXrYbFY4PV6EQqF0NHRwUSYqlnJIhEOh/H4449DpVLx+6D98Hg8vJ+rV6+GUqnkhAGj0Qir1Yp169ZBo9HA4/EweWo2m1i9ejXK5TI0Gg1nl6ZSKWQyGY75qtVqPBDUbDbhdDpx8uRJuFwuVKtVRKNRLhKgISlasqfzR8NvCwsLSCaTyOVyOHz4MLd0UZRWsVhEb28vQqEQt54lk0lOiZDJZHC73RzGn81mYTab8T//8z98TvL5PJrNJjo6OlCpVNgGYrfbOWKru7ubp/2J/H7pS1+C2Wzmc0jeXo1GA4vFgng83nJzQ3aFQqHAyrnFYuGbLpPJBJVKhR/+8Ie4/fbbkUgk8PWvf53Pn7hWuFQq8XX/YoT1Feewno0vFvE2znYTzvW4QWrXkfC6wWt5vb/aryWRVgl/7ZiamsKaNWsAoKXdqV6vIxAIwGq1wmg0cnYnKWg0Aa7T6bB+/XoAaFneL5fLKBQKaDQamJ6eRr1eR3t7O4LBIDo7O1ldBcCEiYZiiIiKiaw4HktMWilUnqKeiJjSNqhXHgBcLhd0Oh2TFcrtzGQy8Pl8HLskCAL7WMlParfb2Y9JkVMGgwHRaJS3//TTTzNpEleVJhIJ2Gw29tzSsj2RLSJmzWYTuVyOB69SqRRsNhvXh8rlcvT39+PAgQMwm82wWCwcfSWXy5HJZOBwOBCLxQAAVqsV9XodHo+HiXBbWxvUajVmZmZ44IzUbq1WC5vNhlAohGq1ysdbq9VyWkBXVxdUKhXm5+fhcDi40YuOqUwmY58u3QjlcjksLCxAq9Uik8kgGo0iFotBEAT09PRAEAQe3CoWi8hms2wfKJfLyOVysFqtrEqTqkz+22KxyEqwmNBWq1UsLCwwCc3n89BqtRgaGsLk5CSfC/Ld0o3UmXBGwnqmL4yz9WXyanwpPZ+SBPz5ZPj0L2SJ/Er4Swddw6/kcyf+3dO3Q9s+/XPyYp/Bl/sZPdvbeCU4168v4S8Per2+JWaKrAFEWKjpaGlpieOXDh8+DAC8LLtnzx5WDsVJAcAyceju7sb8/DyCwSCsVisCgQAWFxdRr9fhdrvR09ODsbGxlqGs/v5+ngLP5/PweDyo1WqYnp6GWq2Gw+FAJBJhZTAajeLDH/4w7xvZFsgfmk6nsW7dOl5aVqvVuPDCCzExMYFIJMIKJeWyksJHhDaTyUCn07X4Ku12O8LhMKrVKrZv345IJAKr1YpcLgeNRoNUKoVKpYJVq1YhGo0ikUi0LJn7fD4mSKVSCalUCuVymaPBaNmfBoIqlQpmZmYgl8vR29uLRCLBCrbRaIROp0M2m4UgCJzZOjAwgGKxyASQyGZvby80Gg1GRkZgsVigVCo5I5W8qRQttbi4CJPJhEwmg3K5zC1bOp0OcrkckUgERqMRzWYTRqMR2WyWrRFmsxnxeJwJZaVSQblchl6vx6lTp7Bu3TrO39VoNACAXC7Hfmhg2UIwOzuLVatW4fDhw7jqqqtw9OhRPPHEE1i9ejXC4TCUSiUOHjyINWvWQKFQsDdYq9WiVCohHo+zBSISiaBeryOfz8NqtaJarSIWi7U0vb0QzpqH9Wz9kX41VRVaAqXXONMX7/M954X2T1KCJJxPONP1+ErJ6it57Ze7jbNBYl8L0F+X1xrS35+/XFgsFqTTaZ7opyl1IpyCIGBmZoabowCwF5VUNMrpDAQCWFhYQDgcRiQSQSQSQSwWg9/vh9vthiAI2LJlC5cAJJNJTE5OYnp6GgBw7NgxHDt2DCMjIwiFQojFYtyCNDY2hqWlJR76slgs7LOs1+swmUwYGxuDw+GAVquFxWLhJADygEajURw9ehTlchnVahUjIyMolUqceqBQKGCxWNDT04POzk709PSgUqnAZrNBo9Ggra0NmUyG/ZI0mU65pLlcDsViEUqlkvNTVSoV8vk8jEYjh/zXajXcd999uO6663DllVfiQx/6EPL5PJO2np4eVpcLhQKSySRHObW3t+ONb3wjUqkUFhYW+PVIEW42m1z72mg0MDU1xdFcWq0W5XIZQ0NDHPpP/l1gWbH8wQ9+wN5jjUaDQqGAubk5HD9+nNXOSqWCZDKJQCCA8fFxJq5UWEA3EeFwmBXvrq6ullYpOj5PPfUUms0m4vE4Ojs7+aaBEhGIRMZiMWSzWXg8HszOzmJiYgLNZhMmkwmFQgFqtZobtOr1OrRaLQ+ykTeZrneKVqMbJLI8iFcIXggvibD+uX8QX+rzX+h5r8UfYDEhfbmk9HTyez57AiW8vvFCN2Av9NiLbefVwJnI3gt9vs70N+T18lmUFN2/XNBQTiwWY2Wt2WwinU6jUChgaWmJB6/EDU4U0E7xUbQcTMvX5OXs6OiA3W7Hb3/72xZS09PTw/31brebPa1kS7BarRwxReonKboA8JnPfAZGo5FfMxgMYmJigonH4OAgisUiBEHAW97yFpTLZRw/fhyf+MQn2HuqUqng8/nQ2dmJTZs2obe3F9///ve5Albs51Wr1VhYWIAgCNixYwdMJhMH5xP5NhgMvCRNS9VGoxHRaBRLS0vIZrNMno1GI5aWlpBKpdDX1wePx8NEfHZ2lr2oFM1EXk9STqvVKrxeLzZu3MikLpFIsM2CBuna2tqg1+uRy+XYynHZZZdhYGAAMpkMK1eu5MGlp59+msP8SdHdvn07uru7sWrVKjSbTbZ5pFIpLC0tAVheVi+Xy5xKQD7gRqPBNzk09JXP5znVgK6FVCqF6elpLq2ga4EGoeg4hEIhbl/L5/NQKpUol8ucZPCd73ynJRuYiG6j0WBvM3l/geW6XpfLxcNk2WwWXV1dZ/y8nLOUgJf7ZfJiX0SvdKnzpXyhv5r7IEHC2cBr9Xk8m3ipn7/Tn3v6770YqX2x93o+HAsJrw+QgkcEjZQt4LkEAY1GA5PJhGKxCACs5hGxo0ErsgRQXqtWq8W73vUuztbctm0blEol7HY7N1719fVhaGiIO+Mp7P4jH/kI+0kpBouI49VXXw2tVguHw4HrrruOo5ai0SgvN584cQKVSgVmsxmTk5M85T8+Po6xsTF897vfxd/8zd/AbrdjdnYWe/fuxZve9Ca43W6sW7eOqz0p6xRYrlKloaf169ezd9TtdrdUodLxKZVKEASB7QXUCEakqr29HceOHQMALjRIJBJMCrPZLIxGIzQaDau3mUwGn/70p3Hbbbdh586d2LJlC/R6PVQqFaxWK5PsRqMBrVaLhYUFVkvT6TRisRjuvvtujI6OYuvWrZicnITVaoXFYsFDDz2EUqnEmbw6nQ6BQABHjhzB1NQUFy0Eg0EuICAvbjweh0wmw7Fjx1qm7smbSuH/NABGP1Npgzh6i1R0sXe5VqthcXERyWQSRqMRxWKRj7HX6+VjRMq0XC5HuVzm3NVcLgdBELC4uAiZTIbBwUG8+93vxlVXXYVPfepTeO9734u5uTlWYl8IZz2H9Wx7W6UvDwkSzi1e7mfxXKmxLxUvNwFFgoSzBSKlNPWdyWR4mZmm7akliIZgxLFQYqJKZJWUtqGhITz77LPI5/PYu3cvotEoFhcXMTo6yjmetOwsVnCVSiX27dvHfkQaoCLl9qqrrsLs7Cx0Oh0eeeQRnqanpfHe3l5WMV0uF4LBIOd4HjlyBJ/97Gfx4IMPYnh4GF1dXdxoVSgUcPvtt2PPnj1wOBw8XNXW1ga5XA6TycRqs1KpRHd3N0/P63Q6mEwmWK1WAGASS4NcADiGSqFQ4Pe//z00Gg2mpqbwr//6r2hra+NtezweHjAKBoOIRqM8AKZUKvHwww+zxWF8fJxVQrICUEoBVcuS55Titf7hH/4BN9xwA3bv3o1f//rXuPPOO7FhwwZ87Wtfwy233IL/+I//wJ133okPfehD3FZFxQ10rDKZDJaWltgWQdeQyWTiISyqlqXjSDYSIuSFQoE9sbVajTNlxYUG4si1cDiMfD6P0dFRHvKi0geDwYAf//jHbO8gZZbsDsViEXK5HFqtFtVqFVarFX6/H9PT0zhy5AhSqRTWrVvH6usL4WUR1nO5lH8mnOvXlyDhLxUvRgBfzmeLtnkm9fPlbvPVgPT3Q8JrDVKgyuUyk01xe9LpX+BEHi0WS8sADnn/iIhQDmkul4NCocDPf/5zpFIpzM/Pc3MTVYkSwQCWl9LdbjcsFgsPCQFoIbSPPfYYgsEge26vueYa6PV6nhannM5GowGfz4dQKAS1Wg2j0YjLLrsMQ0NDGBkZgd/vx0c/+lH4fD6USiUsLi7C6/UiGAzy+5XL5RzfRNP3MpkMTz75JBQKBdasWYN///d/56n33t5eWCwWrF69GpdeeikPadntdib+SqUSjz76KN7znvcgmUzi2LFjGBgYYJVx165dTLgMBgNKpRIqlQo6OzshCAIGBwdRqVQ4YSASifDSOC29U7mB0+lENBpli8H3v/999Pb2Yu/evfjpT3+Km266Cd/85jcxOTmJb37zm7jxxhtx55134sEHH0Sj0YDf72fS2mg0EA6H4fP5+Bhns1mo1WpW5SkrtdFoYO3atSgUCtBqtYjH40xc6Rqi2txkMsm1rd3d3eju7gYAVqPr9TrsdjtX9aZSKQDgm6xUKgWFQoHJyUlWeklNrlQqkMvlLa9PebSZTAaBQACJRAKBQICvxzPhnDRdnQ2l5mx9uUj+r7OPV+oflIiDhLONP9cW8Eq2LUHCS4W4f31gYICX94HnSCJ5S+kf/Xdx3qnYO+jxeGA0GqFWqzE9PQ25XI5bb70ViUQCiUSCt9fb24tarYZHHnmEB6QajQba29sxPDzMU+ni12g0Gnj88cdx6NAhNBoNDAwMwOl0YsOGDeyBHBsbY7UymUyiUCig2WzC6/WiUCjgpptuQjweRyaTQTqdZqU4FovB5/Mhm80iHA5DLpdzhenDDz+MN73pTezBBJazPhcXF3HddddBEAQkk0ls3ryZB8YefvhhjI+PAwCXKVx00UWslhqNRk4iOHHiBDZu3IihoSFuyALAk/ZyuRwdHR2QyWT43e9+h1/96lcwm808UU++UFoSpyKErq4uaDQa6PV69Pb24oYbbsBXv/pV/OIXv8CDDz6IZ555BhMTE4jFYhgbG8P+/fvxwAMP4Gc/+xl+/OMfY/369azckg0kFothYGAAHo8H1WoVq1evhlar5fxaih6Lx+N8HYmD/bPZLGw2G8rlMoxGIxQKBUKhEFQqFfr7+2GxWHgIjob/HA4Hpz3QdVer1TgCi/JUKVHhoYceYguLIAj8fPJFk6Uhn8+3+KOTyeQZPy+vOWE9XwY8gOfIqkRazz+8noZmJLw0nK+f0/N1vySc/6AMSo1Gg3q93jI4JG6+SqVSvOwvVl2JwIqtATRJnsvlOHbJ6/XC5XIhmUxCp9Nxvqder+dtEemNRCLYtGkTEw163dMrWmu1Gh5++GEcOHAAR44cgdFoRCqV4kEymUyGEydO8GQ+AIyMjODEiRMYHx9HMpnkbFmK8BocHOTMTyKKZrMZ+XweCwsLCIVC7PVNJpMwm81Ip9O8lP3000/z+6EEA1Kj6/U6xsbGYLVaEQqF4HA4kEwmceONN+LgwYPw+Xzo6OjgIH46pgD4JoCGjh599FHY7XZ88IMfxO7du1uUWCKr5NnctGkTuru78eEPfxjFYhGlUokzXNvb2+H1eqHX61Gr1WC1WmEymdDT04MTJ05gbm4OALBt2zZYrVbevs/nQzKZREdHB5LJJHw+H6vCRqOR1UytVsuDcJSz6/P5OGqLbmDkcjl0Oh1SqRR7YKnFjIa9arUaisUi8vk82x4oJ5fUdQDsibVYLOyXpfNBFb1yuZzjv0gtfjE7APAaE9ZXSkAkAnP+4vmmuKXzde7wlxAzJ0HC6x0dHR1QqVTwer08+HPRRRchm80yWZDJZEwAKaOVlohpGZX8lQaDgWOXhoeHEY/HUavV8O1vfxvBYBCNRgMWiwVyuRxTU1NQq9VMWomk5fN5HD9+HMVikUmqOP9Ur9ezhzafz3NMFjUlAeD9VCgUcDgcHIJfLBZx6aWXIhqNQozJTrcAACAASURBVKFQ4J577mFlslQqYdeuXYhEIvD5fOy3JBvD/Px8S3NXsVhER0cH536GQiFoNBqo1Wr2RVIYfa1Wg8PhgMvlQjgcRjabhd/vBwB86UtfQnd3N/bu3Ys//elPAJbJlcVigU6nw8qVK6FUKnHxxRejWq2iv78fCoUCjz76KO6880785Cc/aQnwt9vt8Pl8AACv14tTp07h5MmT6O7uZovFwMAA5HI5x0VRKkMmk0E+n+chKyKFwWAQRqMRwWAQBoOBb2yuuOIKTExM8FI6Kb4ul4v3B0DLUF17ezv8fj8EQUA0GkU+n+fzSO+dlFqygZAHVazki8koXRf5fB6XX34520nE1w2dY9oXMUklsu1yuc74eTmrOaznWmk4X/bh9Yjz5X1LBOvVw0s9x+fLtSDG+bhPEiQkk0me3I9Go1Cr1XjyySd5OZWWX8UtUjQgQ4qWuD61q6sLDz30EJNZUlzHx8c5sN9ms/FQ0fj4OFe9kiK5du1a3H333ZienmaCQtsj0nH48GGMj4+jUqlgYmKCo4so1gkAD4nFYjHYbDYeKjt+/DjC4TBkMhmmp6eRyWR42p8KB9LpNJ566ikIgoB4PA6v1wubzcZWA6pWpcpQsRK8cuVKrFq1Cm94wxuQy+UwNzcHg8EArVbLBQmUxkCqI7VJbdq0CRdffDEGBwdx2WWXYfXq1RgcHMSOHTswOjrKjVXXXnstfvjDH+K///u/sWXLFlZyHQ4HTCYT15XWajUMDAxg7dq1+OY3v8kkb9++fQCAdDrN9bByuRx6vZ7PBaUsmM1mHDt2jFVhcXLCPffcw9WxNPzm9XpbWsuA5RsOk8kEmUzGCnU8HmcfLA1c0U0IXVO0vxqNBmazGQ6Hg48B+XVJiZXJZIhEIrj33ns56oyUWMp6pWE0ikMTR7YJgoCvfvWrZ/y8nBMP68uF+EvnfPwCOh/36bXEub5hkMjqy8eLHbtXcl7Pt8/F+bY/LwfStf7XAVIHl5aWYLVaMTo6ysSRyAZ5V8UT26R2UQ0pLauvW7cOuVyuJaJKJpPx9Pz73vc+JnhyuRzFYpH9nUQEH3zwQSYRtF3yIALg12s2m/D7/chkMvz7BoOBq0/peaTgAcvKIjVOFYtFxONxXjpeXFzEihUrOIKK/JFyuRynTp2CWq3mnFqlUolVq1bxABDFJsXjcUSjUa5B1Wg0qFQq+OQnP4kvf/nL+PCHP4yPf/zj2Lp1Ky655BK8+c1v5laprq4uJJNJVgcPHz6M4eFhPPHEE3jmmWcQCAQQDAbR3t6O2267DX/6059w2223cbKD0WjEwMAA3G43urq6YLPZkEqlcOWVV2L9+vVYWlqCRqOB0WiEIAjYtGkTLr/8cmzevBmDg4PYsGEDVCoVtFotLrnkEthsNgwODqKzsxM2m409pMDysn5bWxuroeTLbW9vh0KhwODgIF8ndN4okYFU+WQyiXq9jlgsxhWqpITTMSGFNRwOtwyB0WBgMplENpvF4uIi8vk8N7RVq1UIgoDVq1fjoosu4gza/fv3c/3r6QpwtVrFzMzMGT8vZ6xmJfw5f+Bf7SadV2v7f852X+33KOHl4a+BiPy143w6R6fvy/N52s+n/RXjfN0vCX8e4vE46vU6jEYjQqEQtFotL5WSukX/Tq9vpZ8pYYAqRWl5mohFo9HgKW2tVgun04mpqSkA4BikRqPBUVpENjOZDA8f0dIvkVrguWVmi8WCaDQKjUaDzs5OzMzMQBAE9uSKSwA2bNiARCKBiYkJ6HQ6eDweJBIJmM1maDQadHd3c6MWhecDwHXXXYdMJsPWCa1Wi/HxcSY+jUaDUwu6u7sxNTXF1amNRgO/+tWv8P3vfx9btmzh475nzx7MzMzAbDZjYmKC318gEGBvMFkKaJDJYDAgk8lApVJhZGSEH6fjQYp5JBJBpVLB7t27sWrVKthsNuzatQsA+PzQDQepkzSAJ446+8lPfoL29naMjo7CZDLhHe94B+6//36sXbsWn//85zEyMoKTJ09ifn4egUAAQ0NDGBsbYzIqJp2XX345/vjHP6JYLHJCgEKh4JgsjUbDbVyCICAUCgEAT/1TxWt3dzeryFqtFjKZDE6nEw6HA5OTk9Dr9fB6vXA6nZDL5fD7/VCr1VCr1TxgRzc14usqm83il7/8JS6++OIX/LycUWF9oT+KL/eP5dn6vfPxj/VfwpfcXxqk43j28Eo/ey9W93q28Eq3dbZrXKUbUwmvJmgZ2+VycUA7+Scp2orImFhppa57YHnIhRquDh06xOHvNDij1WoxOzvLQ0SlUgk7d+5Es9nEjh07mHCRv5AyODUaDZrNJiu+RJBPH45ZvXo1DAYDVq5cCQBMkMRkhEiZ0WhEOByG2+1GMplEKpXiLNVcLgeVSoW+vj7edq1Ww8aNGwGAp9pXrlyJgYEBpFIpeDwe3i9ano7FYlwXSnWf1Oz1zDPP4Ctf+Qpuu+023HfffRAEgStFxftNxJGOoU6ng0KhwPr165FMJpHL5diDSipwX18fHyej0YhGo4F9+/bhn/7pn2A2m2GxWGCxWGAwGGCxWPgxuuFQKpXs+6RjkkgkMD8/j3g8jlwuh4MHD0Iul6Onpwf5fB6rVq3CO97xDnzqU5/Cd7/7XVxzzTW45ZZbUK1W2T8ql8uxY8cOPP7445ibm2PFtdlswuPxwGAwwG63I5fLYXR0FCMjI5zaQNfoypUr2VKgUChahvWIfP/hD39glZcSL8TXCg2lJZNJviGja4/qYsXbfT68qpaA5/vy+HO/UCTS8vrDubYWvN7wYmkZ5+sN42vhqT1f3quEv06Qn1Kv10OpVMJqtcJoNPJ/Fw890SAPDawQwQqFQrwUfvLkSaxcuRLZbBbJZJK9sJVKBc1mE3v37oXT6YTNZoNCocDIyEjL/hDZdbvdAMD7JlZeab/IT0uDYzRlrtfr2UNJ+0u46667kEqlOGyfGrSoNSmVSvE+E6LRKPx+P5NnypGl2tm1a9eyWler1ZDP53n4iEgRbf+JJ55ApVJBJpNhck7ZpLQkLlb+6GaBCDUVC/h8PiQSCVgsFnR2dqKvrw+CIKCtrQ1msxldXV3QarVoNptYu3bt8557ceVtOp3mNq1isYhUKoVkMol4PI5CoQC73c5qLwA+3tRqRuei0Whgdna2xU6hUCjw8Y9/HOVyGW1tbXC73ejs7MQ73vEO9PX1oaenB06nEzKZjNuzaBAQWCa2c3NzyOfz6O7uRigUYnWd4Pf7+bptb29nqwKp+3QsLRYL1Go1/vCHP+B///d/MTw8jLm5OUSjURQKBUQikRf8rAAv0RLwcnA2/tC/Gl8WZ1KMXspS/9kg4a8n0PGUjtH5h9fa2iJdAxIktEKn06FYLOLQoUPQ6XQ88U9k1GKxIJVKQafTobOzk1ujxMNHwHNDURaLBel0mskNKVjkh83n84hGo+jo6ODHiTSSgkY+RuqVpyGf9evXY3h4uIXUyWQynDx5EnK5HHa7HYVCgVVC8XNoO0RwaRsul4t9qF1dXdDpdPB6vfwY/T4RaY1Gg1gsBpVKhUgkwmkEYhuEVquFTqeDXC5Hf38/SqUSDh48iF/+8pf405/+xOH3CoUCR48eRU9PT8triffZYrHA6XQin89jZGQEb3jDG6BQKDiTtVgsIhQKwW63w2q1olwuo1gsolKpYGBggJfBAeDee+/F1q1bsbCwgGQyySR1enoaWq0WgiCw+vrII4/AYDDA4XAgGAxCr9ejVCphbm4OHo8HCoUC0WgUJpMJADg1gMi52+1GNBrl90FtVtSMlclkMD8/j7Vr10IQBGi1WqhUKnR3dzMZ1Wg0LccFALLZLEwmE2ZmZtDW1gYAaGtrYyWfPK3RaBR9fX2wWCzIZDJwu92spguCgEKhgNHRUYTDYQDLXu5yuYyBgYEzfl5eVGF9KV8yr0Q1PVdfYmdSk16K0vRciJP0JfxSIC2tnh84XU39c1TK63HDa24HeiXblj6bEs530CS4mHiJo35IqdyxYwc3L5HXlJ4jhlar5XYrUrxoKlwulzMBjkaj/DtEjs1mM1wuF1wuF8xmM7xeL9rb25HL5dDb24vh4eH/Z7lcLpcjlUohEomgra2NiWitVmMCLFY/q9Uq/H4/LBYLvy8azorH49Dr9VCpVDAajVizZg2/P7IVWCwW9Pb2oru7m/M8XS4XE21S/YgAUnNXqVSC3+9HNpvFiRMnsLi4iEajwa1a4puE7u5ubhmLx+M4evQokskkE+5kMsk3C0SUQ6EQTp06hUwmA7vdjq6uLrS1tUGn06FSqeDRRx/FHXfcgVKphDvvvBO33nor7r77bvzf//0fDh8+jMcffxxPP/00VqxYgT/+8Y84cOAAwuEwJxOIa1atVitkMhn8fj9uvPFG3HvvvZienkYul0OhUIBer4fdbudzcdFFF7UcH5lMBo1Gg0QiAUEQuLGLyg1WrFjRcpNA59lisUCr1aKjo4MV8nK5zNFYyWQSQ0NDCAaDvK9+vx8LCwuoVCqwWq0QBAG1Wg0ejwdveMMb4Ha7sXHjRrZctLe3n/Hz8qpYAl6K7038vOf7Wfqy+euDRFpfO7zU+uTz9ZyICfWrsaQv/X2RcD6AiB8pYLSETSSBIoAef/xxTExM8BQ2AE4KEMdaBYNBJibxeBwKhYK3ReQqEolwEYE4O7W9vR1tbW2w2+0cOE/Km9lshl6vx+bNmwGAH1uzZg0v0QeDQWzbto2bnbRaLe8XKbnU5DU5OYlms4nJyUnOhXU4HIhEIhxOT2TVbrfD4/Hw8Uomk+xTbTQa7MsUZ4LabDYYDAZEo1Feyv/Rj37EajF5hBuNBoaHh1syUhOJBMdMGY1GbN26lcsZZmZm+JiTiktDRHTMx8fHMTY2hnQ6zTcjjz76KABwNavFYsHGjRvhcrmwatUqeDweOJ1OrF27FseOHYNMJkNbWxvWrVvHYfvAstqZyWSYvA8MDODEiRO4/fbbcf311+Nf/uVfUK/X+YaEvMj9/f18XdFxouvGYDBAo9GwWhyLxfha1Gg0aGtrg9VqhdVqhdPp5FYxKhAgb7TNZsPMzAyUSiVcLhei0SiKxSK6urowNDQEs9mMTZs2Yffu3XjLW96C97///VixYgVuuukm/PM//zPv65nwii0BZ/sP//n6RXK+7pcECX8OTrcBvNh1/UpU1VdjO6fjfBr4kiDhz4XJZEIsFoPD4UBXVxcmJyfh9Xp5KZlSA0wmEyulFNVks9k4PJ8yT00mEwKBADo7O5HJZJg0kpq2detWPPDAA9DpdFCpVJz/CixnghL5SCaTcDgcPLRES/5Wq5VtCWq1Gh6PB0tLSzycBCwPYc3NzbUEz1ONq06nY8K2d+9eDA0NIRQKYWxsDIIgoNlswmQyoVQqsepmMBhQLBZhsVjQ09PDyQDUST81NQWbzca1oNSSlc1mOfx/xYoV6OzsZO+vXq/H/Pw83yx0dHRwJiopqBTTpdFoOPYqEAiw2qjX61GpVNhCQcvalCpADWVvfvObubGrXC7jbW97G4aGhlCtVjE4OIhsNouBgQEIgoDR0VH09fWhUChgcXERS0tL3Pil0+kgCAIPdJEar1Qq4fF4cOGFF0KtVkOhUCCZTKLZbGLnzp1QKBQYHx/n3wHAvtxCoYB8Pg+bzYZSqYRMJsNZsjQApVQqcdlll8Ht/v/Ye7PYus7zanideT485BlIipMka54lD7ItS3JiN4iTtG6aNkFv2pu2aBv0skVRoOh0WeSqF50QpE3TfmlcJHGcOGlseIghWbKkaKSokaJEijyczjyP/wWxHj57i5LztfFHt/+7AIHk4Tl7v++7t8C117ue9fRL0Vi1WsXi4iIef/xxNJtNfO973xO19Q/+4A+wc+dOAMCf/Mmf4C//8i/hcDjwV3/1V1heXsbv/M7voNlswuPx4Bvf+AbGxsZw9uxZIbqPwn+ZsP48q3l/nn8oPqrIKwOD/wn4727dr3W8R33/s3qU/2/Hwzl8VETXwODjgGeeeQY/+clPMDIygs2bN2PPnj1CJm7fvo3Pf/7z+D//5//gk5/8JN599108+eST2Lx5M773ve/h5Zdfxle/+lW89NJLkpMaDofxz//8zzh06BAmJiYwOjqKer2OGzduoFar4fLly/D5fJifn8fAwACmpqbEdpDL5RAIBKTLEQuXSAx5jkajgVQqhUqlgmAwiK1bt6JcLmNmZkZahrLgB4BYCPr6+uB2u0UhjkQiSCaTeO2115BMJhEMBhGNRsV/SwU5Ho8DWOm2xJxUqprVahXbt29Ho9GA1+tFJBLB6dOnsWXLFkSjUYsKGg6HRdFmpfzx48fx9ttvC+Gn15djJ+Fvt9vo7+/H5OSkeGR1Bi5jqHROLj3Ev/RLvwRgxaNLD+fjjz+OUqkEALKmiUQCX//61/Erv/IrePLJJzE1NYV/+7d/Qz6fFx8sEwK4RplMRtqblkolDA0NiVIMrJDNUCiEa9euSe4pi6pIgu/fv49MJoNwOIx6vY65uTlLl7NYLIYvfelL6Ovrk/sgnU6L97XZbCKbzWJsbAznzp3D1772Nfz2b/823G43RkdH8dd//df43Oc+h3K5jHa7jbNnzyKbzeLq1auYmJjArVu3MD8/D6/XK9f6YfjIiq6A9SF6a53z47rtaWDw88b/7b3+3/2/8fNWOB8WLWVIq8H/RszMzGDnzp0YHh5Gp9OROCZ2n6JqmUgk4HA4MDU1henpafj9fty6dQuxWAy3bt2yhPo7nU4sLi4ilUpJEde+fftQLBbh9/sxMzODQ4cOod1uw+v1YnZ2FgCwf/9+IV4kJ41GAzMzM0KuGKs1NjYGl8uFWq2GZ555BtevX0e328Xp06eRSCRQq9Xg8/lknt1uV5RLr9cLn8+HgYEB8WayerzdbiMYDKKnpweBQADvvvsuFhYWpMUsEwD4HpJGv98vHZoOHz4sdgF6bnXaAhsdkMRGo1FUq1Uh2fS8FotFCeUnKd24caOQWYLEmteAx3G73Za0hD179mBmZgb1eh1XrlxBrVaTFreVSgWlUgmdTgf9/f0YGBiQArJsNgsASKVSmJ2dRb1eR6PRQCwWw8GDB/HWW2+h2+1iaWlJ/LwbN27E9PQ0gBWf9OTkpKjzjJTyer1oNptIpVLodrtIpVK4d++ekHF2AysUCvjggw9QKpWEoN6/f19Ib71ex9TUFCKRCJaXl3H9+nXMzc3h+9//vqj2f//3f4+pqSnJxF1eXsbMzAwCgYB070omk5L7+zB8pIT14wLzx+7jAXMdPnr8LFv8/5XffdR4WBGYuWcM/jdj8+bN8Hg8klHZbrdRqVSQyWSQy+XwL//yL2g0Gnj99dfR6XQwOzsrxTTpdBperxfZbFY8lfQn6iQBkthwOCwdiFKpFMrlsmyRs3iKaijJKAu8mPlKdTIQCIjqd+LECQwPD6Pb7SKRSCAYDMLv90vmKwAhovQoOhwObN68WarEWdDjcrlQKBRkniSc8/Pz6OnpQTKZxMDAAGq1GsLhMLxeL65evYpdu3bB4/GIAssiLRZ66XagfBiYm5tDo9HAwYMHUalUhHAODw/j8uXLcLvdmJ6eRrlcFtUymUzKsQgmINAKoPNqtSfT4XBgZGREYrXy+TxCoZAozqFQSFICuGVOywWwGk0GQMj0+Pg4Wq2WFEAxKYHFVSSd9Pi63W6cPXsWO3bsgMvlkgehTqeDQqEg4+F8u90u5ufn8dZbb1nmzGOykxoLz5rNJorFIl555RWJX6O1YGRkBLOzsyiXy2JPOHTokDxEsMjvUfj/BWE1MDAwkWwGBh83/PCHP5TvqeYBkIIXkoylpSX4/X54PB7xVHJ7l12rtKJ39epVDA4OIh6Po9VqIR6PI5/PSzFNLpeTLlgkXE6nU9q6smUst+bz+Ty63a4QO6qTTACgd9Pn88Hj8aBSqWDXrl24evWqzI8xWSRybrdbWra6XC5MTEwgFosJwXa5XLImVDYzmQx6e3tFqTx06BB2794txDQcDgsB11vzAKTzEwlat9uVdqLvvvuufO6DDz4QEsbrAQC3b9/GyMiIEFNu+VPBJQnTntZisShtZguFghTXsT0qsEL+OLZ6vS7q7s2bN0WFZHeq3bt3o1gs4saNG3j88ccxMzNjyY/lNeO6kgxTGS+Xy3A6neKFZVoCm1EkEgnE43GLikw/NdcOWGkCwCQFANIWl0VZbENbqVQkw3Z0dBShUAjlchmRSETi17gGgUBAWgg/DIaw/oww25L/fZg1NPh/CXO/GXzcwZ7swAqpYEtTkiEdH8Uqe91ClSQ2lUphZGQEPp8P//mf/4m9e/dKID4tAgCkg5IukqJqx/acVOV8Pp+QMCqFVN7YmYieTb43GAwiHA6j0WgIoQVWA/iDwSAikQgqlQrOnj2L0dFRZLNZnDlzRtQ4qrJerxfPP/+8dOCqVCri29y5c6eoqIzxIoHX/7iO7XZb2oJyLI1GAxcuXMCuXbtki5xb4V6vV3JQeZybN29iaGgIxWIRiURCriHJncfjQb1eF3LItV9aWsLc3Bxu3bqFfD6PcrksXa0ajYb8oyWExLVUKlna8zabTWzevBlzc3M4c+YMDhw4YGkfy2I8Kps8Pwk0AExMTEizgaGhIXi9XpTLZdnqX1xcRCQSsfhdg8Egstks6vU6wuGwdBSj7YNqfDAYRCwWg9/vRz6fRzgcRjAYRG9vL3K5HNLpNPx+PxKJBObn5zE8PCzjZbtb7b9dC4aw/owwf/gMDP7nwPx/NfifgH379iEYDKLVakmhC7eti8UiqtUq6vU6/H4/7ty5gxdeeAHxeBzFYtGy3V4sFpHL5YT8FItF8VZSAWVMFoPt9XYxsEIQGc/EQiBNbpvNppAo3QHK6XQK0e12uygWi9i6dauQN76f9gUqfYlEAt/+9rdFKazVarh79y4ymYwQc3aScjgc4nNlikG1WrUoqU6nEx6PR1Reh8MhSiBtDezWRSWUcVHRaBQ9PT1IJBJCugDI+jmdTly7dg03btzApk2bRFHlV6qQ+kGAWaaZTAZOpxNDQ0OIxWIWQstGA6VSyUI2GW/GsReLRSSTScm3rVQqqNfr2LlzJ27evCneYN5DsVhMVGSCHcvcbjcqlQq2bt0qDxQk6k6nE4VCQR6KEokEDh8+jNnZWfHIMp3g+vXrlmKwxcVFmdvWrVsxPj6OPXv2oF6vS7bt+Pg4/H4/kskk7t+/j97eXiHWupPaw2AIq8HPHf+vOygZGJgMZ4P/idCZq9xmpxLIqKZisYihoSHkcjksLy9LARJ9ityK5x98kjVgVQklseh2u/J7qmfMUfV4PKLk6T7vVDVbrZb4EUnk9FZ0q9XC9evXUalUpAjK6/VKwdbS0pIlHzYUCuHq1au4d++e+ExDoZB0b6IH9c6dO1KUBqwowVoRZdU7W5Vy7tzSr9frUtBFWwIfDAqFAs6ePYtQKITdu3cLAaZyqRsfeL1eVCoVTE5O4u7du6IqPvvss5bcXPp8G40GAGBqagrxeByvv/66tFxtNptSEMcoMV67YDCIYDAo83c4HHLNDx48iHK5jGq1Kj/zexLebrdrUb+5lnv37sWFCxfg9/stnbGoUvN9fMigyjs9PS2q8uTkpKjntC7QE8x7jPddu93GlStXsG/fPjidTlSrVbFh8Ly0MAwNDUnnskfBENaHwETqGBgYGBh8lOjv7xdiMjQ0JOSDcVLcDr99+zbm5uawfft25PN5RCIRIUa6YCiRSAhR4bFCodADhKJUKgnhI5rNplTaDw4OolqtWgh1p9MRkkPbAivZ9+/fj3PnziGVSmFhYQHNZlPGxXNfvnxZlEwWFm3btk1IJr8mEglMTU1hbm4OTqcTzzzzjJDVXC4nJI6qHAmT7ujVbDZFbaSayt+73W7p2sX5V6tVXLx4EQcOHACw4qnUHcW63S52794t0VrValX8wjdv3kQqlRKV0+12S1EUAIyPj+Mf//EfhaTpYxK6cxnH5fF4sHnzZrmOzDkdHh7GvXv3UK/XJXv16tWrKJVKKBaLQrR1q9n5+XmMjIzI9aJnlaBfWhfd8Weq+bQ8VKtVeDweWVMAlhgv+5zOnz+PnTt3Sser6elpBINBVCoVbN++HQCwa9cu/Oqv/qqs2cNgCOsjYMjqfx1m7QwMDAwejUwmI9vry8vLqNVqsh1NZTQej1uim6j2Uami8sfgem5RR6NRKeihgqeD9UmEiJ6eHkQiEXS7XVy7dg2BQADJZBLlchn79u3DuXPnhIS43W4hx+l0GidOnEC9XkcoFMKePXuEYLHwqFKpoFgsolgsIp/PY3p6WpRQl8uF/fv3o1qt4rHHHsNrr72GfD4vRWSsYAdWi4hIVgGgUqlIoD+juBion0qlxCLA7eZut4s9e/ag3W7j+vXryGazOHbsmKjUAITMs2CL7UZJqHt7eyWjFYBs8QPAs88+i3feeUcsEXfv3hV7AN9jhyaX/JmeViZILC4uol6vS5cuWkDYKevq1as4e/asJcaL5Pf69es4ePCgEFbeC5wn7ymq5o1GQ5pLJBIJieratGmTPMDQ6kALhCarmniTfJdKJXS7XTQaDfj9fon3YlevD+tyBRjCamBgYGBgsC6gIsf2ofSCMlrI4XCgWq1aYqWazSbu3r2LwcFBS2GUvbMUM1W5Hc7uUN1uF8vLy0gkEuJ1BVYU1uHhYfzrv/6rbGenUinUajW89tpr8Pl8OHTokBCdubk5KcBhsgAr1Jk6wLnEYjHE43GpaCcRpB9zbm4Ofr8f3/ve96Qo6fnnn0coFMLy8rLFF8rzMM+VLWZ5TG5p6/drOJ1OjI6O4pVXXsHWrVvhdrtx7949bNu2TT5P0sfj9Pf3S8C9x+NBPp/H1q1b5XhUn7vdLt555x05b6PRwLlz58QeQS8xwXUCINFUJJvtdlsyd0l0OVfaNhhFk92JtwAAIABJREFUFYvF8OyzzyIajcrDCUnjxMSE3Bu0RPB60VpCOwOtEBwb16BarVqizCKRiNxnmiDboYkz10lfBxZb+Xw+S9vYh8EQVgMDAwMDg3UAGwWQZJFQkmw6nU7xD3IbNxQKiSWABCAQCFh8kyx08vv9WF5eRigUEsWSrUVpFyCJqtVqeO+990SlBCCxT1Te3nzzTYRCIVQqFSFa9L0y8YBxWVTSQqGQRYljPiuPyzzOV199VbyWg4ODKJVKWF5ehtfrFWWQW/8kUiRuPD69m7qlrG6bCkC8sgcPHkSpVEIqlcL169fx2GOPWVROAOKnZRvVnTt3ytY+VUquNbfT2+02hoeHsbS0hHa7jXQ6LQH7oVAIpVIJ/f39SCaTuHr1KsbGxtBsNuW9mtTRG8x5XLp0CZ/5zGekYIw2Dl7DPXv2oFgsitrpcDgwMzMDYMUGsn//fkkeYHEelU1u6etcWZJVEk57zizXlCkMumjKPnbeU7zX6ffVRNn+cGGHIawGBgYGBgbrBKp49JWyeIgRV/yj7nA4EAgERKUEVryXPp8P+XxeOg8BK15PNgvo7++3kA1NtHT268DAAAYGBvCd73xHyDA7I3FLe8eOHZibm5OiLLZIJdHu6+tDLpcThY8WBB1VxYInxl719fXh/PnzeOmll8QjurCwIKQwGo3C4/EImeHYqCqTxJIAkejT32qvPI/FYvB4PJifnxerQavVwuTkJB577DEhUAAkf3YtFbFSqcj3dj/qzMwMXn75Zbz66quiNA8MDGD37t1YXFzEjRs3pKp+amrK4qe1+1kJp9OJyclJWQs+TPChxOfzoVQqIRqNSpOBy5cvy/1SLBbFnrBly5YHUg04T6rinK/2w7Kin80qGJPm8/nkwYTXgbsHVHGTyaTcMy6XS5RiXdz3MMsEYQirgYGBgYHBOiAYDArp01Xe/EOey+WkVSvjqVjVXa/XMTg4KP3pmZMZDAaRTCYRDAZRrVZFbWRMEv2Jvb29Ev0ErBCW2dlZjI2NoVQqoVwuIxgMSntNeltDoRCSyaSopJlMBrFYDI1GQ9RE3RZVFy8xmSASiWBpaUlIyujoKO7cuSN+R5JsTRJ5DO2VpApIwsfEAACizOrfsRXo9PQ0tm/fLgRNb9PbvZR6DLRaaCJpLzTiv29/+9v41Kc+hffffx+Li4sYGhrC6dOnpdOTJvT685qoaosHt/u73S4CgYB0KuPDx8LCAgYGBizNIObm5uRnpiSk02kpvKrX6+jp6UGj0bCo03zg0WOkn5jkfdOmTWIP8fl8iEajqNVquH37NpxOJzZs2IBAIIB0Oo14PI4XX3xRlPxr167hwIED+O53v2tZ44dZCwhDWA0MDAwMDNYBuVwOfr8fwWAQ5XIZ0WhUFC+9ZUrVMBQKiTpFMtFoNCTon33pA4GAbONqz2IkEpHOQ51OBwsLC0J8ZmdnEY1GRZktl8uypR+Px1GtVsVvysr4ZDKJbreLXC4HYNWTyyIwvsZ/sVgM77//Pvbu3Yu+vj6pGqcPNhKJIBwOW0gmob8nkaM6zDVjQZCuXtfeXobW25VLDft5AVi2/vmP7W9JmHVAP/GDH/wAv/7rv46JiQlcvXpVPKok9WupmPbiKxJHPqwsLi5KIRvTINhylw0NdBEYj8+fmYk6MjKCmZkZUYrpk9bn5vZ9q9VCf38/bty4IXNgnJnOuS0UCqLuskiN9pbZ2Vnx9ur1pHXjUV5YwhBWAwMDAwODdcD09DQACAktl8vI5XJwOByIx+Pw+XwIBAJ44oknMDk5iWKxKIQhFAqhUCjI1myn04HP55MirlgshsHBQSmsSqfTyOVyQkKmpqbg9XqFWMZiMbTbbSmoYRzW7Ows4vE4ent70dPTIz3ua7WatAZNJBKiuGoCpy0OZ8+exeHDh3Hw4EF0u10sLi5KC9He3l7ZXtYq41rb41r142tUgDUBosrI32/YsMGiKOv2thr63LoASkMXlHE9ddEXfa4AMDMzg4MHD6LVamHr1q2oVCqSmlAoFCwtTvVWvD4/1WK324379+/LQwqJaavVQjAYFOuGfT5Op1O8rlRCK5UK+vv7sby8jEqlgmazKQ812rfKLXymWdDuweP6fD74fD5LlBetGgCk8QU7axUKBczPzyMQCMic7AT7YTCE1cDAwMDAYB3A2CgSAFZ8+/1+UfBcLhfefvttFItFhMNhxGIxlEol8YBSmRwYGBACGI1GJXJKt94MhULSQjWZTCISieDSpUviiazX66jX62g2mxgYGMCVK1cwPDwMAKKi6UxXnv/u3bvYs2cP3G43Tp48iWg0itHRUbRaLVy9ehWHDh3C4cOH0Wq1UC6XpVWsx+NBJBKBz+eTc2jY45EAWArS7CRH2wj0sUiiZ2dn5Rg6a5SvUW2lVYAeTN35S1e8MwtXK6ysricZrlQqSKfTePLJJzE+Pg6v1yvXi9BElWMnSdbb8E6nE/l8Xry3TCJoNpuIxWKSOavnw8KnVquFgYEBia3KZDLweDyIRqPie+VDBAky/alU8vv6+mTutBRQVWf0Vzwel0QCqr+cA8fG+1uv11rX3w5DWA0MDAwMDNYBo6OjotYxgopFP2wQUCgUMDo6isnJSSFqJJzbt2/H4uIigsEgbt68KTmqJAg61ioSiVjyWKnmcttcK6sAkE6nMTY2ZlEZSTja7TbK5TIikQji8Tiy2SzeeOMN8UHSn7p582YcOHAA1WoVxWIR8/PzWFhYQCwWk7QDDZIsVp+TyPJ1VuFzDBwbiaZuF6tf1/msxFrKqlZKSfK0z5TkX3eE4vi0AqwLiLgeqVTKEq6v36/jtzgvFt2xiQEJZKVSkRa8Ho9H2rSSXNuLtQgmOXC8ACTPtdlsor+/H5s3b5Z0BqrpVKxzuZx8nq+x2IqknIVXTGbg9+VyGQsLC/J7rjPfx3Wwq8N2GMJqYGBgYGCwDqhWq4hEIqLO6bgk/iFnwZXL5cJnPvMZXLp0CdPT05icnMTNmzdRKpWQTCZl65aqJ1u8sigrEokIIRgcHJSe8NwGrtfrCAaDKBQKCIfDiMfjUtXN41H9XVpawoEDB3Dt2jX86Ec/EgIyPDyMLVu2oLe3VwqBisWiRF0lk0n09fXJ9jKLhkig6IesVCqW9p20G+iEAM6VxJN2CF1gReU4Ho8jnU4LyWOiApVAfs7erYnXhWNh7qy9ol0XmfEBRPtPm80mbty4Ia1wqdbyn8fjkQcLJi7Q+rCWt5RrRlLIz5MMas+qTobQarXuDMZsWTYKmJubk+seCoVQq9WQzWYfyHhllBiw0jAhn89jcnIS8Xgc165dw8jICICVh5+5uTnMzMxgz5490tXNbrUoFAro6+t76P8XQ1gNDAwMDAzWASQzzNPs7e2VzNHe3l4kEgk0Gg3k83m0Wi288cYblu1hbseSUGkCwJalwWBQSA/tA5lMBuVyGaFQCN1uF88//zwKhYIQBhb0MIczGo3KFnAkEsG1a9dw7do1KQzbu3cvtm3bJirmvXv3UK1WAUCSCegfJYmjD5NtPxn+z4p0EqqFhQX4/X7E4/EHkgDC4bCQVx2lRTLa6XQwMjKCcDiMdDptWTtdnGUvNNKwt1MlYdRwu92SM8rza8WUftparYZjx47h9OnTclx+JXnngwcTE+z2B37l9S+VSkLAeSw9f/pJG42GdOeiiqsVV947CwsL0qWLSv7y8rJFFeX3jUbD0uLX7XZj8+bN8Hg82Ldvn4yNtpJ6vY6zZ8/iwoUL+O53vys7AoxJe+WVV/CHf/iHD/3/YgirgYGBgYHBOoAKWjKZRDgcRrFYRLVaRSaTQalUkup7HW9ULpdRq9WQTCYBrKi04XDYoj5qlYqEgN5PtvukwgqsZIqGw2H4fD5JGWB0Eluclstl6dpEMvX0008jHo8LeaEPUnezIqHRKiqD5svlsiil+XxeXqfq6/f7MTo6KtvKmlD29fUJ+dSB83qrn2NfWlqSwjTtl6R6qgmh9srqyCzdFlavLY+nx6D9sbqwq9Fo4MaNG4jH48hkMvIeKrIkq/oYzK4lEaZ9hPcOySmPQzVbH2P//v24e/eu5K6u9TmtMutKfyrCwErnM6/XKzYCXk8AlocmruHo6Kj4Xt1uN3bt2oU9e/bgypUrmJ6eluOS0I+Pjz/y/4shrAYGBgYGBuuAI0eOYHx8HLOzs5J/2dPTg263i1QqJaRC2wV8Pp90GfL7/YjFYvI+blUvLy+LOkcVk9FU7EhFwsq2rfRjAiuV7alUCsPDw5icnMSbb74p5M3tdmPLli3S9Yk+y1KpJHFZVO/0FrlWeRuNBoaGhqQdKbBKBF0ul2y7NxoNS6GO7uxVr9fFY0mCpMknExSy2Szm5+ct2/Dbtm2zEE+99U8vK9cdwAOKqrYArJUhSgLI1/nQ4HQ6sby8jEOHDmHz5s04c+aMRR3lZ7l2hMPhkPkzhorz0QozLRC0AHDdOFfOj9eRc9Df6/fpDmGMQ0skEpJCQevF8vKyHJPnDYVCaLfbos7z9XA4jJGREezbtw/pdBoAJBrNbhGwwxBWAwMDAwODdcDp06ctld20AOj8Sm7JAxBiEY/H0Wq1UCwWpQ+7z+eTbfapqSmMjY2hUCgIkWWCwHPPPSfnK5VKEjvF6vFoNIqhoSH89Kc/xaVLl0TNI1Hdu3evKHXNZhOFQgG1Wu0Br6k9nsnv98Pj8YhVgSSRBUVU97SXlKSJ46X/FIDMWxNGqpHACmHauXMnJiYm0NvbK2uuVVVN4EiudSEQz031kARW57vSR8qiJ63U6jXQBPnChQs4cOAAhoaGkE6nLZYCYNVWQJuD2+2WB41isWhZJ5JmnXxAstztdvHMM88IkdSNFLhmBP2p0WjUEh3G47daLVQqFdy/fx/tdhvZbFZirlKpFJrNJhYXF8XaoAveuC5sTVsoFODz+Sz3waVLlwxhNTAwMDAw+DiCgfpUFKlEsvobACKRiBANnSAQCAQQDAYBQNS7a9euSU5rLpeDz+cTxbJSqcDn84kfUbd+XVpawsaNG9Hb24uzZ89idnbWEsbf19eH5557TkgZUwJIrklCddW/3gq3q4WaHGpPqa6818chMdW5q/ycVgc1EduyZYt4fwntT9WeUPtntQVAWwF0KgBJHY9DBVnPk0SR79WRUz/96U9x5MgRtNttLC0tSZIBYY/H0oR+//79lnslEAiIqktFFIBk2/KhQLdBtYP3V6lUEiJPO4cm31o9r1QqiMfj0mSCMVn6XKVSSa5ToVCQOZHI8pq/9tpr8jDyMBjCamBgYGBgsA6gV7DdbiOfz0v3J6qU9BEODQ2JwsZiGJIb/sFfXl7Gxo0bJS6Kx1heXkZvb69krLJjFTNQe3t70dfXJ+kDOvIoEAjg+PHjCIfDltau+XxeSKQuAtLby/r3Ot9UQ4f88zgkQ1T17GSJX+12CW6ru1wuiVqan5+Xuej8UK2Uchwk4jovlISeZJIqpB6DbhKgrQPa/8rP6LXodru4cOECtm7dilKpJN5d/o7klGPds2cPKpWKtLHN5XLieWXxHT2vJKjPPvusWD527tyJmZkZOT5BMqxVXarKLIjTXan0ugHA0tISenp6UK/XJWkgGo1K0wtmxnI9+QDFByKej22EHwVDWA0MDAwMDNYBLpcLlUoFwWDwgeKccDiMRqOBXC6HVqtl8XAyEoqtXUkMGD3FinASQiYPtNttxONx9PX1IRAIwOfz4datW5iamrKQQ6/Xi0QigePHj8PpdEr2JwP0dXC+Lt6xFzTpfFG7RQBYVSqZ30oSTqLI99uJEs+piaAmy2NjY0L27dBh+hyLViV5blohSKb5AEBSS6KtVVP7/Kh6arKrC6KYTzo2NoZr165ZCLndIxuJROByuXDz5k2Mjo5ieXnZYp2gt1lfQyIUCuHChQt47LHHsLCwYPHn6ocIdkvTW/NcQxJLemU1ge10OigWi4jFYigUCvIQ1Wq1JDKNEVjsgMVr4fF4UKvVHki5WAuGsBoYGBgYGKwTPB4PyuWy/HEvl8sIBoOyzcpuVO12G/fu3ROywqKraDQKl8uFRCKBZrOJ69evIxgMotlsClmgaluv1zE8PCyFMh988AHK5bIQwUgkgiNHjlh8ryyoshNS7R+1+019Pp+8R0dCASvKIwuNgNXUALvqx692cktfp35NE6dYLIZqtYqlpSUZm30LXKuK+tw6tkorqHbyyOMCqz5XkniOh8dZS2HWxHd2dlYeJNhwQVscwuGw2DxYdHfx4kU0m0289957ePLJJ1GpVEQlJunUaiXjrBYWFpBIJJDNZuX49hgvve563LVaDYFAQBRoO9Eloee5isWiPISEw2Ekk0lpH5vJZCwtcufn5y3nexgMYTUwMDAwMFgHVKtV2dL1eDxot9sIh8MoFAqSyTo7O4twOCyeP+aJRiIRiRcKBoPIZrOyDRuPx3H//n2Ew2H09PSgVCpJV62LFy8il8uJqulwOBAMBnHw4EH09fVZPKrFYhGlUkm8kIDVm0ro4h+SVa0SAquV9ZpI6XQCEkM7GeZneR6CaioJKdU/n88nhT1aRWw2m3I+Tbzt2/R25ZHzoDLL7XbC3gqVn9FWAT1nTYKpWs7Pz+PQoUNSvKaPVS6XEYvFJBvV5/OJ1WJpaQlLS0tSsa/XV4+RCj6zfD//+c+jVqsJ0dbjXsvny7XRc+D11IkIWgHnvcRCsVqthlAohN7eXinsS6fTqFQqOHny5AP3xlowhNXA4EPwZ/gLAMBf4M/WeSQGBgb/m8DtUaqfJHskVe12G36/H7t27UKr1UI2m4Xf75euVOFwGA6HA9VqFel0GiMjIwgEAsjn85LhOjY2hkqlgrfffhvAKkkkKXziiSekrz2V2Gq1KjmpnU7Hsi2sfZyAtSgKsG4x29VVHaavq+8BayC+Jro8Lz/HKCuG19vtAtxi1tvL9ArzWDw+yTIjsjTR1sSSn+NrVBhJOLXCy+OzQE3PTRdi6cKubreL5eVlacGrlVmn04lSqYR3330Xhw4dkna19KZ+5zvfwZe//GUpbmI+q1aPaQ9gjNStW7cwPDws79PXSycEaNLr9/sf8NVqlZbrwNc492AwKB3L+M/lciEcDiORSKDT6WBqauqBe2ctPFp/NTAwMDAwMPhIoIuSuK3rdrsRi8UwMzMjNoGFhQWUSiVEIhHUajUEg0HpnMRQ/A0bNiCbzYqyOjQ0JOrV9evXpbCHZDUcDuPo0aMYHBy0BPkXCgVkMhnU63VLu1c2E1irWl+TPGB1q57zs5NYRmjRDsACHHtFOrCq5nHcOnqKhI/nGh4eRqvVkq11vp8EkASOXlwSM30sO2nj8bnlrdVYrdZq1ZZfOQZNxvnV7tGdmZlBpVJBX1/fmlX80WgU6XRaCCi7kg0PD+OVV16R6DNNdPV95na7pQjN7XbL/RAKhSwqOK+xLlDTxWD6OvIfVXkNuyLLFAF6hjOZDCqVinhbee5HwSisBgYGBgYG64B0Oo1gMGiJovJ6vbKFy21ordhpkkslcXx8HLt27cKuXbuQTqcxPj5uaa+qi5j8fj+2bNmCLVu2iDeRzQVYXEUlrd1uIxQKiW9UFzbRc6gr7u1Kqs7+1BmgmtACq4RzLZWWa8CtcP5eK3p8zel0YnFxUT5DZY/dn7TfFFj1z3LMOm1Ak1VdVKbnbSdw/Er1lgqsfi+Lxey5qwAwNTWFXbt2iW9YH7/ZbCKfz6PT6SCZTGJychIHDx7Eu+++C7fbjcuXL2Pnzp0AVpMWdPMAklUAyOVyQnCLxSIcDgei0ajko3JMfCBifm6lUpHrT4Xb4XAI+a9Wqw+QcbsXmNmrzWYTfr/fcj/ogqy1YAirgYGBgYHBOoC5pX6/H8FgUAhKo9FAT0+PqIrxeBzZbBbNZhOJRAKVSgWzs7Pw+/3YuXMnduzYgcuXL+PKlStCHrQqyW38DRs2YNeuXWIjcDqdKBaLKBaLAKw+TKfTKeqbfk2TEMDqK9WZprpqXueRAqvtWlnV/jBLAcmP7pql1VxNDBOJhFT787icv66e5xrrQjE7ObWTUU1yOU++ttbWP+fYbDYt2+Y8n14bPhhwe/769evYtm0bIpEI5ufnLcoylcpms4ljx45hYWEBW7duxbVr1/CNb3wDv/u7v2tRvTVppUUEgJB5HQVWLBalcQXzgX0+H2KxmIw5FApJVirHzYcJWioIdirjZ+v1uhDXYrEo769Wq5br/SgYwmrwc8ef4S+M39PAwMDgQ0DitrCwIH/Ua7UaUqkU2u02MpkM2u02gsEg4vE4ZmdncePGDTz11FNStHLq1CkhIFRqCZ/Ph23btmFkZETIC5VUvl+3+CQ5pE9Uq44kdiRpdu+jVsoAWGKP2ATBThoBWHyPPJcu2NIEmcfU2+/szuR2u5FOpyXjU9sT7OPk98Bq9JR9e5vn0N2m9GfoC12rIEyTYGBVQeYcua1Pby2JHNebRXdsd6tB64jT6cTXvvY1/Omf/ilu3bqFWCyGv/mbv8GXv/xl8dLynFRzub46/1df+0wmg2QyKR5hvkerzmxyAaxEXmWzWQSDQYRCIUkJqFQqiEajyOfzCIfDoqyGw2EEAgEsLCxgamoKAwMDDzSKeBQMYTX4SGBIq4GBgcGjQcKQSqWkrSiD7wFgYGBAKqwzmQy2b98Ot9uN8fFxiUPqdrsIBAKoVqtCsvx+P0ZGRrBlyxYAK4oaySnfp0kNAKnwJ2kiSdTqqCaB9u1wjp0g6dEB+lR9+Xsey54KwN/znPy99rDq99EuwGNznPb4Jb5m91uu1VjAHk0FQOK4GBtGtZFb/CSda1kFeB4WRfFz9uYITA0YHh5GMplEt9sVewfjo/7jP/4DfX19eOaZZ3DixAkcPXoU8/PzyGazeP/99+UBg+vLByN7igHfQyVYrx1JsV4zXdBVrValw5km+dVq1fLwEgqFUKvVUCqVMD09jcHBQRSLRaRSKSkatCdKPAyGsBoYGBgYGKwDmAxAP2o2m8Xg4KB0ByoWiwgEAgiHw4jH47h48aJYA/R280svvYRbt27h3r172L17N1KplBAoFrQwS5UgGWX1N7BaBAZYlU9NYvX2tlZUNSGiEqeLonQiAAkUocmSVmip/NmVV57D4VhpwZrJZDA9PW1pFKC33UmmdKGU/TjaDkFVUausWh2lJYDzorKtySrJs56PXYnm+7WlgGt9/vx5jI2NYXBwENPT0xZlk8TV5XLhz//8z/HDH/4QO3bswOTkJBKJBGZnZ+W8V65cweHDh9HtdiU6jVv5Wj3ngwCL7ZinqwvHeJ+SuOuxawXa4XCgXC6jVqtheXlZiv2Y9hCJRKRwkF5d+4PIWjApAQYGBgYGBusAnetJpZV/1MPhMIaHh+HxeHDhwgW8++67WFxclO1cFr04nU5MT0/D4XDg6NGj6O3tRaFQQLFYxOLiIvL5vBBgbqF7PB5LuDyVWk2k7ASCCqYmdnaQyFWrVVEOSa5IsO0V+fbP83We356TqtuE/uIv/iK2b9+OhYUFIauaRPG9/N6uuPJnTSo1gbNHW+k5ArC0x2XSgU4jsJN5zoPj4vWwz5nzXlhYQKPRwPDwsHSYojLKrfZut4uvfOUrOHDgAIaHhzE7OyvjYqFWq9WC1+tFIBCQQrCJiQnx/HKN9FyppNZqNUuaA8kubSUkwPoBgPcRSbWOQ9OqPrDaSUsr+A+DIawGBgYGBgbrgL6+PiFxgUBAfH49PT1Ip9N47733cO7cOZRKJWkVSoIVDAaxZcsWfPazn8XAwIBEOlWrVVSrVQmadzgc4ktln3luZQPWQhceX/sfgVXvp53E2SvnWZVP4qVjpKhGAtbKe6qG2i9LBU9vYfNnEvwvfOELcLlceO2111CtVkXB1conC3u0+qthV22BVXWVY+Z8tboMQBovkHDq8Hy7fUF/Vvtg+bO+Hlq1ZiMBJjvUajW89dZbqNfrWFpakoeWb37zm5iensYv//Ivi1/Y5XLhwoULcDqdqNfrePzxx1EqlSwqLcfPtaH9g19pU+E14DWlx5lz48MJ7xUq1vY4Ma1kk7TTovJh6ipgLAEGHwGMd9XAwMDgw0H1Kh6PIxwOo9Vq4fbt27h//75l61Z7M0OhELZt24bBwUGLN7VerwtJ5XuBtdts2rek9fsBWF7TRJLEw66+kshQqdNb59r/qreXdVEWj6Er0EkA7b7GTqeDRCIBv9+PV199FdVq9QHLAMemvZkckyZHWrnlezgHkl4SeL7m9XplHi6XSx4k9Hrxc9pGodVWXaEPWLuHMYKLY1tcXEQ0GkUkEsHGjRtlW7/b7aJWq2F4eBj9/f34oz/6I/zDP/wDDhw4gDfffFPuDY75woULonbyvOPj49i7d694pkki9Vi4C6BtG3xw4INQp9ORa6djwvS14Gv6vQCkqOzD/KuAUVgNDH4mGBJuYGDw80Y6ncbAwAD6+/tRr9fx3nvv4c6dOxKoTjLkcrkQjUbx7LPP4siRI0gkEqjVaqhWq2g0GigWi0JW7UqXvRMVof2GVNl0QDyJC0mMrubWKiGJkVbSuH2sq/UBaxyUnfRqxVWTWt36lO/7xCc+gVKphEqlIlv9+th6W/1hgfb6db5Xb1/b141EPRQKIRaLwePxyBa5Vi31eNeyOOguYfpacUz2CK1ut4ubN2/C6XQikUgIuaRyPjg4iKGhIRSLRXzjG99APB6XxgBsVfv666/D4XCIek/fdKPRwPnz5yXWjPOfnZ2VtdbjcDgclmQJ3iM6iUFfS03YOeZWqyW5rlqFJwl+FAxhNTD4EBiyamBg8FFgcHBQulf95Cc/sah1JC9+vx9Hjx7FsWPHpFCFhJBeQns+KsmnfUsXsLZJXWv7n+/hlrg+piYidjVVq4rsZKWr0XXVuR6P/tmu4pJA6bF97nOfg9/vxze/+U0pKANWSdJaFf96+11bBLTqqrfFteLJ70k2RSawAAAgAElEQVSKqYrrjFtCq6ZavdXkTT9YkPDrJghaEeZ5nU4nrl69imQyiWPHjsk5mU8LAHv37sX3v/99XLx4UZImSqUSyuUy9u3bh97eXtRqNRQKBSHlHOOtW7fkunU6K3FnfEDR5F9bGDQJ5fvWUti5Q6CLs3RsFtex2+1ibGzskf9fDGE1MDAwMDBYB4TDYdTrdfzoRz8SwkBF0+Px4KmnnsLx48fh8/mkIQB9qtlsVjpdaeKpyZe9+Ecrhnxvq9WSYH2CPkb9s317l+RGR1xRbdXFZHZCrAmOtgTYybZ9/JxjX18fJiYmhNzreevtfL1tr39nH7N9XewEl+8nySPB4la4Ljhi4ZX2apKsA7CMye7n5e9J9jXx5fZ/sViE1+vF5z//edlyJ6n3er147rnnUCwWMTU1hb6+PmzYsAHDw8PYvHkzvvKVr+DTn/404vE4AoHAAxFkZ86ckXguTah5nWmv0B5dTbi1yt3tdlEuly0POfxH7y+wUtjFoiufz4dPfOITj/z/YjysBgYGBgYG64BoNIo333zT8ofe6/Xi4MGD6OvrsyhT/J6qom7Vqrsu2YkgYN3a1QkAJIPao6m9pSRnmuTqqnASGSqE2vNKnyKJylpV8/rcVCc1udQZsN1uFy+//DKq1SpOnz4NABYipRMAdCIASb72t+pxcjy6KIxk1L4WHGcoFEKxWITf75frYS/s4tibzabkrtqLzDSR1ySda0fiT3J66tQpHDt2DJFIBEeOHMGJEycs5HhoaAidTge7d+/G1q1bcebMGTz33HN49dVXAQBf+tKXsGvXLrz22mvwer3SfYrktFgsyvXUai+LpDT55NrodaSvtd1uIxwOw+v1IhQKSWpBJBKRxIpgMAgAklRAq8WjYAirgYGBgYHBOuDHP/6xEKNAIIDt27cjmUxKtT3JDIuq+IdfF/YAsChZACxkg7/nV11gZH+vroYnGdHEj6omyVmz2bRkperKcx2iz9d4bpI57e3USqreWif27dsHp9OJH/3oR0LeSQC1AqzbveoxcS52skoiptMBuFZaCeU2NlVIl8uFcrksXlZub9tJHMmnJoZ28qzbr9ofHnTyQavVwvvvv49Pf/rTGBgYwNjYGO7evSu5tq1WS7yhABCPx7G0tIRGo4EzZ85gfn4eL774IqLRKP7pn/5JEgV43pmZGYyNjcl5STbpl+12uwiFQkIyuVY+nw8+n09IbLPZFK9sOBxGuVyWLOFyuYxEIoGxsTE0m00hsCMjIx/6/8UQVgMDAwMDg3XCyMgItm3bJsSF6iXJISObqGCSIBFUtDTx1GomYE0MAKxkVRNL+9a0vQjLXsxkJ3j62LqyXNsJtIKqx6VJHn9H5bDb7WLTpk145513sLCwIPmeWqFcK6ifJFBv6+s15ti4ftqSoBVfO6Glh9Xn81nWT9sf9Oc4N60Wa9sGC5H0mPk+3cSg210J9r906RL27duHp59+GrlcDvl8Xtat2+3C5/PB4/FgbGwMMzMzsi7ZbBbf/OY38fLLL+M3f/M38bd/+7eo1WpyfO091kkGAwMDmJqaQjAYlGYClUoFtVoNbrcbkUhEbAYs9gKAhYUFFItFVCoVNBoNFAoFNJtNLC0tYX5+Hm63G6lUCi6XC8ePH3/gIcUOQ1gNDAwMDAzWAS+++KLF+0dy0mw2LdmiAIT4cBtXd6fSxTeE9jgC1qp1vXXNY1MB1eRM+1TtYf96C10TKh2VpYmbjlMCYPHI6rHrrXEiFovhpz/9KcrlsoyVYyOB5vE1edeFQFwDfT6tJHPMnDffR8Jst1WwoK1cLss87X5hPT4SQD0WfX5+zt6ulZ/XdoK7d+9icHAQPp8Px44dw+uvv45GoyH5qFrNjUQicDqduH37NjKZjBTuffKTn8Tv//7v4+tf/7oQT1pOqNZ6PB7UajVMT08jEAigVquhUqnIQxI9y8BKVzaq8HyoyufziMViYsvggxjH5/F4UK/X4fF4MDo6+sB9aYcpujIwMDAwMFgHNBoNS9EKW1WWSqU1ySVVPJ2DaY+s0tX4ertdkzetMpL86u15YJVQ8f32z5KA6CIljlETRjv5BWDx32oVVKcEcC4AsHHjRsv8taoJWLfPtYKriaYuslqrsl0XBvEBgB5bjr1UKgmJ49gZ6UVogm9fU02K9TXTCjRbo+rUAH1MrtupU6ewsLCATqeDF154wVJ9z7UMBAIYHx+XQrienh4Ui0VcvHgR3/rWt+ByufDHf/zHEtMFQAr5Op0OTp48icnJSdy8eRP5fN6SmEBSzweEWq0myivV4lgshkqlgnK5jGq1inQ6jdnZWczMzODOnTticwkGgw/4rteCUVgNDAwMDAzWAYxIWqsynSTO5XJZtovXKhaiUsctax3Ar38mNNljJyV7zBM/qwu7dPESCRsVNb5Htxq195cHVpVVr9f7gKJmj0VqtVr4hV/4BUxOTqJQKCCbzYodol6vIxAIoNlsisoHrBIorQhzbiTP2tvKdbWrslqxZdGU3+8Xf7HX60W1WpUWpvaiMv6slVVtD7AnJ/Cz9IBq1RpYVX7dbrf8/p133sHBgwfR39+Po0eP4t///d9x9OhRWQtN/CcnJ2V9c7kcNm3ahFdffRXbt2/Hb/3Wb+HmzZv41re+hVKpJIRV+2tnZmaQTqctFhBtn+A/j8eDarUKv98Pl8sl99a9e/ewdetW1Ot1hMNhACvKeSaTEUvMh8EQVgMDAwMDg3UA44v0lruGVuK0DYCqnZ0Qsjpfb4vrTlXaXkC/ZSAQAGANsadKp72yhM5VJRnWZAtYLarieHheKnT2aCSqmPZCrXA4jFwuh7GxMdy4ccNSzd9ut1Gv19dcN61Oa6WTxVK6wYBWo/Uc9Pprcs81pYKpkwk0EbZbBPjwweu0VrGb/drr8WjbhlZuz58/j6NHj8LhcODTn/40fvzjH+Opp56C3++3FGPx/FRwFxcX0Ww2cefOHSwvL+OFF15AKpUSTyvHwHvA4/HgiSeesDwwaaUZWOla5fV6pRsYUa1WkUwmH4jzCofDyGQyOHjwoOU4D4OxBBgYGBgYGKwD6vW6xAhpgqK3g7WaqbeaNSHQ29p2vyWwSqZIUnUEFQBReXXKgI504jm0MqjVVE2q7UVMHLOOZ9K2A46Pv9fq73PPPYfh4WGcPn1arAg8j/bc6i35tbyofF0TJr7Hvh7awqDJolYWtb0hGAxaSOFafledDEDo7X7dWUs/XNjXiWvL77nu7733HtrtNqLRKD7zmc/gjTfeEKKpVWTtex4aGsKmTZuwf/9+NJtNvPPOO/i93/s9dLtdHD9+HMBKMwLOVav2Wrn1eDwPJEVwzXQ+a09Pj+X+oR2m1Wqht7fXEuH2MBjCamBgYGBgsE7QpEtXzestVr6P5EoTWh05ROKkSQUA2dLmsfmPoe0kniTQOtuUxyO0OqrnoH9vJ8za6mD323IsPA8Jo8/nQ6FQwP3795HP5y0FXZqs6c5WHPdavlquryaHmrzy85ow82GC5JHb8e12G8FgEI1GQ4qudO6sXgvt/9VqL7DaqUo/cNBioG0Emrhq24ImiGfPnpUCpl/7tV+TyDT94KAzfU+dOoWlpSUsLS2h3V7pnDYxMYF8Pg+fz4dutytb+8AKeeUYut2VtIJqtSo+1FKphEajgWq1+oCHmF+19YKqutPpXNMeshaMJcDAwMDAwGCdoFU2/gxYi630lruOerIrjCSvJCokYPaEABIpABY7glYCdRqBVi15Pq3GAqvqnyYi/Ofz+SyRTx6Px6KY8hzaxxsMBnHy5ElZA1aY6+12jklvsWtCqP2pfL+OkdJkmWphs9m0eHrtrWG9Xq8oii6XC4FAAMvLy5amDXayzAcK+1joCSa0paDRaFjaxOo11/cBj1epVHDx4kXs3r0b0WgUX/ziFzE7O4tOp4M7d+6gWq3KfNlh6ubNm9i7dy+KxSLa7TYymQxarRZu376N0dFRy7ju3bsn19Pv98Pv9wvxZGoCrzVJMiPAtDdZq9WM3+I1+DDSagirgYGBgYHBOkCrlZp8ajKoCZomYlo50yRIEzl6GNc6B8kSFUCekwRDq2E8p50ca5Kq/Zj6XNqrqgkvsJrVShVTF0vxq93fq39+2LY/SS/HYI/k4nHsAf+cE2Oe2CSg2WzC5/MJsXU4HKhWqzI/v98vTRS0f9iujtrJtV4Le5GTTjzQxNS+Ja9/LpfLKJfL8Pl86O3tRTqdxsaNGyXrVMdnZbNZ3L17V1T2WCyGdnuly1YikUA2m0UqlcLWrVuxsLCA/v5+uWa8Po1GA3Nzc4jFYkJOy+WyrKtOEyiXy9IZjGs3NDRkIewfZgkwhNXAwMDAwGAdoAtx7NX09qr6tTyQa5FcwBrXZCeNfC8VQW4H873au0q1z06U9Fh0q1HtJeW8WIC1lvJYKpUQCoUkj5O/GxgYkGD+YrFomRPJMACxAOi10kVPJI2M0XpYKgHtES6XS4gqAHmNxN/pdKJarQrRZgETi4do2WCXMq3gajKu7Qxrqeb6emoLBNu80l9L769e0/HxcRw5cgS1Wg09PT3o7e0V9VhbFFKpFKLRKObm5rBx40ZMT08jEonA4XDg8uXL2LRpEzweD/r6+jA8PCwEVNs4isUiNm7cKKpppVIRhZXzoPobCoXkIYpz6OnpecD7+igYwmpgYGBgYLAO0JmpACxkkb8nWdGqKgDLH3qncyUPlF5VvT1NIqC307WKpwu+WFxDP6m96EqTK8Cac0qyphMC7KTL3izA7/dbGibwK+dCf6hWJTUJ1N5f7TW1PwBoqwFf075SXeTEeXCN9fq0Wi0Eg0GUy2WZV7FYtMzTPh6dqKDXVCvQ2s6gC5xIcHUbWh2NxXXhfcKfT548iU984hMYGRnByMiIFGHpYjimHAwPD2NiYkKsC319fdLR6vLly3A4HNiyZQv6+/tx9+5dzM7OSotgj8eDnTt3ik2AtgP7PcrrzjFwXn6/H5FI5IF79WEwRVcGBgYGBgbrADtR0gTGXqzCLkZ6C1krcuy8xN8BqyRVK5tEs9mUSm2tcNkr3bUKad+e1mowP0dSAsBCovQ49Nh5Dr4vmUyi1WohnU5LARiLyYDVIiS7oqzXQm/L289FpZJEVmeO6ip6zpPqKsk4O0oxksyuiHI8PJ7uWuVwOCxrrhVXPQ6uh/49VV1NhnUqgybqnU4HV65ckaYGL7zwgoyPFgBifn4ePp8P4XBYKvV5jlgshrm5OUxNTWF+fh6jo6MSg8ZrcePGDQBWP24mk0GxWJQmBIwfa7VaKJfLlkzdeDxuuT6PglFYDQwMDAwM1gF62157PNdS7BiOT1JFAscCIL5fH1crjfpcAB7IWNU2Av0ZvaWvFV09zrUKsABre1VNCDXhJOnqdDoIh8Oo1+uSVkDip7fOeVzt6WQBF5U8+zY7QQKr462ogOrmCnr89m19fqZSqQiR5HryoYKf1Sq2XjeuK8fncDjEFqGtHlpZJ5G0q7GdTkeq+rk+LpdL/KvxeBxOpxOf/OQn8ZOf/ETU90qlgkqlAr/fj0ajAafTiUqlgkKhgFQqhbt37wqRnZiYwMTEBF588UUcPnwYb7/9NsrlstgN7t+/b4mlarfb4lnlOudyuTXvUz5o0T/7KBjCamBgYGBgsA6w+y/ptSQJIqEhEdCET2+va3XNvm1OhZDvo8LH99ozYLUSaS/sWouk6s/osWj1WDcMIEjw9LZ2KBTC8vKypT2oHpvOOtVFVdpKQQWV6wdY46DYSUqPW1sftKKqt7ZZVET/ZSAQkDFqGwCht+/t9gpd/GT3s9q9rvohQlsVOp2OdCnTRWh8b7fbxalTp3D06FGEw2H4fD5s3LhROl4Vi0V4PB74fD5Z7263C6/Xi8uXL1vuA87/7bffRrPZxPHjx3H58mXMzs6iUqkI4Y/H4+KDjUajaLVayGQyCIVCyGazACDX3OVywefzWUj4Wk0gNAxhNTAwMDAwWAfYSSBJi1agNNHThJSft/tE9Za99pN2Oh1pY8riFxI3HZKvt7Z11boe71rKMMdLJZUV8/pz2otpVzSDwSAymQxqtZrF78ljNhoNS9GPVl8fRrypkJIg0bKg56zJnlZtOR8qsDyu/Zj2eC67D9dOqrVqrefPY2nyppVsPrjoZAC7Yq39rfzciRMn8MILL6DT6WDHjh0olUpYWFiwqPfhcBjNZhNzc3Piz7XfByzUunXrFkqlEoaGhhCJRPDee+/JPbK0tIRnnnkG0WhUVNtUKoVcLocNGzZYVOdKpSLJA3osj4LxsBoYGBgYGKwD9DY5FT170ZBWuuxKpX1rmD5BTYD5+1qtJgohiZ72fdp/JjQp4r+1yIweF32LevzAauKB3Z5AMqe3vu2dkjSosnJ8ertdj0vPQat3Oi+W68jXtc2g2+1KML4+ria1TBHQFgdtO9D+YCrl+tqS8DJZwL42elzabqBJNb+3WwZ4vBMnTsg4Hn/8cTgcDiwuLlo8uMvLy0JW9Vz1/Tk/P4/FxUWMj4/j4sWLiMfj+MIXviC5td1uFydPnkS1WhVy6na74ff7pWUwsKJiezweyb3lPfthPlZDWA0MDAwMDNYBmijxZ12EpbebddGTLvLRuanaF0lwKxuAWA60JUBX4HMMOkqLqh3JiybWJMj6nIxPAqydjjgX3ViAr42MjFh8orQykIRqi4Te/qfFgcexk2m9zloZBlZJMgPw11L42u22pUsYC9X0zySc9mvHddIdsOhV1Wujfa28Rjy3JsZ8yNBFclo1532gLQQ6G3Vubg6tVguFQgGHDx/Grl270Ol0UK1Wcfv2bczPzz+S9LPQjNc8nU7jxz/+MQDgs5/9LHw+n5z3nXfesaQn8Fjs4sXj0AbzsxRcAYawGhgYGBgYrAtIVKjQaQJLokbioxVWEiN2bNKKK0kNiQWVV6fTaSlkWqvaHljtWKWVNfs2uVYgddU6sEqgOXbOU5NYEj2STWZ4agsDABk/lUl7EZkmr1Q0deMCEm7tt9VeUq1Uch31fKjeav+rPY3BTsr0mtrTCrSiaFeOtdVBk2faAHTHKPt8tY1A3x/6/ZcuXcL9+/dlHY8dO4Z4PC7qrlbH7feDy+VCrVZDt7vSrrVWq6Fer6NUKuG73/0uGo0Gjh8/jr6+PrmnL1++jLt37yKdTiOXy2FhYQHz8/NYWlpCOp0WD62+740lwMDAwMDA4GMIEiRNRN1ut6hVJKt8D7eo+Yedat3D/Je6AIlEzl6cZffFcqvWnsEKrHolWZlOEq2D6elf5Vh4fpKodrsNv98vBT7d7moDgVKpJHPWHk4N3ehAk3E70dLeUntaASOi3G63rCcJXqPRQK1Wk/gnvqYLtezHI3knCa3VamuqqSSG2tpB8q+JrT6mVp71NeYYNMHnuXg+PjTw9+fPn0c2m4XT6UQoFEJ/fz8GBgbkvZwnO3uxQM/n88nrfBDi3KvVKn7wgx+gWCziU5/6FEZHR0Xpv3nzptwj+n7X6jmJuF29Xgum6MrAwMDAwGAdoIukqMBpxczuW3Q6nUJmdQW5VtVIWO1+Vl2UpIt89PY/AAsZ0UROk1B78RHnwGgiTYK1Csz3alIdiUTgdDpRKpVkXUjoSJDsW+aNRsNSxc/tZU28NUnSqjGJPH8meeKYfD6fHEsXUekCL86XRJlro4ukNLnU10rbN+zrri0PPp9PiByVWXtygVZ3SYb1w43+Pedx69YtPP3002g0Gti9ezdqtRqeffZZuX/sPupGo4FKpYLBwUEsLi6iUCggmUxieXlZlHG/34+TJ0+iVqvhyJEjiMViuHHjBpxOpzycRKNRS+OCWq0Gv9+PQqEgpF3fA2vBEFYDAwMDA4N1ArfBSUD0zzouyU5Q7FvPJJrcQtZqqs4t1WSKCpxdnbR32LIrggDWJEP2sXY6K9mq2oepFUCqg5VKBbVaTUihruonAQZWs2MZjQTAQkD1GmnCzHOThPLhQKuampTrzlHaHqDJMD9DYs0x6fQAff34OR7b6VxJEqAayWPxODw/f9Zqut7ut3cW0+PVxJPXuVgs4vr169iyZQtKpRJ2796NM2fOWIrkuJYk9D6fD8lkEtu2bUO1WsWFCxfw5JNPYnl5WSwCzWYT4+PjAIDNmzejr68P58+fx9TUFHbs2CFjZGYsryPvn0qlYhRWAwMDAwODjyMeVhUOrJJA7TXVBVKaoOiKcL3NvFZVPwBL+1XtA7WTWhItkiIdcUVSrMkVj8PvdeYpCaEeSzAYlLlq+wKwQk65ZaybF2jyzXPx91rB02SVc9OEUhducT6cNztE8XMkzTyeJqe0cHDsei012aR3lcpqo9GwrLGeNz9Hj6rb7X4gt1YTbP0woa8D7ysSaJLY6elpDAwMIBKJoFQqYd++fbhw4YLFl2wv+ON1DIVCOH78OE6dOoUdO3YgGAzC7/db/LzpdBobNmzA888/L0SUY2g0GhY7Cdc1l8theHj4Yf9VVubyyN8aGBgYGBgYfCTQxABY9R8CsPwxJynU76ESRiJEgqPJKr/qcwGrnk5NPjU0MV6LvGhiCsBCPuzFY1TR6HPVVe6hUMiiAjNBwF5spdu9kojqLWytCHK8VOvcbrcQTq3Acrud5E+Tca/XC7/fD5/PJ35eqt+6wE2vDUmw3v7nGlDh5FqQbHJ8/KqL4/Q9wLFrPzKvr/bq8v7Q5F3fOxx3t9vFuXPnkM/n4ff7AQA7duywfF7fFzxGuVxGqVQSknvr1i3k83lUKhWLlSUej2N2dlZUfBJUh2Ol1W29XhcCy3m99dZblkSGtWAIq4GBgYGBwTqAREcXn3BLl0TEHiOls0k1sSNx0pmedmsAYG02oLes7Uqvro7XW+L8rCbW+hjanwmsqqesNCfhTKVSQirpv9RbwppsM93AvkVvJ2Z6Hto3q8muJuckhPxer6v2veq15Ny1kqmVcLuPWF+7VquFcrls8aHqFABtA9Hj1oRXX0etyvP68z6yP+xoby3X69y5cyiXyzJ2+mY5ZvsDFc/j8XgQiUSwZ88ezM/PI5PJoNVqSWZtp9NBPB6XAq++vj54vV65h2jH4LVvNpuYn5//0NashrAaGBgYGBisAzR5IsnTBFX/sxNNwBrKrz2sfE+tVkOpVLJ0mAJWFVZNcrm9bCenmvCSBNr9s1Qf9TG14snXuQUeiUTQ6XRQr9dRLpfR7XbFB0nCtVZRmd7yX0slthdcaVKnyZ0m8CR2lUplTQLMbWz9UMD5aMuEzlvVDwp8jX7hUCgkr9kL3bSyyWp67bvVxJsPLtoaob3D2vJhTzXgvB0OB65duwaPx4NQKIQnn3wS4XBY1l8/QOix0bcaDoexf/9+OJ1OzM3NyTrxHL29vSgWi1hcXEQoFLLk+DIDt9FoSMMCQ1gNDAwMDAw+htDET/sQSagqlYplS1iTPxIo/gysElESNp/Ph0AgIIRH+x01odRFQprk2T2wJGzsbASsFkIxDYDEV6t7VC673S78fj96e3uFvOj36G32bncl9kqrzDyPVvw0cSbsMVBU9DSRIyHj9jx9mIzlAoBAIGCJYQIgrWOB1SQFKo5+v1/isLQ6qv9pSwHnph8OuKba32ovWrOTcH1/cE3tnmh97fW9Vi6Xkc1mEY1GEQgEcOTIEXg8HoTD4Qe8sLrorlgsolwuw+Vy4bHHHoPD4cDc3JzEU/GaMwVifn4eDocDgUAAXq9X7pN2u42lpaU1x2yHIawGBgYGBgbrBL0Fq9U9kiCtipJgaFVN+1e1KqmJL4mYfStbezK1KqgJIaELslhRDqwWcDGSS6cPcF5aPe7p6UGhUMD8/DxyuZyl0EqTOV1gpdeJVeaa7NrtAHrewKoHVkd7cf4kxfyeRNGeMMC1iUQi8Pl8soZ9fX344he/iMXFRdy9e1e2x7nNz+OQJGrfrFZQ9Rw5Zp5Xq6T2oH9dyKb9rPa10X5WvabdbhcTExOoVqsIhUIIh8N4/PHH5RqTwGuiy3uoWq0CWNnW37JlC1KpFO7cuYN6vY52e7U9L9c2n89bSDD916dOnRKy/SgYwmpgYGBgYLBO0P5PFt5ocghAqrTb7bbksOptcxbfsApdb3dr0mOv7Odn1iqm0koeVUBdXa/VXI5Xxz1pcqxJNFuFkhjqinwel4qjVn3ttgDGYJFEaWV0LaWOpEtbJ/TxdIU814n/9FY8wfn+xm/8Br761a/C4/EglUphcHBQ5s5rpe0SXDO7B1nbO6hU232yenwAsG3bNjz33HN48cUXEY/HZd21eql9wGutCcdz+vRpFAoFOJ1ObNq0CU8//fQDDxz8DLNVnU4n0um03BsbNmzAnj17MD4+LhYLqtgulwu9vb24e/euKLhcRxJfneqwFgxhNTAwMDAwWCdo1YvbzfxZe0xJMJkMYLcFkODUajULQdSET2+t8zXdA57EWStw9l7vWsXk5wDrVj1jjICVLXRdxb+0tIRarSbqaqvVkrafXAse1+5XBVbJqPbTavVYFzhx7UhUSZzsUVLcwu52u9LpqtFoCNkiudZk3+FwwO/34+/+7u8shVC0MpTLZSGJ2iLBtdL5q5yPvgZ6nPphQpPoGzduYGZmBplMxqIeU8W12xFarZb8jteP5200GuJ3drlcGBkZwdDQEDqdDsrlsniM7V3ASFq5fuFwGDt27MD4+DjK5bKsLR8MYrEYZmZm5B7m/cGxPAqGsBoYGBgYGKwTSApJUkggSEh1cY0mYZqwau/lWtFL9iIp7UXU6qYusNLKKbAau8Tv+X7tAeU8OAf+4+uMP+JngFU1kePj91wD+za/ViM1AQSssWBaFaSSrL/n2pKIsWCIn9WV9fbj8bxPPPEEWq2WRGDV63U5fzgcRiaTkc9oIq4fQrR1g6SUxJLrqDNj9bZ/q9XCtWvXcPbsWSwtLUmaAt9Lb7I+j/2+YR6sw+HABx98gFKphFqtBo/Hg4MnTIQAACAASURBVKeeekqKpez+Zj4Y8d6bn59HvV6Hw+EQpfXatWuo1WpC3rm+8XhcSDah77WHwRBWAwMDAwODdQBJBH2Ja23/6u17EgQWDGlliu/R5MZeXEVyoYt87Bmeup2rfYw8tm4Tqo/9MOVQq8U6SkoTZxJzKoCANd9Vkya7L3atwiW7D1evBc9nL8LS0WKMeKKiqJVAnveNN96w2DdcrpXOUPb8W0Z92VVgemf12msyrovDmDSgO1sR2iMLrD5caKVd2yT40LKWSn7ixAkhzG63G0eOHJE11vYOr9crRJjHW15eRqFQQKfTweDgIPbu3Yvr16/LwwBJusPhQDgcRrPZFDsAx/UoGMJqYGBgYGCwDtDb+7rdKH2dJIq6gAhYzS1lcROPQXXS4VgJaNef0R5ZTQz0Njwr3klk9dYxsLrtb/fY6s9rSwGJlNvtRqvVEjKnM2YBK+lk8ZYuUuJXrhmPzXWxd5nSLVY5Ls6V4yOxZmMAYFXt5XY8i7z4lWOkWsj14M+8niTxfX19Qhy1kqkL2/R8dBW/1+sV3zKvh44Qs8dm6Wut14oPBTwWt/G1d5lr1O12Ua/Xcf36dczNzWFxcRGNRgOPP/64xZ+s7xl93dvtNvL5vKxBMpnEjh07MDk5iXq9LlYLjiWXyyGXy334fxSe52d+p4GBgYGBgcHPFVQQSTp0FyBuMZOAMKdUV+CTgGgSqQmM7pZEBVbHHxGaFPKYeltebwnriCNtO+BXej+BFdJUrValUIfH1uTWXmjFJgO64p3QaiHnpX2dehucBE2Pxe7hBVaIKjs+2c9Dok8llJ7fdruNaDRqKZLTnwUgLVV5Dp6X4/V6vdLdiYkBWlHXHmSek6A6zNf1tj/PQ2hlU19LnR6gbRoTExMol8vwer2IRqNIpVJ46aWXZNwaa0VvZbNZNJtN+Hw+JJNJ7Nq1C7du3UKtVrNk7+ZyOUxNTcnDxVqFYRqGsBoYGBgYGKwT+Adfq2ks+NHeS03qtMqpt2qpZPJ7bQ/QhVSa7NiryYFV9VJ7We2xRgTHpEmxPSqLAfH1ev2BmCa9RU7lkFv+eutae1l5fD0WfRy2AtV+Tj1WfQz7Fr6eo7Y86Ngvv9+PQCAAYJWIejwesT/YyaEer/Yr8zoDkO5kdkuD3UfLcTLei7CrpZw3z89rrtef46CirNX3Dz74AD6fD+FwGH6/H6FQCAcOHLB4e+3FYfo8CwsLqNfrCAaDGBoawr59+3Dv3j1pOkCFtVKpfMj/kFUYwmpgYGBgYLBO0CRTV7cD1vxQEkL7+0hetVqoiZw9e5TFWbpVJmCNFNI93al4avKqfajatmD/HcdbrVZRr9dFNdafo6pMZdbhcEjxDs9vJ9ea3OooLh6Tn6fFQCckUIUlkavX60I6taeW14XtVEulkhDMer0u3kv9UAAA1WrVMiZ+tV83rZbymumHCqqZVJ213UOr7gTPT3uC9gKTWOox2RMJ1ooCe/vtt4V4tlotDA0NIRKJWB5mtF2F5Jvjy2azci36+/uxY8cO3L9/X4rdFhYWLOfT+b5rwRBWAwMDAwODdQC9hNoLyp+1d5WvA6uEUwe62yvCgVXSozNA9Xa4zlEFYDmWJsgkd3allcfhsUmseOze3l709vYilUoJQSNRppeRx/X7/WuqtxyfVh05Dt1Jq9vtWryvOi2ApJVKIrtWafJNMqjJnPZ4sgALgCWGi5Xy3W4Xs7OzyGQyQui45a/9sfb5rGVv4Jrra8C50y/7/7V3LbtxXNd2dbO7qx/sF9kUJUokLUUCLMhI4kcSGIEnGeQD8iuZJb+RX8jUk0wyyiBBgDiGJSeWBYuyZVESI1Ik1U/2o5rdfQfE2lx12KKSe68vfYG9AEP9qD51zqkivGrttfcmcdVro35oPZ9eY7V3cBwSXC3az3O2Wi08ffrUlPE4jvHuu+8in88nKhIokVZC3u/30W637b5YX1/H22+/jb29PfR6PRwcHNgYcRyfIbBn/l7O/dbhcDgcDsd3AiWjVBnDED1Ja5hlThKgHscwYYnEQYmrklVV+eYlVKl6yFCvKroaylfCsrKygoWFBVQqFdTrdUwmE2SzWatsoIXxgdPmA1RXARihVYVV/aiaZKbVDkIyzZJVVAmZ9EMyql25eF76hLl/JL0AUCqVbO9I4vb395FOp3HlyhVrWUpCpz5a9RHrg4euad49Qn+xZvOrgkzVmMq4Wj50DXoO3X/OjddbSf/Dhw9xcHCAZrNp8/7www/RaDRsjqp66zWZzU6aAuzs7KDX62EymVjJqyiKsLW1Zdd+Mpng6dOn5/69OGF1OBwOh+MCQAKjmeAkOcCpF1Hfq6KqofiQ2OrvNdyvpI8kjEpfqVRKeFDV86khdQ1XUyUmCYyiCDdu3MDbb7+Nd955B4VCwUib+jqn06kRLIaSqVxy7ppUxbqkmphERVH9prpuTUJTAs7vSBq1Nuy8ElRHR0eWDDccDk05nU6naLfbWFxcxNLSEqbTKYrFIorFIrrdLqIoQqFQsGvFigNcsz5chN5Q2ge451rjVktzAaeEP47jRAUBrotjcW/CjlJcC60JJKbcv7t376Lf76Pf71s5q3feeccqUcxT8VV1n06nODw8xGAwwGw2Q61WQ61Ww+bmJmq12pn78nVwwupwOBwOxwVAQ/iaXAUkOz2RWGrReBJEVTdJtFR11GQhJWUMITMp6vj4GIPBwMbQRC2C6qjOg/MnkanX61hcXESpVMLW1hY+/fRTm7uqn5lMxrLGSdLVbgAkw+eqJnN9YQMDTVTSfSCR0rG1kkDoC1WySmjInnu9s7ODbDaLRqOR8NSS/OdyuYQHmcQx9BWTkGqyG49jG1tVTDlXvVbcLx6j89d1axIW16XEWFV6JdN3797F4eEh/vSnP6FQKOD4+BhvvfVWIjlOfch8zSSr4XCI3d1dvHjxAp1OB5VKBbVaDb/61a9QKpWQTqffmICVOfdbh8PhcDgc3wm0BmeY+a7Z1yQEVLRUadNMcJJCJVxKukgS6fmkh5HnDTtUqTcWgB2vXZ9IhuI4NnWV5OXBgweJGqmaUKahdqqAVBm5Fr4PKwqwBFLobyVJVRI6j6CRMLNCANehbUoVDN0zoUqJbjabTbQqVc/q9va2kbEwbM690ESlKIpsXaqc6zp031WB5pw0kY7HqSrOefKacwx6WtmxjNYFPiSMRiM0m0389Kc/tRaty8vLODo6wvPnzxPzVf81CSzvm3a7bWp3tVrF+vo6fv3rX+N3v/vdG2uyusLqcDgcDscFgCSL6p8qkEo4wzArSYl6Tvk7rdGqhAxAIiys2eEsyaTZ6/PCvCRbqsCSmGSzWfz85z/H8vIystksHj9+nFirJo0VCoUzRAk4zVwnydF9Uc+nhsgJriMk02EmuxLAXq+XIFhMQNKweiqVMusC94mqdqPRsLC7KuTpdBo3b95EqVQyNZbzUUKsnmUqqqqE676ojzhMfuPYVL/VVsJ7RBOyXqdIs9SWNqTQ8Z8/f47BYIDxeIy1tTWk02msr6/PtQGoB5kteTkPelWHwyG2trZw+fJl/Pa3vzV7wOvghNXhcDgcjgsAlTclfkpalZwS6gfVJB6SDybnaNa7lmtSYjybzSzjW5VBzSKnMkeFlOqkJvKkUilcu3bN3rNbktoXSKSYBEUix3HDOqKcrxJ39ewqUefY2kGL34VJaFw3wTlxbCVaXFuo4gInxLtUKqHT6ZzxIN++fRuffvppwnOrCU2aIEZiymM5J/W1qqVBvam89uoN1nshbIfKvQ2JvNoMeL3UL6379o9//APdbhedTgfpdBqDwQDr6+uJur88N32vnU4HrVYLo9EIuVwO165dw2AwwPHxMf74xz9id3cXxWIRv/jFL87/ezn3W4fD4XA4HN8JSK5IMqlwaiF34LSUFXBKOHgclcYwXKykkoRKS2Gx9ScVNbUP8BgdU8mTElEqc1euXEEul0Or1cJnn31mZEkTxtQCEX7HdWr4nOflMdq/nmRKFWS1E6j6qiFqvldfqfp8qaam0yc1Whke51pVdTw+Pkaj0bDQdzabxcbGBv76179aYwFWElASrdYLenh1j6lS6vqUtOt6Cb0uCr2WJLpK7pWYc3y1L2h1Ae7h/fv3rZoC1eB6vW7XZDweI5fLIZvNolwuJ8pc0RrA+w8AHjx4gI8//hidTufM/BVOWB0Oh8PhuCCQTJJ0kmgCp+RUPamqkIUERS0BWq+TBEiVPVVfSUwymYx12KLSSkKsNgUlg5lMBu+//z5qtRqm05MmAS9fvjTCpSSZlQFUtdW5kGjO86Xye1VLNQkLSCYQqb819IRy7DCzHkh2rqKlQj3DlUrFOmlx7tlsFv1+H8ViEV988QWiKLKEKy1Lpf5XQr3LqpTyPTP3CY7B68B2vXyg0ftJ7zG+Z3UC9SlrNQG9xqrKKukdjUZ49OgRUqkUarWaeVHL5bLdX/x3MBhgZWUFo9HICKnaE168eIHZbIbf//73+M1vfnPu34onXTkcDofDcQHQ8HaYJKWhXQ3NKhng5yS5mtikCUo8nv9yXCp9nAvJF4+lJxI4IT1K4EiKPvroIyO93W4Xf/vb30w5y+VyplIyXD0cDi18TLIInBJIDYXzcyVLoWKslgol+LqnYTcqHqNlvcJKAWGiF1/TPsB9UZtEpVJBqVSyeSlp1FqzSmD5e4bhuV5dK+esyjrPz/0bDoe2T7qXmtDHsXU9ujdK/nlO3WO97q1WC8Ph0NYOAFevXkW/3080dSgWi0ilTjpdqTrNcTKZDD7++GPEcYxms3nu34srrA6Hw+FwXBBU1QrJAokGi+erd5NkiF5GtQCQvFHdZHUB1g9dWFhANptNeFeBU1Kl/k+1IlCd47w++OAD1Go1LCwsoN1u4y9/+UtCCWb2PMPlSppZQklD/PxcFWVV/jg3qoKafKRKJZAkp9xD/l4L9qtSrUlohM6R49DnqtaCTCaDb775xjphsQECHx5YRoxJZfxOC+3zenF9/Ez3Q68P56sElWtX7yyJtiJ8MFArAPeDVgYdV0n4vXv3Ekr34uIibt++nVDQub+lUgmXLl0yMk5VmKT36tWruHHjxrl/K05YHQ6Hw+G4AIQKl4Z69T8qmOFvtFwRSZOSGi2fFHo+6TPkmPM8smF4mmOkUiksLS2h0Whgf38fx8fH2NnZsXOp1xSAhd6VHHMOIUElVI1UC4BWC6DtgSSLxJDrV9+oKs1hDVaG3XVveD4ST/pY+/0+4jhGHMfodrsAgF6vh36/j9FoZL5gHk9yS7JPdVbnoBUAuL+qfvP6q4WCDyia1c/rqw8Bup96TZSAa0kxVVPV6xqqrMSrV68S5DqKIty+fTtRTYEPO6PRCOVy2a5Zr9fDcDjE06dP0e/3kc/nz/17ccLqcDgcDscFIMwE19fqP1XVVL/XEk4aptbkIi0mr4lD6nNkiFqTkAgSqDiO0e/3ze95584dpNMnBfIHgwEePnxo5yfJU2WOSUzAiXLH8zObXEPSmhGvr7kmjsn/uA8kSFq/VveD59CKBGyYQCLKzHa2cqVHlJUOSLLT6ZOGC0p4oyg64x3l7/QBRFXikLTye/1M168+ZSqYwGl1h3w+b37bUI3lWJwP900VdeCEsPNa0QoSeqc51ydPnmA6naLf79s5crkcisWitePVRLLhcIjxeIyXL1+i3W4jm81iZWUlQdBf+/dy7rcOh8PhcDi+E/B/+ixPRIJCAgkgQbBUCQv/5x7aCbRSgKqpAIx06DhKDLVkFQkuCXG328WHH36IfD5vRO/u3bs2HskO32sXJSKKIhwfH2M0GqHX62FxcdH2Q9U9VVDVv6vqqM5Vk9VCa4CqmCx8r2RU/1Mbgob+qV6qH5eNGPQa6fVltQA9f6iq8nslraFXed69Q8JK4kllW/dJCbIq0HpN1PvLcymxpbVD91bH+vzzz1EsFs0XnMlksLq6asR5MBjY76iyDodDqxrAuYYtY0N40pXD4XA4HBcADe8DyQLuSiLC8k98TTV0nv+V/9I7Sj+qeiRVgdNQMxXYbDaL0WiEdPqkpFQcx1hbW7MQdKFQwOHhIQ4ODkzxA4BSqZQoLUXyo1nys9lJYwM9NkyO0tA29yUk+EpaVUlVQh9WUwgVxfA7ErqQJKt62u12cfXqVbx48cKupZIvAFZvVq8N90OJtird/D704Or+qvKu81bleN661JvLvQwrMqjXl+fSeem9yD0Zj8f47LPPcOvWLURRZIl2jUYDT548wcuXL/GDH/zgTNKYkt95pDyEE1aHw+FwOC4A7Nuu/dhJ7jSJiGpWSEg06YbkSgkwiSeQVC/nEQQlICRZLG/F8HCxWMQPf/hDlEolUyI/+eSTM4k7JCYkukpctdoAs+O5Fg2BK1FllQG1TWhikfp2SbSUXIbrPA+q1ipx1TF5vp2dHdy8eRPb29umZIeEPCSQnKMSbCWEGupnchwAS54Lqw/oA02pVEoQ7FQqhV6vZ/eN+mBD24GqsFwr7zuOp/cbP+N84zjGo0ePsLGxYf7UVqt1JuGOayoWi4l7hcls58EJq8PhcDgcFwCSvvPKDvE7kttQiVTFS/2nqhCqZ5LQDHWSE/4uJC4kKiQZR0dHppIxXDzP/0oiNBwOLfTPzHD+husjadfkMh4zLyFLoYRPSa2Oo3NS0hq+D5XF0B6h5Hg6neLrr7/GBx98gK+++goHBwdzk6bUh0riB8CqNtA6QcKvDxqapU/yenBwgIWFBTQaDbTbbSOz9I52u12zXAwGAwwGA0sE417ThsE1agLf4uKiledSJZcPUrPZaXtZfVgZjUY4PDxEpVKxZgLvvfcehsMh9vf3E/fY8vKyqdP8TBXgeXDC6nA4HA7HBYDK4bxOU6ECFxIxVVZDkssx8/l8wsPK3zDDnu+1WcF0OrXkIZIrEp333nsPURQZOf3zn/9shIrJNcAJsYmiCJPJxAiTekrpteQ6gNNuXiSCWvEgiiLEcZzwVSoR5V5p+Frfh75Ono9Q5VofAEJLQDgGz/PJJ5/YdZv3sME1dDoda4XLtczDvGz8y5cvI51OY29vD8vLy2i327hy5Qo2NzftIaLf7yOVOinWv729bfPd2Niwmrpqh9DxuR+7u7uI49iaPzCJKp/Po1AoIJPJIJvNmj9V92MymeDw8BCbm5sAgHa7jdFohKWlJXS7XYxGI0vQYlk1vffCKhIhnLA6HA6Hw3EBoHpF8qgKniYOkZxpeDUMsytZ479apD+Xy+Ho6MgSnpQoMjwPnLYxpXeV/d+XlpbQ6XRQr9eRSqVMvVtYWECn0zEiyzmR8JZKJcumf53Hcl6ykRJSWhJSqRTy+Xwi2YiEnIRZa6MqCQ8VWiWuSkS1UL56LHUc/j70kIY+2nK5jDiOsbOzk6jXyrFYxonheq36EFZHePbsmZUpI7FbWFiw/VhdXQUAtFot7O/vYzwe48qVK5hMJqjX67h3756F3qnE8sGI68lkMrh8+TK2trawtraGTqdj9yS9zYPBwK4Jz882rJzX119/jVwuh2q1ai1btQnFbDZLrJ1reVOVACesDofD4XBcABjip88zbLcahqLz+bwR2zDxSAmo+hzH47H5UKl6kqSF3ZU0mYeEgmrg5cuXUalUMBgMkMlk8OTJE6sIkM/njWzxdyS9oRqp/lYlpeFnqiorQQzLPOn3iiiKLHO91+udqXuqY80jitx/+oJDbyw/5/XSxg25XA7j8Rjdbhez2Qyrq6totVpmAWEZrMFgkEgw41iaaEVFk68rlQpevnyJpaUlVKtVHB0d2ZhK0ElOFxYW7EGl1+sZKS8UCgn7CPeQ4Xyq/yS2w+EQhULBHkz4PStDDAYD289Op4NisYjd3d2EZYDn4j1Vr9ctCqBk/nVwwupwOBwOxwVAyVDo/aRaSDLCLG+SIg3HajJO6GHVxB9NvKK9ICRJoac2m82i0WigXC7b74+Pj/HixQv7TMlpr9czAsL5aXY5x9ci+SSBWrlAw9ecn9oIdHxCSS9VWSKXyyGKIqRSKfNzUvEbDodG5AuFQsJ6QXCNtDdowf5SqWRr43iKGzduIJPJWPOAZ8+eYW9vL6FI63Vj8haJJ7tBFQoFXL9+Hfv7+8hkMlYWipUTdB8A2MPE/v4+0uk0lpaWTCGlX1T3Mp1O4+joyNYexzFqtZodz7nl83lbI89L3y5VaSZ7cVzeo1RkZ7MZ3n33XSOq3W4XURThPDhhdTgcDofjAhCWT9K+9MAJSep0OqjVakZ41DrA0Di9gKr4MQRLQsnC8hrKVo+nVhkggWHL10ajgX6/j729PRweHloNU+DUM8vXIZEMPZOh51a/U1IaKq3zMvVVXaYaqklSwKkvkn5ajp/NZtFut02JnEwmpiaqx5fnnExOWslSYc7n80awJpOJlbAKiXomk8Ha2ho2Nzfx7bff4tWrV7h16xZWV1etqcBgMLA9VTLN7HuSwpWVFVSrVRQKBVsrO2mxooMmv3U6HXS7XdTr9URS29HRkZFiVXNZM5XqqarRvDZ8aNKHDRJSRgHopSXx5/xp3+C9t76+jsXFRSPPP/rRj879e3HC6nA4HA7HBYAKp2b4qzrZ6XRMvaPvNPRPkpAxsYrEVj2aJKQkDvl83giRtm4Fkooolcp79+4ZmdbyUsS8TH4gmdijCWLqVdU1cE/CxCp9TZU03MeQNPO/sAQTz8cQ9mAwwPLyMl69emVdrhQkgalUyorhszSXNhPgevXakMR1u128ePEC7XYbrVYL5XIZURShUqkYMRwMBpbZH8exJatxrmz80G63LTFO275q3VstGZZKpbC/v4+NjQ10u90EyeS5WZOVe0eVmaByr6ov95Flqlg5Ikyuo3pK5VUT+Z4/f45bt26hXC5jZWUFL1++xHlwwupwOBwOxwUgJIkkVXyvyhiJgqqT2gGKRE/LMQEnYV16VpkYQwKi/dvV98jEJUIJIN8rNLStr6mccV1aYovQ+qWaaBZ6S8PzzbM3qBqo5aLmqb2sRMDMfoa52ZmKIe9KpYJOp2Pn7vV6KBaLFt5nSFvPzXMOh0MsLCzgyy+/xC9/+Uvcv3/f9mV3dxdLS0u2xlqthoODA1QqFZTLZYzHY3z11VemcmezWTSbTVNJ2VGKr/v9PtLp0/awvM7qq+12uyiVShb612urynq9Xker1QIAa1FbLBaNKIdlt5Sk9/t9q7Or9yrv43w+fyaiMBqNkM1mUS6X515vwgmrw+FwOBwXgDBEPy/zfDweJ0gBiQCzzNULyrA1yQrJFMnidDo11Y3ksN/vm7o2L7wfKrpqI5iX8c/fhmvUf8Pi92FJq7DcU1juiGFvPf88n64er3tAkkwi1mq1LGOeJJNqd6fTsf1mAhstAwsLC6hWq+j3+xgOh1ZZgd+TCDLc/9FHH5n63Wg0cHBwgMePH1uo/fr16/jnP/9pGfa8tiwBxdqnly9fNuWS49ECsLGxYftXrVbR6XTMLjAej9FqtVAsFm1ftf6qNjwgKR2NRvY6jmMj8vrgQ88xHxI0uW00Gtl9S0WbD0MstXb//n3zs54HJ6wOh8PhcFwAwlA8/yWRIBkg4SJBIPFS8kpVi4SM4Wj+lkSVpIekcV54X0mpJh+pOqpkMfSXKvEleeFvODZD67pG+hsZGqfvNpvN2nq4B0z+Cc9J8sTsc342mUywsrKSyNYHThTTarWKVquVKO1FkKzRp8mHhPF4jCiKrGRYu91OPDywFi3P8Yc//AEbGxtoNpvodruYTqdYW1vD9evXrVxVHMe4desWXr16hdlshmKxaBn+VL8HgwGuXr2Kfr+POI7R7XatcQDH0EYAtDuQbNNGQJuBVp3gNWIJK71H9UGC9wAtC7xGJPu5XA7D4dCO02tHAk7rSqvVwvHxMf7+97/jzp075/69OGF1OBwOh+MCoKF8VVGVJACnHk0tnaSeQkJfk2hRTdT6pCHxDImxJjTNS6JShVQTvVTpZSKYloFSny4JJqsLaNH9VCqFYrFoPkySpVChZRiciUT0+7IME48nWfvZz36GJ0+eWNmlBw8eoFAonKkIoBUYdG8YetcM+8PDQ5u7qpQArIYtSWQcx9jd3bXzPHr0CKVSCWtra4iiyAryX716FdPpSRetQqFgTRNKpZKRRHpouafpdNoSwXh+EslyuYxms2nXjopvtVpNWEGUODN8r35YJa16bYETry8rElB9Ho/H6HQ6qFarWFxctL2h6gwAzWYTuVwOvV4Pjx49OvfvxQmrw+FwOBwXDA29K/FT1U/9nWHSEkOvmUzGOgppKSm2AdWmAYQSDyWf+p6EWc+pRfs5BpVNkj4taaVVC/i9Zpk3m00sLy+btWE8HqPdbqNQKBjpBE7JeGhlILlSAqz96b/88kuUy2X0+31L8KlUKtjd3bW9o4WCpJjE+/j4GHt7e1haWkKv17Pjjo6OUK/XEx3BlJizUD8AbG1tYX193dqUptNpDIdDfPPNN4lEN4bkNzY28K9//cv2gio5FdE4jq1xgHpnASQePKiY8r7hQxEJdT6ft3Jd0+nU/Kuz2UmZMs6fNhQqx6y6kEqlrDkErw+vPfeuVCohiiLreNVoNPD48WMMBgP8+Mc/tm5h58EJq8PhcDgc/0+hJBY4mxDF70hS5vlOw+z/MOGK4WY2CiC0i5Zm5ZMs0SeqhHZlZcXO02q1rEQTPabM3p9OpxgOh0a86TFlqSd6RRmGJrnc3NzE06dPbb6ayLW1tYV8Pm9eUyqkVChDUqj+zNlshna7jWKxaLVMG40G0um0eUm5l5p0pN7fyWSCvb09rK+vo1qtGrF7+PBhotsZf3N4eGjXgseqX5SNA1qtlhFQKqHct9lshkuXLmFnZwcAUCqVTNWm6suOaKxH2+v1EEXRmaL/+XwevV4PvV4P9Xrd5qGJgXoPNptNa0VL+wTJPnBaZaBer1sHt3Pv9XO/dTgcGVDjFgAAA+RJREFUDofD8Z1CSWboGf3fgpKBUGE979hwHvpalVmt1cnj5iVYkcSq3UHD6SSax8fHVmJKfaHs1jQej3Ht2jUjPSSw29vbCUJL5U/buKbTaSwuLuLmzZuI4xg/+clPzpSpUoVbSS9JKgBsb28n1sL1aCJTuJeDwQDPnj3DkydP8O2332Jvbw+1Wg21Wg2FQgG5XA7lctlC6izjpao666hmMhlUq1W89dZbuH37Nm7fvp3wRLO16qVLlwDASlCxsgB9toVCIVFxQB9C+DsqylSu+bCiCVXNZtOqTOh9wGtK3y33Qb2zd+7cOZNcF8IVVofD4XA4LgDzEphChFUD/i/wuvPM+1zX8CaF7LwxlfSFmKcea9ksVZlJmEg8Sb74PZXKer2OpaWlBBlVGwQV3bBxwfPnzxO+WE1aI0mfV/VBbRAkm2wZOxqN8P7776Pf71unMCZLkWSqF7jT6eDg4ACrq6sol8vmNdVap1Ram80mjo6OkEqddMpixQCOR8+rJsT1ej00Gg07JpPJIIoiC+2T+GujgrBWqzaymM1mePz4ccImwnqyvF4ArKTY6+CE1eFwOByOC8A8IhYSt9eF+F93zH9CNs+Dkq3X2Qhed/x/CvVdzitVpeOH6vDrjic0zK6JbOHvNNEsHJ+JcVRt6VcNE9PUShDWIaVtgXNqNBrodDoJ72gul8Pu7q55SwEYQaQamc1mLbFpd3cX29vbWFhYQBRFWF1dNYsFMR6P8fnnn6NUKiGXy5kdgqSS6jOT1PieFQVIOhcXF23+JJmlUilhI6FfleOGe067Bwku1dV2u21VEc6DE1aHw+FwOC4Q/47COo+8KUI1b944YfmpN81pXoWA8+agmHeON1kRQvxPFOV5cwtD9/8pQo9m+PpNUPIWznE0GiU6RfF7+mHZMpWNAdjkgGpyq9XCbHbSVSsk0qPRCNVqFVEUWcMAqp0ku/Sy6uc6j0qlgkqlYtaKTqeDfr9viW29Xs9sBlRymSxH77HWe9U9oU3gTfelE1aHw+FwOC4Q55Ge132nLU7/U3WTvw2JzZvOqyrkf1dNDc8XnuffUXO1fu15c33deAAS6ud3tZY3IbQ4nHfMeWr3m8aezWbo9/tWWkpLjIWNEFRtpnI6mUzw6NEju+487tKlS7hy5QoA4IsvvkhUUFhcXEQcx4jj2BTcbDZryW2KVquFRqOB5eXlc9eUmv1fmWIcDofD4XA4HI7/BrxKgMPhcDgcDofjew0nrA6Hw+FwOByO7zWcsDocDofD4XA4vtdwwupwOBwOh8Ph+F7DCavD4XA4HA6H43sNJ6wOh8PhcDgcju81/gv+lf5GVCDvJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x864 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l1x-HsH9IkQ",
        "colab_type": "raw"
      },
      "source": [
        "TO be checked for images obtained from net"
      ]
    }
  ]
}